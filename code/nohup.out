[2023-08-02 18:22:47,722] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:23:15,833] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:24:01,146] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:24:12,496] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:24:23,453] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:49 in train                        │
│                                                                              │
│    46 │   │   model = SentenceTransformer(BERT_PATH, device=DEVICE)          │
│    47 │   │   model.__setattr__("max_seq_length", MAX_SEQ_LENGTH)            │
│    48 │   elif LEARNING_METHOD in ["consert"]:                               │
│ ❱  49 │   │   model = ConSERT(BERT_PATH, device=DEVICE, cutoff_rate=CUTOFF_R │
│    50 │   else:                                                              │
│    51 │   │   raise Exception(f"Unsupport LEARNING_METHOD: {LEARNING_METHOD} │
│    52                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: __init__() got an unexpected keyword argument 'max_seq_length'
[2023-08-02 18:25:10,484] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:49 in train                        │
│                                                                              │
│    46 │   │   model = SentenceTransformer(BERT_PATH, device=DEVICE)          │
│    47 │   │   model.__setattr__("max_seq_length", MAX_SEQ_LENGTH)            │
│    48 │   elif LEARNING_METHOD in ["consert"]:                               │
│ ❱  49 │   │   model = ConSERT(BERT_PATH, device=DEVICE, cutoff_rate=CUTOFF_R │
│    50 │   else:                                                              │
│    51 │   │   raise Exception(f"Unsupport LEARNING_METHOD: {LEARNING_METHOD} │
│    52                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: __init__() got an unexpected keyword argument 'max_seq_length'
[2023-08-02 18:25:47,815] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-02 18:25:53,340] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:26:06,818] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:49 in train                        │
│                                                                              │
│    46 │   │   model = SentenceTransformer(BERT_PATH, device=DEVICE)          │
│    47 │   │   model.__setattr__("max_seq_length", MAX_SEQ_LENGTH)            │
│    48 │   elif LEARNING_METHOD in ["consert"]:                               │
│ ❱  49 │   │   model = ConSERT(BERT_PATH, device=DEVICE, cutoff_rate=CUTOFF_R │
│    50 │   else:                                                              │
│    51 │   │   raise Exception(f"Unsupport LEARNING_METHOD: {LEARNING_METHOD} │
│    52                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: __init__() got an unexpected keyword argument 'max_seq_length'
[2023-08-02 18:26:20,406] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:49 in train                        │
│                                                                              │
│    46 │   │   model = SentenceTransformer(BERT_PATH, device=DEVICE)          │
│    47 │   │   model.__setattr__("max_seq_length", MAX_SEQ_LENGTH)            │
│    48 │   elif LEARNING_METHOD in ["consert"]:                               │
│ ❱  49 │   │   model = ConSERT(BERT_PATH, device=DEVICE, cutoff_rate=CUTOFF_R │
│    50 │   else:                                                              │
│    51 │   │   raise Exception(f"Unsupport LEARNING_METHOD: {LEARNING_METHOD} │
│    52                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: __init__() got an unexpected keyword argument 'max_seq_length'
[2023-08-02 18:26:55,874] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-02 18:27:33,552] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-02 18:25:54 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-02 18:25:58 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-02 18:25:58 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-02 18:25:58 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-02 18:25:58 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-02 18:25:59 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-02 18:26:01 - Cosine-Similarity :	Pearson: 0.4211	Spearman: 0.4462
2023-08-02 18:26:01 - Manhattan-Distance:	Pearson: 0.4408	Spearman: 0.4470
2023-08-02 18:26:01 - Euclidean-Distance:	Pearson: 0.4384	Spearman: 0.4456
2023-08-02 18:26:01 - Dot-Product-Similarity:	Pearson: 0.4227	Spearman: 0.4420
2023-08-02 18:26:01 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-02 18:26:10 - Cosine-Similarity :	Pearson: 0.5301	Spearman: 0.5443
2023-08-02 18:26:10 - Manhattan-Distance:	Pearson: 0.5278	Spearman: 0.5450
2023-08-02 18:26:10 - Euclidean-Distance:	Pearson: 0.5250	Spearman: 0.5430
2023-08-02 18:26:10 - Dot-Product-Similarity:	Pearson: 0.5238	Spearman: 0.5392
2023-08-02 18:26:10 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-02 18:26:17 - Cosine-Similarity :	Pearson: 0.6069	Spearman: 0.6196
2023-08-02 18:26:17 - Manhattan-Distance:	Pearson: 0.5923	Spearman: 0.6217
2023-08-02 18:26:17 - Euclidean-Distance:	Pearson: 0.5887	Spearman: 0.6179
2023-08-02 18:26:17 - Dot-Product-Similarity:	Pearson: 0.5867	Spearman: 0.6033
2023-08-02 18:26:17 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:21 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-02 18:26:24 - Cosine-Similarity :	Pearson: 0.6615	Spearman: 0.6711
2023-08-02 18:26:24 - Manhattan-Distance:	Pearson: 0.6464	Spearman: 0.6796
2023-08-02 18:26:24 - Euclidean-Distance:	Pearson: 0.6441	Spearman: 0.6774
2023-08-02 18:26:24 - Dot-Product-Similarity:	Pearson: 0.6091	Spearman: 0.6247
2023-08-02 18:26:24 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-02 18:26:31 - Cosine-Similarity :	Pearson: 0.6877	Spearman: 0.6931
2023-08-02 18:26:31 - Manhattan-Distance:	Pearson: 0.6686	Spearman: 0.6990
2023-08-02 18:26:31 - Euclidean-Distance:	Pearson: 0.6683	Spearman: 0.6984
2023-08-02 18:26:31 - Dot-Product-Similarity:	Pearson: 0.6482	Spearman: 0.6605
2023-08-02 18:26:31 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-02 18:26:38 - Cosine-Similarity :	Pearson: 0.7030	Spearman: 0.7069
2023-08-02 18:26:38 - Manhattan-Distance:	Pearson: 0.6809	Spearman: 0.7097
2023-08-02 18:26:38 - Euclidean-Distance:	Pearson: 0.6812	Spearman: 0.7093
2023-08-02 18:26:38 - Dot-Product-Similarity:	Pearson: 0.6807	Spearman: 0.6891
2023-08-02 18:26:38 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-02 18:26:45 - Cosine-Similarity :	Pearson: 0.7136	Spearman: 0.7171
2023-08-02 18:26:45 - Manhattan-Distance:	Pearson: 0.6922	Spearman: 0.7196
2023-08-02 18:26:45 - Euclidean-Distance:	Pearson: 0.6926	Spearman: 0.7193
2023-08-02 18:26:45 - Dot-Product-Similarity:	Pearson: 0.6918	Spearman: 0.6996
2023-08-02 18:26:45 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-02 18:26:52 - Cosine-Similarity :	Pearson: 0.7241	Spearman: 0.7263
2023-08-02 18:26:52 - Manhattan-Distance:	Pearson: 0.7030	Spearman: 0.7287
2023-08-02 18:26:52 - Euclidean-Distance:	Pearson: 0.7034	Spearman: 0.7289
2023-08-02 18:26:52 - Dot-Product-Similarity:	Pearson: 0.7036	Spearman: 0.7108
2023-08-02 18:26:52 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:26:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-02 18:26:59 - Cosine-Similarity :	Pearson: 0.7295	Spearman: 0.7312
2023-08-02 18:26:59 - Manhattan-Distance:	Pearson: 0.7084	Spearman: 0.7331
2023-08-02 18:26:59 - Euclidean-Distance:	Pearson: 0.7086	Spearman: 0.7327
2023-08-02 18:26:59 - Dot-Product-Similarity:	Pearson: 0.7129	Spearman: 0.7182
2023-08-02 18:26:59 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-02 18:27:06 - Cosine-Similarity :	Pearson: 0.7346	Spearman: 0.7363
2023-08-02 18:27:06 - Manhattan-Distance:	Pearson: 0.7134	Spearman: 0.7376
2023-08-02 18:27:06 - Euclidean-Distance:	Pearson: 0.7136	Spearman: 0.7371
2023-08-02 18:27:06 - Dot-Product-Similarity:	Pearson: 0.7219	Spearman: 0.7250
2023-08-02 18:27:06 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-02 18:27:13 - Cosine-Similarity :	Pearson: 0.7356	Spearman: 0.7374
2023-08-02 18:27:13 - Manhattan-Distance:	Pearson: 0.7145	Spearman: 0.7384
2023-08-02 18:27:13 - Euclidean-Distance:	Pearson: 0.7147	Spearman: 0.7381
2023-08-02 18:27:13 - Dot-Product-Similarity:	Pearson: 0.7233	Spearman: 0.7264
2023-08-02 18:27:13 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:20 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-02 18:27:23 - Cosine-Similarity :	Pearson: 0.7397	Spearman: 0.7414
2023-08-02 18:27:23 - Manhattan-Distance:	Pearson: 0.7190	Spearman: 0.7426
2023-08-02 18:27:23 - Euclidean-Distance:	Pearson: 0.7191	Spearman: 0.7421
2023-08-02 18:27:23 - Dot-Product-Similarity:	Pearson: 0.7286	Spearman: 0.7313
2023-08-02 18:27:23 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:30 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-02 18:27:33 - Cosine-Similarity :	Pearson: 0.7424	Spearman: 0.7445
2023-08-02 18:27:33 - Manhattan-Distance:	Pearson: 0.7219	Spearman: 0.7451
2023-08-02 18:27:33 - Euclidean-Distance:	Pearson: 0.7220	Spearman: 0.7449
2023-08-02 18:27:33 - Dot-Product-Similarity:	Pearson: 0.7321	Spearman: 0.7349
2023-08-02 18:27:33 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:40 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-02 18:27:43 - Cosine-Similarity :	Pearson: 0.7430	Spearman: 0.7454
2023-08-02 18:27:43 - Manhattan-Distance:	Pearson: 0.7219	Spearman: 0.7457
2023-08-02 18:27:43 - Euclidean-Distance:	Pearson: 0.7220	Spearman: 0.7457
2023-08-02 18:27:43 - Dot-Product-Similarity:	Pearson: 0.7333	Spearman: 0.7365
2023-08-02 18:27:43 - Save model to ./outputs/simcse-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-25-45
2023-08-02 18:27:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-02 18:27:54 - Cosine-Similarity :	Pearson: 0.7409	Spearman: 0.7433
2023-08-02 18:27:54 - Manhattan-Distance:	Pearson: 0.7190	Spearman: 0.7438
2023-08-02 18:27:54 - Euclidean-Distance:	Pearson: 0.7190	Spearman: 0.7435
2023-08-02 18:27:54 - Dot-Product-Similarity:	Pearson: 0.7318	Spearman: 0.7354
2023-08-02 18:27:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-02 18:27:56 - Cosine-Similarity :	Pearson: 0.7401	Spearman: 0.7422
2023-08-02 18:27:56 - Manhattan-Distance:	Pearson: 0.7172	Spearman: 0.7429
2023-08-02 18:27:56 - Euclidean-Distance:	Pearson: 0.7173	Spearman: 0.7424
2023-08-02 18:27:56 - Dot-Product-Similarity:	Pearson: 0.7315	Spearman: 0.7349
2023-08-02 18:27:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-02 18:28:00 - Cosine-Similarity :	Pearson: 0.7395	Spearman: 0.7415
2023-08-02 18:28:00 - Manhattan-Distance:	Pearson: 0.7163	Spearman: 0.7424
2023-08-02 18:28:00 - Euclidean-Distance:	Pearson: 0.7163	Spearman: 0.7419
2023-08-02 18:28:00 - Dot-Product-Similarity:	Pearson: 0.7311	Spearman: 0.7344
2023-08-02 18:28:02 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-02 18:28:04 - Cosine-Similarity :	Pearson: 0.7392	Spearman: 0.7413
2023-08-02 18:28:04 - Manhattan-Distance:	Pearson: 0.7157	Spearman: 0.7421
2023-08-02 18:28:04 - Euclidean-Distance:	Pearson: 0.7158	Spearman: 0.7415
2023-08-02 18:28:04 - Dot-Product-Similarity:	Pearson: 0.7309	Spearman: 0.7340
2023-08-02 18:28:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-02 18:28:07 - Cosine-Similarity :	Pearson: 0.7390	Spearman: 0.7412
2023-08-02 18:28:07 - Manhattan-Distance:	Pearson: 0.7157	Spearman: 0.7420
2023-08-02 18:28:07 - Euclidean-Distance:	Pearson: 0.7157	Spearman: 0.7414
2023-08-02 18:28:07 - Dot-Product-Similarity:	Pearson: 0.7304	Spearman: 0.7333
2023-08-02 18:28:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-02 18:28:12 - Cosine-Similarity :	Pearson: 0.7387	Spearman: 0.7406
2023-08-02 18:28:12 - Manhattan-Distance:	Pearson: 0.7154	Spearman: 0.7417
2023-08-02 18:28:12 - Euclidean-Distance:	Pearson: 0.7154	Spearman: 0.7412
2023-08-02 18:28:12 - Dot-Product-Similarity:	Pearson: 0.7296	Spearman: 0.7324
2023-08-02 18:28:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-02 18:28:15 - Cosine-Similarity :	Pearson: 0.7387	Spearman: 0.7406
2023-08-02 18:28:15 - Manhattan-Distance:	Pearson: 0.7155	Spearman: 0.7418
2023-08-02 18:28:15 - Euclidean-Distance:	Pearson: 0.7155	Spearman: 0.7412
2023-08-02 18:28:15 - Dot-Product-Similarity:	Pearson: 0.7294	Spearman: 0.7322
2023-08-02 18:28:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-02 18:28:17 - Cosine-Similarity :	Pearson: 0.7387	Spearman: 0.7406
2023-08-02 18:28:17 - Manhattan-Distance:	Pearson: 0.7156	Spearman: 0.7419
2023-08-02 18:28:17 - Euclidean-Distance:	Pearson: 0.7156	Spearman: 0.7413
2023-08-02 18:28:17 - Dot-Product-Similarity:	Pearson: 0.7294	Spearman: 0.7323
2023-08-02 18:28:17 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-02 18:28:20 - Cosine-Similarity :	Pearson: 0.7064	Spearman: 0.6866
2023-08-02 18:28:20 - Manhattan-Distance:	Pearson: 0.6887	Spearman: 0.6884
2023-08-02 18:28:20 - Euclidean-Distance:	Pearson: 0.6882	Spearman: 0.6883
2023-08-02 18:28:20 - Dot-Product-Similarity:	Pearson: 0.6948	Spearman: 0.6751
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-02 18:26:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-02 18:26:04 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-02 18:26:04 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-02 18:26:04 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-02 18:26:04 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-02 18:26:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-02 18:26:07 - Cosine-Similarity :	Pearson: 0.4057	Spearman: 0.4280
2023-08-02 18:26:07 - Manhattan-Distance:	Pearson: 0.4271	Spearman: 0.4289
2023-08-02 18:26:07 - Euclidean-Distance:	Pearson: 0.4237	Spearman: 0.4264
2023-08-02 18:26:07 - Dot-Product-Similarity:	Pearson: 0.4087	Spearman: 0.4285
2023-08-02 18:26:07 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-02 18:26:16 - Cosine-Similarity :	Pearson: 0.4733	Spearman: 0.4781
2023-08-02 18:26:16 - Manhattan-Distance:	Pearson: 0.4684	Spearman: 0.4814
2023-08-02 18:26:16 - Euclidean-Distance:	Pearson: 0.4648	Spearman: 0.4753
2023-08-02 18:26:16 - Dot-Product-Similarity:	Pearson: 0.4486	Spearman: 0.4574
2023-08-02 18:26:16 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:21 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-02 18:26:24 - Cosine-Similarity :	Pearson: 0.5672	Spearman: 0.5762
2023-08-02 18:26:24 - Manhattan-Distance:	Pearson: 0.5423	Spearman: 0.5727
2023-08-02 18:26:24 - Euclidean-Distance:	Pearson: 0.5422	Spearman: 0.5717
2023-08-02 18:26:24 - Dot-Product-Similarity:	Pearson: 0.5687	Spearman: 0.5785
2023-08-02 18:26:24 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-02 18:26:31 - Cosine-Similarity :	Pearson: 0.6446	Spearman: 0.6482
2023-08-02 18:26:31 - Manhattan-Distance:	Pearson: 0.6252	Spearman: 0.6459
2023-08-02 18:26:31 - Euclidean-Distance:	Pearson: 0.6252	Spearman: 0.6453
2023-08-02 18:26:31 - Dot-Product-Similarity:	Pearson: 0.6467	Spearman: 0.6510
2023-08-02 18:26:31 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-02 18:26:38 - Cosine-Similarity :	Pearson: 0.6882	Spearman: 0.6916
2023-08-02 18:26:38 - Manhattan-Distance:	Pearson: 0.6642	Spearman: 0.6916
2023-08-02 18:26:38 - Euclidean-Distance:	Pearson: 0.6639	Spearman: 0.6903
2023-08-02 18:26:38 - Dot-Product-Similarity:	Pearson: 0.6866	Spearman: 0.6906
2023-08-02 18:26:38 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-02 18:26:45 - Cosine-Similarity :	Pearson: 0.7118	Spearman: 0.7141
2023-08-02 18:26:45 - Manhattan-Distance:	Pearson: 0.6891	Spearman: 0.7146
2023-08-02 18:26:45 - Euclidean-Distance:	Pearson: 0.6877	Spearman: 0.7128
2023-08-02 18:26:45 - Dot-Product-Similarity:	Pearson: 0.7108	Spearman: 0.7137
2023-08-02 18:26:45 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-02 18:26:52 - Cosine-Similarity :	Pearson: 0.7329	Spearman: 0.7344
2023-08-02 18:26:52 - Manhattan-Distance:	Pearson: 0.7158	Spearman: 0.7354
2023-08-02 18:26:52 - Euclidean-Distance:	Pearson: 0.7145	Spearman: 0.7335
2023-08-02 18:26:52 - Dot-Product-Similarity:	Pearson: 0.7321	Spearman: 0.7341
2023-08-02 18:26:52 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:26:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-02 18:26:59 - Cosine-Similarity :	Pearson: 0.7424	Spearman: 0.7444
2023-08-02 18:26:59 - Manhattan-Distance:	Pearson: 0.7254	Spearman: 0.7453
2023-08-02 18:26:59 - Euclidean-Distance:	Pearson: 0.7239	Spearman: 0.7432
2023-08-02 18:26:59 - Dot-Product-Similarity:	Pearson: 0.7421	Spearman: 0.7446
2023-08-02 18:26:59 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-02 18:27:06 - Cosine-Similarity :	Pearson: 0.7471	Spearman: 0.7485
2023-08-02 18:27:06 - Manhattan-Distance:	Pearson: 0.7292	Spearman: 0.7491
2023-08-02 18:27:06 - Euclidean-Distance:	Pearson: 0.7275	Spearman: 0.7469
2023-08-02 18:27:06 - Dot-Product-Similarity:	Pearson: 0.7469	Spearman: 0.7487
2023-08-02 18:27:06 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:11 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-02 18:27:14 - Cosine-Similarity :	Pearson: 0.7498	Spearman: 0.7511
2023-08-02 18:27:14 - Manhattan-Distance:	Pearson: 0.7321	Spearman: 0.7515
2023-08-02 18:27:14 - Euclidean-Distance:	Pearson: 0.7306	Spearman: 0.7495
2023-08-02 18:27:14 - Dot-Product-Similarity:	Pearson: 0.7492	Spearman: 0.7508
2023-08-02 18:27:14 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:20 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-02 18:27:23 - Cosine-Similarity :	Pearson: 0.7511	Spearman: 0.7525
2023-08-02 18:27:23 - Manhattan-Distance:	Pearson: 0.7338	Spearman: 0.7526
2023-08-02 18:27:23 - Euclidean-Distance:	Pearson: 0.7322	Spearman: 0.7508
2023-08-02 18:27:23 - Dot-Product-Similarity:	Pearson: 0.7505	Spearman: 0.7520
2023-08-02 18:27:23 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:30 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-02 18:27:33 - Cosine-Similarity :	Pearson: 0.7569	Spearman: 0.7583
2023-08-02 18:27:33 - Manhattan-Distance:	Pearson: 0.7407	Spearman: 0.7583
2023-08-02 18:27:33 - Euclidean-Distance:	Pearson: 0.7392	Spearman: 0.7566
2023-08-02 18:27:33 - Dot-Product-Similarity:	Pearson: 0.7561	Spearman: 0.7578
2023-08-02 18:27:33 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:40 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-02 18:27:43 - Cosine-Similarity :	Pearson: 0.7586	Spearman: 0.7608
2023-08-02 18:27:43 - Manhattan-Distance:	Pearson: 0.7452	Spearman: 0.7606
2023-08-02 18:27:43 - Euclidean-Distance:	Pearson: 0.7438	Spearman: 0.7594
2023-08-02 18:27:43 - Dot-Product-Similarity:	Pearson: 0.7575	Spearman: 0.7598
2023-08-02 18:27:43 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:27:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-02 18:27:54 - Cosine-Similarity :	Pearson: 0.7598	Spearman: 0.7629
2023-08-02 18:27:54 - Manhattan-Distance:	Pearson: 0.7495	Spearman: 0.7630
2023-08-02 18:27:54 - Euclidean-Distance:	Pearson: 0.7481	Spearman: 0.7616
2023-08-02 18:27:54 - Dot-Product-Similarity:	Pearson: 0.7586	Spearman: 0.7616
2023-08-02 18:27:54 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-02 18:28:03 - Cosine-Similarity :	Pearson: 0.7620	Spearman: 0.7653
2023-08-02 18:28:03 - Manhattan-Distance:	Pearson: 0.7521	Spearman: 0.7655
2023-08-02 18:28:03 - Euclidean-Distance:	Pearson: 0.7509	Spearman: 0.7642
2023-08-02 18:28:03 - Dot-Product-Similarity:	Pearson: 0.7606	Spearman: 0.7635
2023-08-02 18:28:03 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-02 18:28:12 - Cosine-Similarity :	Pearson: 0.7644	Spearman: 0.7673
2023-08-02 18:28:12 - Manhattan-Distance:	Pearson: 0.7535	Spearman: 0.7674
2023-08-02 18:28:12 - Euclidean-Distance:	Pearson: 0.7524	Spearman: 0.7664
2023-08-02 18:28:12 - Dot-Product-Similarity:	Pearson: 0.7627	Spearman: 0.7655
2023-08-02 18:28:12 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-02 18:28:21 - Cosine-Similarity :	Pearson: 0.7660	Spearman: 0.7685
2023-08-02 18:28:21 - Manhattan-Distance:	Pearson: 0.7544	Spearman: 0.7684
2023-08-02 18:28:21 - Euclidean-Distance:	Pearson: 0.7532	Spearman: 0.7675
2023-08-02 18:28:21 - Dot-Product-Similarity:	Pearson: 0.7643	Spearman: 0.7668
2023-08-02 18:28:21 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-02 18:28:30 - Cosine-Similarity :	Pearson: 0.7670	Spearman: 0.7693
2023-08-02 18:28:30 - Manhattan-Distance:	Pearson: 0.7552	Spearman: 0.7692
2023-08-02 18:28:30 - Euclidean-Distance:	Pearson: 0.7540	Spearman: 0.7682
2023-08-02 18:28:30 - Dot-Product-Similarity:	Pearson: 0.7653	Spearman: 0.7674
2023-08-02 18:28:30 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-02 18:28:39 - Cosine-Similarity :	Pearson: 0.7675	Spearman: 0.7701
2023-08-02 18:28:39 - Manhattan-Distance:	Pearson: 0.7561	Spearman: 0.7703
2023-08-02 18:28:39 - Euclidean-Distance:	Pearson: 0.7548	Spearman: 0.7690
2023-08-02 18:28:39 - Dot-Product-Similarity:	Pearson: 0.7660	Spearman: 0.7682
2023-08-02 18:28:39 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:46 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-02 18:28:48 - Cosine-Similarity :	Pearson: 0.7678	Spearman: 0.7707
2023-08-02 18:28:48 - Manhattan-Distance:	Pearson: 0.7570	Spearman: 0.7709
2023-08-02 18:28:48 - Euclidean-Distance:	Pearson: 0.7557	Spearman: 0.7696
2023-08-02 18:28:48 - Dot-Product-Similarity:	Pearson: 0.7662	Spearman: 0.7688
2023-08-02 18:28:48 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-02 18:28:55 - Cosine-Similarity :	Pearson: 0.7681	Spearman: 0.7710
2023-08-02 18:28:55 - Manhattan-Distance:	Pearson: 0.7574	Spearman: 0.7714
2023-08-02 18:28:55 - Euclidean-Distance:	Pearson: 0.7562	Spearman: 0.7699
2023-08-02 18:28:55 - Dot-Product-Similarity:	Pearson: 0.7665	Spearman: 0.7691
2023-08-02 18:28:55 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:28:59 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-02 18:29:01 - Cosine-Similarity :	Pearson: 0.7681	Spearman: 0.7710
2023-08-02 18:29:01 - Manhattan-Distance:	Pearson: 0.7575	Spearman: 0.7714
2023-08-02 18:29:01 - Euclidean-Distance:	Pearson: 0.7562	Spearman: 0.7699
2023-08-02 18:29:01 - Dot-Product-Similarity:	Pearson: 0.7666	Spearman: 0.7691
2023-08-02 18:29:01 - Save model to ./outputs/simcse-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-25-51
2023-08-02 18:29:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-02 18:29:07 - Cosine-Similarity :	Pearson: 0.7313	Spearman: 0.7126
2023-08-02 18:29:07 - Manhattan-Distance:	Pearson: 0.7127	Spearman: 0.7116
2023-08-02 18:29:07 - Euclidean-Distance:	Pearson: 0.7129	Spearman: 0.7117
2023-08-02 18:29:07 - Dot-Product-Similarity:	Pearson: 0.7303	Spearman: 0.7106
2023-08-02 18:27:04 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-02 18:27:04 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-02 18:27:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-02 18:27:09 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-02 18:27:09 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-02 18:27:09 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-02 18:27:09 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-02 18:27:12 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-02 18:27:14 - Cosine-Similarity :	Pearson: 0.6404	Spearman: 0.6548
2023-08-02 18:27:14 - Manhattan-Distance:	Pearson: 0.6460	Spearman: 0.6619
2023-08-02 18:27:14 - Euclidean-Distance:	Pearson: 0.6415	Spearman: 0.6577
2023-08-02 18:27:14 - Dot-Product-Similarity:	Pearson: 0.3410	Spearman: 0.3251
2023-08-02 18:27:14 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:27:21 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-02 18:27:24 - Cosine-Similarity :	Pearson: 0.6970	Spearman: 0.7091
2023-08-02 18:27:24 - Manhattan-Distance:	Pearson: 0.6839	Spearman: 0.7000
2023-08-02 18:27:24 - Euclidean-Distance:	Pearson: 0.6783	Spearman: 0.6953
2023-08-02 18:27:24 - Dot-Product-Similarity:	Pearson: 0.5640	Spearman: 0.5843
2023-08-02 18:27:24 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:27:30 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-02 18:27:33 - Cosine-Similarity :	Pearson: 0.7183	Spearman: 0.7239
2023-08-02 18:27:33 - Manhattan-Distance:	Pearson: 0.7028	Spearman: 0.7150
2023-08-02 18:27:33 - Euclidean-Distance:	Pearson: 0.6987	Spearman: 0.7113
2023-08-02 18:27:33 - Dot-Product-Similarity:	Pearson: 0.5553	Spearman: 0.5696
2023-08-02 18:27:33 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:27:40 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-02 18:27:43 - Cosine-Similarity :	Pearson: 0.7338	Spearman: 0.7397
2023-08-02 18:27:43 - Manhattan-Distance:	Pearson: 0.7152	Spearman: 0.7271
2023-08-02 18:27:43 - Euclidean-Distance:	Pearson: 0.7123	Spearman: 0.7247
2023-08-02 18:27:43 - Dot-Product-Similarity:	Pearson: 0.5679	Spearman: 0.5805
2023-08-02 18:27:43 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:27:51 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-02 18:27:54 - Cosine-Similarity :	Pearson: 0.7447	Spearman: 0.7512
2023-08-02 18:27:54 - Manhattan-Distance:	Pearson: 0.7204	Spearman: 0.7330
2023-08-02 18:27:54 - Euclidean-Distance:	Pearson: 0.7180	Spearman: 0.7311
2023-08-02 18:27:54 - Dot-Product-Similarity:	Pearson: 0.6289	Spearman: 0.6484
2023-08-02 18:27:54 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-02 18:28:03 - Cosine-Similarity :	Pearson: 0.7490	Spearman: 0.7549
2023-08-02 18:28:03 - Manhattan-Distance:	Pearson: 0.7254	Spearman: 0.7383
2023-08-02 18:28:03 - Euclidean-Distance:	Pearson: 0.7232	Spearman: 0.7365
2023-08-02 18:28:03 - Dot-Product-Similarity:	Pearson: 0.6436	Spearman: 0.6559
2023-08-02 18:28:03 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-02 18:28:12 - Cosine-Similarity :	Pearson: 0.7529	Spearman: 0.7580
2023-08-02 18:28:12 - Manhattan-Distance:	Pearson: 0.7303	Spearman: 0.7435
2023-08-02 18:28:12 - Euclidean-Distance:	Pearson: 0.7282	Spearman: 0.7417
2023-08-02 18:28:12 - Dot-Product-Similarity:	Pearson: 0.6390	Spearman: 0.6503
2023-08-02 18:28:12 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:18 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-02 18:28:21 - Cosine-Similarity :	Pearson: 0.7566	Spearman: 0.7614
2023-08-02 18:28:21 - Manhattan-Distance:	Pearson: 0.7329	Spearman: 0.7466
2023-08-02 18:28:21 - Euclidean-Distance:	Pearson: 0.7309	Spearman: 0.7448
2023-08-02 18:28:21 - Dot-Product-Similarity:	Pearson: 0.6449	Spearman: 0.6550
2023-08-02 18:28:21 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-02 18:28:30 - Cosine-Similarity :	Pearson: 0.7675	Spearman: 0.7709
2023-08-02 18:28:30 - Manhattan-Distance:	Pearson: 0.7398	Spearman: 0.7542
2023-08-02 18:28:30 - Euclidean-Distance:	Pearson: 0.7382	Spearman: 0.7529
2023-08-02 18:28:30 - Dot-Product-Similarity:	Pearson: 0.6637	Spearman: 0.6734
2023-08-02 18:28:30 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-02 18:28:39 - Cosine-Similarity :	Pearson: 0.7715	Spearman: 0.7744
2023-08-02 18:28:39 - Manhattan-Distance:	Pearson: 0.7426	Spearman: 0.7570
2023-08-02 18:28:39 - Euclidean-Distance:	Pearson: 0.7410	Spearman: 0.7561
2023-08-02 18:28:39 - Dot-Product-Similarity:	Pearson: 0.6778	Spearman: 0.6874
2023-08-02 18:28:39 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:45 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-02 18:28:47 - Cosine-Similarity :	Pearson: 0.7720	Spearman: 0.7749
2023-08-02 18:28:47 - Manhattan-Distance:	Pearson: 0.7427	Spearman: 0.7569
2023-08-02 18:28:47 - Euclidean-Distance:	Pearson: 0.7412	Spearman: 0.7561
2023-08-02 18:28:47 - Dot-Product-Similarity:	Pearson: 0.6810	Spearman: 0.6908
2023-08-02 18:28:47 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:28:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-02 18:28:55 - Cosine-Similarity :	Pearson: 0.7742	Spearman: 0.7768
2023-08-02 18:28:55 - Manhattan-Distance:	Pearson: 0.7445	Spearman: 0.7589
2023-08-02 18:28:55 - Euclidean-Distance:	Pearson: 0.7430	Spearman: 0.7579
2023-08-02 18:28:55 - Dot-Product-Similarity:	Pearson: 0.6852	Spearman: 0.6955
2023-08-02 18:28:55 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:29:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-02 18:29:02 - Cosine-Similarity :	Pearson: 0.7757	Spearman: 0.7779
2023-08-02 18:29:02 - Manhattan-Distance:	Pearson: 0.7467	Spearman: 0.7611
2023-08-02 18:29:02 - Euclidean-Distance:	Pearson: 0.7452	Spearman: 0.7601
2023-08-02 18:29:02 - Dot-Product-Similarity:	Pearson: 0.6851	Spearman: 0.6956
2023-08-02 18:29:02 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:29:07 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-02 18:29:08 - Cosine-Similarity :	Pearson: 0.7757	Spearman: 0.7777
2023-08-02 18:29:08 - Manhattan-Distance:	Pearson: 0.7476	Spearman: 0.7621
2023-08-02 18:29:08 - Euclidean-Distance:	Pearson: 0.7461	Spearman: 0.7610
2023-08-02 18:29:08 - Dot-Product-Similarity:	Pearson: 0.6839	Spearman: 0.6944
2023-08-02 18:29:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-02 18:29:11 - Cosine-Similarity :	Pearson: 0.7757	Spearman: 0.7776
2023-08-02 18:29:11 - Manhattan-Distance:	Pearson: 0.7475	Spearman: 0.7621
2023-08-02 18:29:11 - Euclidean-Distance:	Pearson: 0.7462	Spearman: 0.7610
2023-08-02 18:29:11 - Dot-Product-Similarity:	Pearson: 0.6843	Spearman: 0.6944
2023-08-02 18:29:12 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-02 18:29:14 - Cosine-Similarity :	Pearson: 0.7759	Spearman: 0.7778
2023-08-02 18:29:14 - Manhattan-Distance:	Pearson: 0.7476	Spearman: 0.7622
2023-08-02 18:29:14 - Euclidean-Distance:	Pearson: 0.7463	Spearman: 0.7612
2023-08-02 18:29:14 - Dot-Product-Similarity:	Pearson: 0.6859	Spearman: 0.6957
2023-08-02 18:29:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-02 18:29:17 - Cosine-Similarity :	Pearson: 0.7764	Spearman: 0.7784
2023-08-02 18:29:17 - Manhattan-Distance:	Pearson: 0.7482	Spearman: 0.7630
2023-08-02 18:29:17 - Euclidean-Distance:	Pearson: 0.7468	Spearman: 0.7620
2023-08-02 18:29:17 - Dot-Product-Similarity:	Pearson: 0.6892	Spearman: 0.6985
2023-08-02 18:29:17 - Save model to ./outputs/sbert-sts-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-26-51
2023-08-02 18:29:22 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-02 18:29:23 - Cosine-Similarity :	Pearson: 0.7764	Spearman: 0.7781
2023-08-02 18:29:23 - Manhattan-Distance:	Pearson: 0.7484	Spearman: 0.7633
2023-08-02 18:29:23 - Euclidean-Distance:	Pearson: 0.7471	Spearman: 0.7621
2023-08-02 18:29:23 - Dot-Product-Similarity:	Pearson: 0.6897	Spearman: 0.6988
2023-08-02 18:29:24 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-02 18:29:26 - Cosine-Similarity :	Pearson: 0.7755	Spearman: 0.7772
2023-08-02 18:29:26 - Manhattan-Distance:	Pearson: 0.7485	Spearman: 0.7632
2023-08-02 18:29:26 - Euclidean-Distance:	Pearson: 0.7472	Spearman: 0.7620
2023-08-02 18:29:26 - Dot-Product-Similarity:	Pearson: 0.6877	Spearman: 0.6964
2023-08-02 18:29:27 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-02 18:29:29 - Cosine-Similarity :	Pearson: 0.7756	Spearman: 0.7771
2023-08-02 18:29:29 - Manhattan-Distance:	Pearson: 0.7485	Spearman: 0.7633
2023-08-02 18:29:29 - Euclidean-Distance:	Pearson: 0.7472	Spearman: 0.7621
2023-08-02 18:29:29 - Dot-Product-Similarity:	Pearson: 0.6877	Spearman: 0.6963
2023-08-02 18:29:29 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-02 18:29:31 - Cosine-Similarity :	Pearson: 0.7758	Spearman: 0.7773
2023-08-02 18:29:31 - Manhattan-Distance:	Pearson: 0.7487	Spearman: 0.7634
2023-08-02 18:29:31 - Euclidean-Distance:	Pearson: 0.7474	Spearman: 0.7622
2023-08-02 18:29:31 - Dot-Product-Similarity:	Pearson: 0.6880	Spearman: 0.6966
2023-08-02 18:29:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-02 18:29:33 - Cosine-Similarity :	Pearson: 0.7758	Spearman: 0.7773
2023-08-02 18:29:33 - Manhattan-Distance:	Pearson: 0.7487	Spearman: 0.7634
2023-08-02 18:29:33 - Euclidean-Distance:	Pearson: 0.7474	Spearman: 0.7622
2023-08-02 18:29:33 - Dot-Product-Similarity:	Pearson: 0.6880	Spearman: 0.6967
2023-08-02 18:29:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-02 18:29:34 - Cosine-Similarity :	Pearson: 0.7290	Spearman: 0.7155
2023-08-02 18:29:34 - Manhattan-Distance:	Pearson: 0.7089	Spearman: 0.7007
2023-08-02 18:29:34 - Euclidean-Distance:	Pearson: 0.7085	Spearman: 0.7006
2023-08-02 18:29:34 - Dot-Product-Similarity:	Pearson: 0.6404	Spearman: 0.6324
2023-08-02 18:27:41 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-02 18:27:41 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-02 18:27:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-02 18:27:47 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-02 18:27:47 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-02 18:27:47 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-02 18:27:47 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-02 18:27:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-02 18:27:50 - Cosine-Similarity :	Pearson: 0.6326	Spearman: 0.6499
2023-08-02 18:27:50 - Manhattan-Distance:	Pearson: 0.6372	Spearman: 0.6544
2023-08-02 18:27:50 - Euclidean-Distance:	Pearson: 0.6312	Spearman: 0.6493
2023-08-02 18:27:50 - Dot-Product-Similarity:	Pearson: 0.3875	Spearman: 0.3799
2023-08-02 18:27:50 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:27:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-02 18:27:59 - Cosine-Similarity :	Pearson: 0.5778	Spearman: 0.5981
2023-08-02 18:27:59 - Manhattan-Distance:	Pearson: 0.5947	Spearman: 0.6111
2023-08-02 18:27:59 - Euclidean-Distance:	Pearson: 0.5846	Spearman: 0.6040
2023-08-02 18:27:59 - Dot-Product-Similarity:	Pearson: 0.4452	Spearman: 0.4573
2023-08-02 18:28:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-02 18:28:01 - Cosine-Similarity :	Pearson: 0.6444	Spearman: 0.6504
2023-08-02 18:28:01 - Manhattan-Distance:	Pearson: 0.6153	Spearman: 0.6363
2023-08-02 18:28:01 - Euclidean-Distance:	Pearson: 0.6088	Spearman: 0.6300
2023-08-02 18:28:01 - Dot-Product-Similarity:	Pearson: 0.5929	Spearman: 0.6045
2023-08-02 18:28:01 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:07 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-02 18:28:09 - Cosine-Similarity :	Pearson: 0.7008	Spearman: 0.7045
2023-08-02 18:28:09 - Manhattan-Distance:	Pearson: 0.6570	Spearman: 0.6794
2023-08-02 18:28:09 - Euclidean-Distance:	Pearson: 0.6546	Spearman: 0.6773
2023-08-02 18:28:09 - Dot-Product-Similarity:	Pearson: 0.6667	Spearman: 0.6779
2023-08-02 18:28:09 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-02 18:28:15 - Cosine-Similarity :	Pearson: 0.7279	Spearman: 0.7319
2023-08-02 18:28:15 - Manhattan-Distance:	Pearson: 0.6861	Spearman: 0.7078
2023-08-02 18:28:15 - Euclidean-Distance:	Pearson: 0.6847	Spearman: 0.7071
2023-08-02 18:28:15 - Dot-Product-Similarity:	Pearson: 0.6946	Spearman: 0.7042
2023-08-02 18:28:15 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-02 18:28:21 - Cosine-Similarity :	Pearson: 0.7475	Spearman: 0.7505
2023-08-02 18:28:21 - Manhattan-Distance:	Pearson: 0.7089	Spearman: 0.7283
2023-08-02 18:28:21 - Euclidean-Distance:	Pearson: 0.7080	Spearman: 0.7278
2023-08-02 18:28:21 - Dot-Product-Similarity:	Pearson: 0.7175	Spearman: 0.7254
2023-08-02 18:28:21 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:27 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-02 18:28:29 - Cosine-Similarity :	Pearson: 0.7649	Spearman: 0.7669
2023-08-02 18:28:29 - Manhattan-Distance:	Pearson: 0.7304	Spearman: 0.7479
2023-08-02 18:28:29 - Euclidean-Distance:	Pearson: 0.7300	Spearman: 0.7476
2023-08-02 18:28:29 - Dot-Product-Similarity:	Pearson: 0.7326	Spearman: 0.7383
2023-08-02 18:28:29 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-02 18:28:37 - Cosine-Similarity :	Pearson: 0.7768	Spearman: 0.7791
2023-08-02 18:28:37 - Manhattan-Distance:	Pearson: 0.7412	Spearman: 0.7591
2023-08-02 18:28:37 - Euclidean-Distance:	Pearson: 0.7410	Spearman: 0.7594
2023-08-02 18:28:37 - Dot-Product-Similarity:	Pearson: 0.7398	Spearman: 0.7476
2023-08-02 18:28:37 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-02 18:28:44 - Cosine-Similarity :	Pearson: 0.7818	Spearman: 0.7845
2023-08-02 18:28:44 - Manhattan-Distance:	Pearson: 0.7470	Spearman: 0.7649
2023-08-02 18:28:44 - Euclidean-Distance:	Pearson: 0.7470	Spearman: 0.7652
2023-08-02 18:28:44 - Dot-Product-Similarity:	Pearson: 0.7434	Spearman: 0.7519
2023-08-02 18:28:44 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-02 18:28:51 - Cosine-Similarity :	Pearson: 0.7854	Spearman: 0.7880
2023-08-02 18:28:51 - Manhattan-Distance:	Pearson: 0.7537	Spearman: 0.7708
2023-08-02 18:28:51 - Euclidean-Distance:	Pearson: 0.7537	Spearman: 0.7713
2023-08-02 18:28:51 - Dot-Product-Similarity:	Pearson: 0.7458	Spearman: 0.7541
2023-08-02 18:28:51 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:28:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-02 18:28:57 - Cosine-Similarity :	Pearson: 0.7854	Spearman: 0.7877
2023-08-02 18:28:57 - Manhattan-Distance:	Pearson: 0.7546	Spearman: 0.7717
2023-08-02 18:28:57 - Euclidean-Distance:	Pearson: 0.7546	Spearman: 0.7721
2023-08-02 18:28:57 - Dot-Product-Similarity:	Pearson: 0.7452	Spearman: 0.7532
2023-08-02 18:28:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-02 18:28:59 - Cosine-Similarity :	Pearson: 0.7867	Spearman: 0.7890
2023-08-02 18:28:59 - Manhattan-Distance:	Pearson: 0.7590	Spearman: 0.7757
2023-08-02 18:28:59 - Euclidean-Distance:	Pearson: 0.7592	Spearman: 0.7761
2023-08-02 18:28:59 - Dot-Product-Similarity:	Pearson: 0.7452	Spearman: 0.7531
2023-08-02 18:28:59 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-02 18:29:06 - Cosine-Similarity :	Pearson: 0.7892	Spearman: 0.7918
2023-08-02 18:29:06 - Manhattan-Distance:	Pearson: 0.7628	Spearman: 0.7783
2023-08-02 18:29:06 - Euclidean-Distance:	Pearson: 0.7632	Spearman: 0.7792
2023-08-02 18:29:06 - Dot-Product-Similarity:	Pearson: 0.7483	Spearman: 0.7554
2023-08-02 18:29:06 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-02 18:29:12 - Cosine-Similarity :	Pearson: 0.7903	Spearman: 0.7920
2023-08-02 18:29:12 - Manhattan-Distance:	Pearson: 0.7640	Spearman: 0.7786
2023-08-02 18:29:12 - Euclidean-Distance:	Pearson: 0.7644	Spearman: 0.7795
2023-08-02 18:29:12 - Dot-Product-Similarity:	Pearson: 0.7518	Spearman: 0.7576
2023-08-02 18:29:12 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:17 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-02 18:29:18 - Cosine-Similarity :	Pearson: 0.7918	Spearman: 0.7936
2023-08-02 18:29:18 - Manhattan-Distance:	Pearson: 0.7652	Spearman: 0.7800
2023-08-02 18:29:18 - Euclidean-Distance:	Pearson: 0.7656	Spearman: 0.7805
2023-08-02 18:29:18 - Dot-Product-Similarity:	Pearson: 0.7553	Spearman: 0.7609
2023-08-02 18:29:18 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:22 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-02 18:29:24 - Cosine-Similarity :	Pearson: 0.7941	Spearman: 0.7966
2023-08-02 18:29:24 - Manhattan-Distance:	Pearson: 0.7684	Spearman: 0.7831
2023-08-02 18:29:24 - Euclidean-Distance:	Pearson: 0.7688	Spearman: 0.7841
2023-08-02 18:29:24 - Dot-Product-Similarity:	Pearson: 0.7565	Spearman: 0.7624
2023-08-02 18:29:24 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:29 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-02 18:29:30 - Cosine-Similarity :	Pearson: 0.7956	Spearman: 0.7981
2023-08-02 18:29:30 - Manhattan-Distance:	Pearson: 0.7702	Spearman: 0.7851
2023-08-02 18:29:30 - Euclidean-Distance:	Pearson: 0.7706	Spearman: 0.7860
2023-08-02 18:29:30 - Dot-Product-Similarity:	Pearson: 0.7589	Spearman: 0.7648
2023-08-02 18:29:30 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-02 18:29:36 - Cosine-Similarity :	Pearson: 0.7967	Spearman: 0.7990
2023-08-02 18:29:36 - Manhattan-Distance:	Pearson: 0.7712	Spearman: 0.7863
2023-08-02 18:29:36 - Euclidean-Distance:	Pearson: 0.7715	Spearman: 0.7871
2023-08-02 18:29:36 - Dot-Product-Similarity:	Pearson: 0.7606	Spearman: 0.7667
2023-08-02 18:29:36 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-02 18:29:42 - Cosine-Similarity :	Pearson: 0.7973	Spearman: 0.7997
2023-08-02 18:29:42 - Manhattan-Distance:	Pearson: 0.7718	Spearman: 0.7869
2023-08-02 18:29:42 - Euclidean-Distance:	Pearson: 0.7721	Spearman: 0.7877
2023-08-02 18:29:42 - Dot-Product-Similarity:	Pearson: 0.7618	Spearman: 0.7681
2023-08-02 18:29:42 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:47 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-02 18:29:49 - Cosine-Similarity :	Pearson: 0.7977	Spearman: 0.8001
2023-08-02 18:29:49 - Manhattan-Distance:	Pearson: 0.7721	Spearman: 0.7873
2023-08-02 18:29:49 - Euclidean-Distance:	Pearson: 0.7724	Spearman: 0.7882
2023-08-02 18:29:49 - Dot-Product-Similarity:	Pearson: 0.7624	Spearman: 0.7690
2023-08-02 18:29:49 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-02 18:29:55 - Cosine-Similarity :	Pearson: 0.7979	Spearman: 0.8003
2023-08-02 18:29:55 - Manhattan-Distance:	Pearson: 0.7724	Spearman: 0.7875
2023-08-02 18:29:55 - Euclidean-Distance:	Pearson: 0.7727	Spearman: 0.7885
2023-08-02 18:29:55 - Dot-Product-Similarity:	Pearson: 0.7624	Spearman: 0.7691
2023-08-02 18:29:55 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:29:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-02 18:30:00 - Cosine-Similarity :	Pearson: 0.7979	Spearman: 0.8004
2023-08-02 18:30:00 - Manhattan-Distance:	Pearson: 0.7724	Spearman: 0.7875
2023-08-02 18:30:00 - Euclidean-Distance:	Pearson: 0.7727	Spearman: 0.7885
2023-08-02 18:30:00 - Dot-Product-Similarity:	Pearson: 0.7624	Spearman: 0.7692
2023-08-02 18:30:00 - Save model to ./outputs/sbert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-27-31
2023-08-02 18:30:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-02 18:30:05 - Cosine-Similarity :	Pearson: 0.7608	Spearman: 0.7499
2023-08-02 18:30:05 - Manhattan-Distance:	Pearson: 0.7291	Spearman: 0.7300
2023-08-02 18:30:05 - Euclidean-Distance:	Pearson: 0.7290	Spearman: 0.7306
2023-08-02 18:30:05 - Dot-Product-Similarity:	Pearson: 0.7366	Spearman: 0.7298
2023-08-02 18:22:53 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-02 18:22:53 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  snil-sup  data is 9314
The len of  snil-sup  data is 9176
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-02 18:22:59 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-02 18:23:10 - Cosine-Similarity :	Pearson: 0.1772	Spearman: 0.1806
2023-08-02 18:23:10 - Manhattan-Distance:	Pearson: 0.1662	Spearman: 0.1665
2023-08-02 18:23:10 - Euclidean-Distance:	Pearson: 0.1628	Spearman: 0.1627
2023-08-02 18:23:10 - Dot-Product-Similarity:	Pearson: 0.1815	Spearman: 0.1776
2023-08-02 18:25:20 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-02 18:25:43 - Cosine-Similarity :	Pearson: 0.6064	Spearman: 0.6039
2023-08-02 18:25:43 - Manhattan-Distance:	Pearson: 0.5722	Spearman: 0.5858
2023-08-02 18:25:43 - Euclidean-Distance:	Pearson: 0.5695	Spearman: 0.5818
2023-08-02 18:25:43 - Dot-Product-Similarity:	Pearson: 0.6093	Spearman: 0.6091
2023-08-02 18:25:43 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:28:56 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-02 18:29:20 - Cosine-Similarity :	Pearson: 0.6570	Spearman: 0.6570
2023-08-02 18:29:20 - Manhattan-Distance:	Pearson: 0.6376	Spearman: 0.6501
2023-08-02 18:29:20 - Euclidean-Distance:	Pearson: 0.6328	Spearman: 0.6442
2023-08-02 18:29:20 - Dot-Product-Similarity:	Pearson: 0.6541	Spearman: 0.6550
2023-08-02 18:29:20 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:32:32 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-02 18:32:54 - Cosine-Similarity :	Pearson: 0.6877	Spearman: 0.6842
2023-08-02 18:32:54 - Manhattan-Distance:	Pearson: 0.6586	Spearman: 0.6755
2023-08-02 18:32:54 - Euclidean-Distance:	Pearson: 0.6526	Spearman: 0.6678
2023-08-02 18:32:54 - Dot-Product-Similarity:	Pearson: 0.6884	Spearman: 0.6875
2023-08-02 18:32:54 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:36:06 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-02 18:36:29 - Cosine-Similarity :	Pearson: 0.6997	Spearman: 0.6973
2023-08-02 18:36:29 - Manhattan-Distance:	Pearson: 0.6704	Spearman: 0.6866
2023-08-02 18:36:29 - Euclidean-Distance:	Pearson: 0.6665	Spearman: 0.6814
2023-08-02 18:36:29 - Dot-Product-Similarity:	Pearson: 0.7022	Spearman: 0.7024
2023-08-02 18:36:29 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:39:41 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-02 18:40:04 - Cosine-Similarity :	Pearson: 0.7092	Spearman: 0.7061
2023-08-02 18:40:04 - Manhattan-Distance:	Pearson: 0.6844	Spearman: 0.7003
2023-08-02 18:40:04 - Euclidean-Distance:	Pearson: 0.6799	Spearman: 0.6946
2023-08-02 18:40:04 - Dot-Product-Similarity:	Pearson: 0.7109	Spearman: 0.7097
2023-08-02 18:40:05 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:43:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-02 18:43:41 - Cosine-Similarity :	Pearson: 0.7142	Spearman: 0.7111
2023-08-02 18:43:41 - Manhattan-Distance:	Pearson: 0.6879	Spearman: 0.7060
2023-08-02 18:43:41 - Euclidean-Distance:	Pearson: 0.6835	Spearman: 0.7001
2023-08-02 18:43:41 - Dot-Product-Similarity:	Pearson: 0.7135	Spearman: 0.7124
2023-08-02 18:43:41 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:46:53 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-02 18:47:16 - Cosine-Similarity :	Pearson: 0.7205	Spearman: 0.7169
2023-08-02 18:47:16 - Manhattan-Distance:	Pearson: 0.6967	Spearman: 0.7128
2023-08-02 18:47:16 - Euclidean-Distance:	Pearson: 0.6905	Spearman: 0.7053
2023-08-02 18:47:16 - Dot-Product-Similarity:	Pearson: 0.7213	Spearman: 0.7201
2023-08-02 18:47:16 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:50:28 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-02 18:50:51 - Cosine-Similarity :	Pearson: 0.7249	Spearman: 0.7214
2023-08-02 18:50:51 - Manhattan-Distance:	Pearson: 0.7043	Spearman: 0.7189
2023-08-02 18:50:51 - Euclidean-Distance:	Pearson: 0.6987	Spearman: 0.7121
2023-08-02 18:50:51 - Dot-Product-Similarity:	Pearson: 0.7260	Spearman: 0.7242
2023-08-02 18:50:51 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
2023-08-02 18:54:02 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-02 18:54:25 - Cosine-Similarity :	Pearson: 0.7280	Spearman: 0.7252
2023-08-02 18:54:25 - Manhattan-Distance:	Pearson: 0.7071	Spearman: 0.7218
2023-08-02 18:54:25 - Euclidean-Distance:	Pearson: 0.7021	Spearman: 0.7159
2023-08-02 18:54:25 - Dot-Product-Similarity:	Pearson: 0.7292	Spearman: 0.7277
2023-08-02 18:54:25 - Save model to ./outputs/sbert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-22-45
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:99 in train                        │
│                                                                              │
│    96 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    97 │                                                                      │
│    98 │                                                                      │
│ ❱  99 │   model.fit(**training_params)                                       │
│   100 │   test_evaluator(model)                                              │
│   101 │   return model                                                       │
│   102                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/SentenceTransformer.py │
│ :733 in fit                                                                  │
│                                                                              │
│   730 │   │   │   │   │   │   │   loss_value = loss_model(features, labels)  │
│   731 │   │   │   │   │   │                                                  │
│   732 │   │   │   │   │   │   scale_before_step = scaler.get_scale()         │
│ ❱ 733 │   │   │   │   │   │   scaler.scale(loss_value).backward()            │
│   734 │   │   │   │   │   │   scaler.unscale_(optimizer)                     │
│   735 │   │   │   │   │   │   torch.nn.utils.clip_grad_norm_(loss_model.para │
│   736 │   │   │   │   │   │   scaler.step(optimizer)                         │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/_tensor.py:488 in  │
│ backward                                                                     │
│                                                                              │
│    485 │   │   │   │   create_graph=create_graph,                            │
│    486 │   │   │   │   inputs=inputs,                                        │
│    487 │   │   │   )                                                         │
│ ❱  488 │   │   torch.autograd.backward(                                      │
│    489 │   │   │   self, gradient, retain_graph, create_graph, inputs=inputs │
│    490 │   │   )                                                             │
│    491                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/autograd/__init__. │
│ py:197 in backward                                                           │
│                                                                              │
│   194 │   # The reason we repeat same the comment below is that              │
│   195 │   # some Python versions print out the first line of a multi-line fu │
│   196 │   # calls in the traceback and some print out the last line          │
│ ❱ 197 │   Variable._execution_engine.run_backward(  # Calls into the C++ eng │
│   198 │   │   tensors, grad_tensors_, retain_graph, create_graph, inputs,    │
│   199 │   │   allow_unreachable=True, accumulate_grad=True)  # Calls into th │
│   200                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
RuntimeError: Found dtype Long but expected Float
The len of  snil-sup  data is 545859
The len of  snil-sup  data is 9314
The len of  snil-sup  data is 9176
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-02 18:24:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-02 18:24:54 - Cosine-Similarity :	Pearson: 0.1110	Spearman: 0.1138
2023-08-02 18:24:54 - Manhattan-Distance:	Pearson: 0.1158	Spearman: 0.1134
2023-08-02 18:24:54 - Euclidean-Distance:	Pearson: 0.1146	Spearman: 0.1122
2023-08-02 18:24:54 - Dot-Product-Similarity:	Pearson: 0.1240	Spearman: 0.1285
2023-08-02 18:28:01 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-02 18:28:25 - Cosine-Similarity :	Pearson: 0.5940	Spearman: 0.5938
2023-08-02 18:28:25 - Manhattan-Distance:	Pearson: 0.5885	Spearman: 0.5933
2023-08-02 18:28:25 - Euclidean-Distance:	Pearson: 0.5873	Spearman: 0.5921
2023-08-02 18:28:25 - Dot-Product-Similarity:	Pearson: 0.5954	Spearman: 0.5953
2023-08-02 18:28:25 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:31:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-02 18:31:57 - Cosine-Similarity :	Pearson: 0.6558	Spearman: 0.6512
2023-08-02 18:31:57 - Manhattan-Distance:	Pearson: 0.6479	Spearman: 0.6542
2023-08-02 18:31:57 - Euclidean-Distance:	Pearson: 0.6452	Spearman: 0.6509
2023-08-02 18:31:57 - Dot-Product-Similarity:	Pearson: 0.6556	Spearman: 0.6509
2023-08-02 18:31:57 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:35:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-02 18:35:32 - Cosine-Similarity :	Pearson: 0.6779	Spearman: 0.6742
2023-08-02 18:35:32 - Manhattan-Distance:	Pearson: 0.6679	Spearman: 0.6774
2023-08-02 18:35:32 - Euclidean-Distance:	Pearson: 0.6655	Spearman: 0.6745
2023-08-02 18:35:32 - Dot-Product-Similarity:	Pearson: 0.6770	Spearman: 0.6733
2023-08-02 18:35:32 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:38:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-02 18:39:06 - Cosine-Similarity :	Pearson: 0.6867	Spearman: 0.6800
2023-08-02 18:39:06 - Manhattan-Distance:	Pearson: 0.6761	Spearman: 0.6846
2023-08-02 18:39:06 - Euclidean-Distance:	Pearson: 0.6718	Spearman: 0.6801
2023-08-02 18:39:06 - Dot-Product-Similarity:	Pearson: 0.6862	Spearman: 0.6797
2023-08-02 18:39:06 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:42:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-02 18:42:40 - Cosine-Similarity :	Pearson: 0.6963	Spearman: 0.6902
2023-08-02 18:42:40 - Manhattan-Distance:	Pearson: 0.6877	Spearman: 0.6945
2023-08-02 18:42:40 - Euclidean-Distance:	Pearson: 0.6840	Spearman: 0.6904
2023-08-02 18:42:40 - Dot-Product-Similarity:	Pearson: 0.6955	Spearman: 0.6896
2023-08-02 18:42:40 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:45:50 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-02 18:46:13 - Cosine-Similarity :	Pearson: 0.6994	Spearman: 0.6939
2023-08-02 18:46:13 - Manhattan-Distance:	Pearson: 0.6883	Spearman: 0.6976
2023-08-02 18:46:13 - Euclidean-Distance:	Pearson: 0.6850	Spearman: 0.6940
2023-08-02 18:46:13 - Dot-Product-Similarity:	Pearson: 0.6988	Spearman: 0.6934
2023-08-02 18:46:13 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:49:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-02 18:49:47 - Cosine-Similarity :	Pearson: 0.7077	Spearman: 0.7027
2023-08-02 18:49:47 - Manhattan-Distance:	Pearson: 0.6989	Spearman: 0.7069
2023-08-02 18:49:47 - Euclidean-Distance:	Pearson: 0.6951	Spearman: 0.7031
2023-08-02 18:49:47 - Dot-Product-Similarity:	Pearson: 0.7067	Spearman: 0.7016
2023-08-02 18:49:47 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:52:59 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-02 18:53:23 - Cosine-Similarity :	Pearson: 0.7125	Spearman: 0.7070
2023-08-02 18:53:23 - Manhattan-Distance:	Pearson: 0.7041	Spearman: 0.7111
2023-08-02 18:53:23 - Euclidean-Distance:	Pearson: 0.7006	Spearman: 0.7073
2023-08-02 18:53:23 - Dot-Product-Similarity:	Pearson: 0.7117	Spearman: 0.7059
2023-08-02 18:53:23 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:56:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-02 18:56:57 - Cosine-Similarity :	Pearson: 0.7214	Spearman: 0.7188
2023-08-02 18:56:57 - Manhattan-Distance:	Pearson: 0.7150	Spearman: 0.7236
2023-08-02 18:56:57 - Euclidean-Distance:	Pearson: 0.7110	Spearman: 0.7190
2023-08-02 18:56:57 - Dot-Product-Similarity:	Pearson: 0.7210	Spearman: 0.7183
2023-08-02 18:56:57 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:59:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-02 18:59:51 - Cosine-Similarity :	Pearson: 0.7244	Spearman: 0.7214
2023-08-02 18:59:51 - Manhattan-Distance:	Pearson: 0.7165	Spearman: 0.7252
2023-08-02 18:59:51 - Euclidean-Distance:	Pearson: 0.7131	Spearman: 0.7216
2023-08-02 18:59:51 - Dot-Product-Similarity:	Pearson: 0.7240	Spearman: 0.7207
2023-08-02 18:59:51 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 18:59:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-02 19:00:12 - Cosine-Similarity :	Pearson: 0.7244	Spearman: 0.7214
2023-08-02 19:00:12 - Manhattan-Distance:	Pearson: 0.7165	Spearman: 0.7252
2023-08-02 19:00:12 - Euclidean-Distance:	Pearson: 0.7131	Spearman: 0.7216
2023-08-02 19:00:12 - Dot-Product-Similarity:	Pearson: 0.7240	Spearman: 0.7207
2023-08-02 19:02:35 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-02 19:02:52 - Cosine-Similarity :	Pearson: 0.7221	Spearman: 0.7184
2023-08-02 19:02:52 - Manhattan-Distance:	Pearson: 0.7151	Spearman: 0.7233
2023-08-02 19:02:52 - Euclidean-Distance:	Pearson: 0.7109	Spearman: 0.7189
2023-08-02 19:02:52 - Dot-Product-Similarity:	Pearson: 0.7216	Spearman: 0.7177
2023-08-02 19:05:15 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-02 19:05:33 - Cosine-Similarity :	Pearson: 0.7260	Spearman: 0.7214
2023-08-02 19:05:33 - Manhattan-Distance:	Pearson: 0.7208	Spearman: 0.7259
2023-08-02 19:05:33 - Euclidean-Distance:	Pearson: 0.7167	Spearman: 0.7217
2023-08-02 19:05:33 - Dot-Product-Similarity:	Pearson: 0.7255	Spearman: 0.7207
2023-08-02 19:07:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-02 19:08:12 - Cosine-Similarity :	Pearson: 0.7296	Spearman: 0.7238
2023-08-02 19:08:12 - Manhattan-Distance:	Pearson: 0.7215	Spearman: 0.7285
2023-08-02 19:08:12 - Euclidean-Distance:	Pearson: 0.7174	Spearman: 0.7241
2023-08-02 19:08:12 - Dot-Product-Similarity:	Pearson: 0.7289	Spearman: 0.7229
2023-08-02 19:08:12 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:10:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-02 19:10:56 - Cosine-Similarity :	Pearson: 0.7308	Spearman: 0.7259
2023-08-02 19:10:56 - Manhattan-Distance:	Pearson: 0.7222	Spearman: 0.7304
2023-08-02 19:10:56 - Euclidean-Distance:	Pearson: 0.7183	Spearman: 0.7264
2023-08-02 19:10:56 - Dot-Product-Similarity:	Pearson: 0.7301	Spearman: 0.7250
2023-08-02 19:10:56 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:13:23 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-02 19:13:40 - Cosine-Similarity :	Pearson: 0.7343	Spearman: 0.7291
2023-08-02 19:13:40 - Manhattan-Distance:	Pearson: 0.7230	Spearman: 0.7334
2023-08-02 19:13:40 - Euclidean-Distance:	Pearson: 0.7190	Spearman: 0.7291
2023-08-02 19:13:40 - Dot-Product-Similarity:	Pearson: 0.7340	Spearman: 0.7288
2023-08-02 19:13:40 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:16:05 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-02 19:16:22 - Cosine-Similarity :	Pearson: 0.7349	Spearman: 0.7293
2023-08-02 19:16:22 - Manhattan-Distance:	Pearson: 0.7248	Spearman: 0.7333
2023-08-02 19:16:22 - Euclidean-Distance:	Pearson: 0.7214	Spearman: 0.7296
2023-08-02 19:16:22 - Dot-Product-Similarity:	Pearson: 0.7343	Spearman: 0.7287
2023-08-02 19:16:22 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:18:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-02 19:19:07 - Cosine-Similarity :	Pearson: 0.7357	Spearman: 0.7306
2023-08-02 19:19:07 - Manhattan-Distance:	Pearson: 0.7259	Spearman: 0.7345
2023-08-02 19:19:07 - Euclidean-Distance:	Pearson: 0.7226	Spearman: 0.7310
2023-08-02 19:19:07 - Dot-Product-Similarity:	Pearson: 0.7351	Spearman: 0.7299
2023-08-02 19:19:07 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:21:35 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-02 19:21:53 - Cosine-Similarity :	Pearson: 0.7366	Spearman: 0.7315
2023-08-02 19:21:53 - Manhattan-Distance:	Pearson: 0.7276	Spearman: 0.7358
2023-08-02 19:21:53 - Euclidean-Distance:	Pearson: 0.7237	Spearman: 0.7318
2023-08-02 19:21:53 - Dot-Product-Similarity:	Pearson: 0.7361	Spearman: 0.7309
2023-08-02 19:21:53 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:24:19 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-02 19:24:36 - Cosine-Similarity :	Pearson: 0.7366	Spearman: 0.7308
2023-08-02 19:24:36 - Manhattan-Distance:	Pearson: 0.7262	Spearman: 0.7351
2023-08-02 19:24:36 - Euclidean-Distance:	Pearson: 0.7223	Spearman: 0.7310
2023-08-02 19:24:36 - Dot-Product-Similarity:	Pearson: 0.7362	Spearman: 0.7305
2023-08-02 19:26:59 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-02 19:27:15 - Cosine-Similarity :	Pearson: 0.7376	Spearman: 0.7320
2023-08-02 19:27:15 - Manhattan-Distance:	Pearson: 0.7273	Spearman: 0.7361
2023-08-02 19:27:15 - Euclidean-Distance:	Pearson: 0.7236	Spearman: 0.7322
2023-08-02 19:27:15 - Dot-Product-Similarity:	Pearson: 0.7372	Spearman: 0.7316
2023-08-02 19:27:15 - Save model to ./outputs/simcse-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-02_18-24-10
2023-08-02 19:27:19 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-02 19:27:36 - Cosine-Similarity :	Pearson: 0.7376	Spearman: 0.7320
2023-08-02 19:27:36 - Manhattan-Distance:	Pearson: 0.7273	Spearman: 0.7361
2023-08-02 19:27:36 - Euclidean-Distance:	Pearson: 0.7236	Spearman: 0.7322
2023-08-02 19:27:36 - Dot-Product-Similarity:	Pearson: 0.7372	Spearman: 0.7316
2023-08-02 19:27:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-02 19:27:54 - Cosine-Similarity :	Pearson: 0.7320	Spearman: 0.7271
2023-08-02 19:27:54 - Manhattan-Distance:	Pearson: 0.7213	Spearman: 0.7313
2023-08-02 19:27:54 - Euclidean-Distance:	Pearson: 0.7178	Spearman: 0.7276
2023-08-02 19:27:54 - Dot-Product-Similarity:	Pearson: 0.7315	Spearman: 0.7265
2023-08-02 18:23:21 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-02 18:23:21 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  snil-sup  data is 9314
The len of  snil-sup  data is 9176
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-02 18:23:26 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-02 18:23:42 - Cosine-Similarity :	Pearson: 0.1772	Spearman: 0.1806
2023-08-02 18:23:42 - Manhattan-Distance:	Pearson: 0.1662	Spearman: 0.1665
2023-08-02 18:23:42 - Euclidean-Distance:	Pearson: 0.1628	Spearman: 0.1627
2023-08-02 18:23:42 - Dot-Product-Similarity:	Pearson: 0.1815	Spearman: 0.1776
2023-08-02 18:26:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-02 18:27:12 - Cosine-Similarity :	Pearson: 0.6226	Spearman: 0.6305
2023-08-02 18:27:12 - Manhattan-Distance:	Pearson: 0.6078	Spearman: 0.6245
2023-08-02 18:27:12 - Euclidean-Distance:	Pearson: 0.6057	Spearman: 0.6220
2023-08-02 18:27:12 - Dot-Product-Similarity:	Pearson: 0.6249	Spearman: 0.6337
2023-08-02 18:27:12 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:30:57 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-02 18:31:21 - Cosine-Similarity :	Pearson: 0.6619	Spearman: 0.6703
2023-08-02 18:31:21 - Manhattan-Distance:	Pearson: 0.6482	Spearman: 0.6672
2023-08-02 18:31:21 - Euclidean-Distance:	Pearson: 0.6431	Spearman: 0.6622
2023-08-02 18:31:21 - Dot-Product-Similarity:	Pearson: 0.6608	Spearman: 0.6697
2023-08-02 18:31:21 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:35:06 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-02 18:35:30 - Cosine-Similarity :	Pearson: 0.6720	Spearman: 0.6879
2023-08-02 18:35:30 - Manhattan-Distance:	Pearson: 0.6673	Spearman: 0.6867
2023-08-02 18:35:30 - Euclidean-Distance:	Pearson: 0.6624	Spearman: 0.6819
2023-08-02 18:35:30 - Dot-Product-Similarity:	Pearson: 0.6726	Spearman: 0.6877
2023-08-02 18:35:30 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:39:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-02 18:39:38 - Cosine-Similarity :	Pearson: 0.6852	Spearman: 0.6957
2023-08-02 18:39:38 - Manhattan-Distance:	Pearson: 0.6738	Spearman: 0.6915
2023-08-02 18:39:38 - Euclidean-Distance:	Pearson: 0.6702	Spearman: 0.6880
2023-08-02 18:39:38 - Dot-Product-Similarity:	Pearson: 0.6881	Spearman: 0.7008
2023-08-02 18:39:38 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:43:22 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-02 18:43:44 - Cosine-Similarity :	Pearson: 0.6939	Spearman: 0.7044
2023-08-02 18:43:44 - Manhattan-Distance:	Pearson: 0.6814	Spearman: 0.7013
2023-08-02 18:43:44 - Euclidean-Distance:	Pearson: 0.6776	Spearman: 0.6977
2023-08-02 18:43:44 - Dot-Product-Similarity:	Pearson: 0.7001	Spearman: 0.7123
2023-08-02 18:43:44 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:47:28 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-02 18:47:52 - Cosine-Similarity :	Pearson: 0.6983	Spearman: 0.7095
2023-08-02 18:47:52 - Manhattan-Distance:	Pearson: 0.6832	Spearman: 0.7050
2023-08-02 18:47:52 - Euclidean-Distance:	Pearson: 0.6793	Spearman: 0.7012
2023-08-02 18:47:52 - Dot-Product-Similarity:	Pearson: 0.7060	Spearman: 0.7188
2023-08-02 18:47:52 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:51:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-02 18:52:00 - Cosine-Similarity :	Pearson: 0.6975	Spearman: 0.7122
2023-08-02 18:52:00 - Manhattan-Distance:	Pearson: 0.6890	Spearman: 0.7092
2023-08-02 18:52:00 - Euclidean-Distance:	Pearson: 0.6850	Spearman: 0.7052
2023-08-02 18:52:00 - Dot-Product-Similarity:	Pearson: 0.7028	Spearman: 0.7186
2023-08-02 18:52:00 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:55:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-02 18:56:07 - Cosine-Similarity :	Pearson: 0.6973	Spearman: 0.7158
2023-08-02 18:56:07 - Manhattan-Distance:	Pearson: 0.6946	Spearman: 0.7142
2023-08-02 18:56:07 - Euclidean-Distance:	Pearson: 0.6909	Spearman: 0.7108
2023-08-02 18:56:07 - Dot-Product-Similarity:	Pearson: 0.7007	Spearman: 0.7197
2023-08-02 18:56:07 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 18:59:15 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-02 18:59:33 - Cosine-Similarity :	Pearson: 0.6990	Spearman: 0.7171
2023-08-02 18:59:33 - Manhattan-Distance:	Pearson: 0.6929	Spearman: 0.7134
2023-08-02 18:59:33 - Euclidean-Distance:	Pearson: 0.6898	Spearman: 0.7107
2023-08-02 18:59:33 - Dot-Product-Similarity:	Pearson: 0.7065	Spearman: 0.7258
2023-08-02 18:59:33 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:02:15 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-02 19:02:34 - Cosine-Similarity :	Pearson: 0.7024	Spearman: 0.7196
2023-08-02 19:02:34 - Manhattan-Distance:	Pearson: 0.6967	Spearman: 0.7161
2023-08-02 19:02:34 - Euclidean-Distance:	Pearson: 0.6936	Spearman: 0.7134
2023-08-02 19:02:34 - Dot-Product-Similarity:	Pearson: 0.7112	Spearman: 0.7307
2023-08-02 19:02:34 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:02:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-02 19:02:55 - Cosine-Similarity :	Pearson: 0.7024	Spearman: 0.7196
2023-08-02 19:02:55 - Manhattan-Distance:	Pearson: 0.6967	Spearman: 0.7161
2023-08-02 19:02:55 - Euclidean-Distance:	Pearson: 0.6936	Spearman: 0.7134
2023-08-02 19:02:55 - Dot-Product-Similarity:	Pearson: 0.7112	Spearman: 0.7307
2023-08-02 19:05:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-02 19:05:54 - Cosine-Similarity :	Pearson: 0.7087	Spearman: 0.7249
2023-08-02 19:05:54 - Manhattan-Distance:	Pearson: 0.7008	Spearman: 0.7216
2023-08-02 19:05:54 - Euclidean-Distance:	Pearson: 0.6973	Spearman: 0.7185
2023-08-02 19:05:54 - Dot-Product-Similarity:	Pearson: 0.7132	Spearman: 0.7307
2023-08-02 19:05:54 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:08:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-02 19:08:56 - Cosine-Similarity :	Pearson: 0.7115	Spearman: 0.7252
2023-08-02 19:08:56 - Manhattan-Distance:	Pearson: 0.7014	Spearman: 0.7214
2023-08-02 19:08:56 - Euclidean-Distance:	Pearson: 0.6984	Spearman: 0.7187
2023-08-02 19:08:56 - Dot-Product-Similarity:	Pearson: 0.7161	Spearman: 0.7316
2023-08-02 19:08:56 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:11:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-02 19:11:57 - Cosine-Similarity :	Pearson: 0.7088	Spearman: 0.7283
2023-08-02 19:11:57 - Manhattan-Distance:	Pearson: 0.7031	Spearman: 0.7238
2023-08-02 19:11:57 - Euclidean-Distance:	Pearson: 0.6995	Spearman: 0.7207
2023-08-02 19:11:57 - Dot-Product-Similarity:	Pearson: 0.7117	Spearman: 0.7318
2023-08-02 19:11:57 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:14:42 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-02 19:15:01 - Cosine-Similarity :	Pearson: 0.7139	Spearman: 0.7306
2023-08-02 19:15:01 - Manhattan-Distance:	Pearson: 0.7071	Spearman: 0.7278
2023-08-02 19:15:01 - Euclidean-Distance:	Pearson: 0.7044	Spearman: 0.7255
2023-08-02 19:15:01 - Dot-Product-Similarity:	Pearson: 0.7139	Spearman: 0.7308
2023-08-02 19:15:01 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:17:44 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-02 19:18:02 - Cosine-Similarity :	Pearson: 0.7156	Spearman: 0.7306
2023-08-02 19:18:02 - Manhattan-Distance:	Pearson: 0.7075	Spearman: 0.7270
2023-08-02 19:18:02 - Euclidean-Distance:	Pearson: 0.7049	Spearman: 0.7248
2023-08-02 19:18:02 - Dot-Product-Similarity:	Pearson: 0.7197	Spearman: 0.7353
2023-08-02 19:20:42 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-02 19:21:00 - Cosine-Similarity :	Pearson: 0.7153	Spearman: 0.7305
2023-08-02 19:21:00 - Manhattan-Distance:	Pearson: 0.7055	Spearman: 0.7273
2023-08-02 19:21:00 - Euclidean-Distance:	Pearson: 0.7023	Spearman: 0.7245
2023-08-02 19:21:00 - Dot-Product-Similarity:	Pearson: 0.7175	Spearman: 0.7338
2023-08-02 19:23:40 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-02 19:23:58 - Cosine-Similarity :	Pearson: 0.7170	Spearman: 0.7311
2023-08-02 19:23:58 - Manhattan-Distance:	Pearson: 0.7063	Spearman: 0.7274
2023-08-02 19:23:58 - Euclidean-Distance:	Pearson: 0.7039	Spearman: 0.7253
2023-08-02 19:23:58 - Dot-Product-Similarity:	Pearson: 0.7200	Spearman: 0.7355
2023-08-02 19:23:58 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:26:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-02 19:27:01 - Cosine-Similarity :	Pearson: 0.7185	Spearman: 0.7337
2023-08-02 19:27:01 - Manhattan-Distance:	Pearson: 0.7092	Spearman: 0.7306
2023-08-02 19:27:01 - Euclidean-Distance:	Pearson: 0.7060	Spearman: 0.7278
2023-08-02 19:27:01 - Dot-Product-Similarity:	Pearson: 0.7189	Spearman: 0.7351
2023-08-02 19:27:02 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:29:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-02 19:29:22 - Cosine-Similarity :	Pearson: 0.7202	Spearman: 0.7353
2023-08-02 19:29:22 - Manhattan-Distance:	Pearson: 0.7104	Spearman: 0.7316
2023-08-02 19:29:22 - Euclidean-Distance:	Pearson: 0.7076	Spearman: 0.7291
2023-08-02 19:29:22 - Dot-Product-Similarity:	Pearson: 0.7225	Spearman: 0.7386
2023-08-02 19:29:22 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:31:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-02 19:31:29 - Cosine-Similarity :	Pearson: 0.7201	Spearman: 0.7354
2023-08-02 19:31:29 - Manhattan-Distance:	Pearson: 0.7107	Spearman: 0.7316
2023-08-02 19:31:29 - Euclidean-Distance:	Pearson: 0.7079	Spearman: 0.7292
2023-08-02 19:31:29 - Dot-Product-Similarity:	Pearson: 0.7224	Spearman: 0.7386
2023-08-02 19:31:29 - Save model to ./outputs/sbert-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-14
2023-08-02 19:31:32 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-02 19:31:45 - Cosine-Similarity :	Pearson: 0.7201	Spearman: 0.7354
2023-08-02 19:31:45 - Manhattan-Distance:	Pearson: 0.7107	Spearman: 0.7316
2023-08-02 19:31:45 - Euclidean-Distance:	Pearson: 0.7079	Spearman: 0.7292
2023-08-02 19:31:45 - Dot-Product-Similarity:	Pearson: 0.7224	Spearman: 0.7386
2023-08-02 19:31:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-02 19:31:57 - Cosine-Similarity :	Pearson: 0.7146	Spearman: 0.7312
2023-08-02 19:31:57 - Manhattan-Distance:	Pearson: 0.7070	Spearman: 0.7284
2023-08-02 19:31:57 - Euclidean-Distance:	Pearson: 0.7043	Spearman: 0.7261
2023-08-02 19:31:57 - Dot-Product-Similarity:	Pearson: 0.7155	Spearman: 0.7332
The len of  snil-sup  data is 545859
The len of  snil-sup  data is 9314
The len of  snil-sup  data is 9176
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-02 18:24:12 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-02 18:24:38 - Cosine-Similarity :	Pearson: 0.1110	Spearman: 0.1138
2023-08-02 18:24:38 - Manhattan-Distance:	Pearson: 0.1158	Spearman: 0.1134
2023-08-02 18:24:38 - Euclidean-Distance:	Pearson: 0.1146	Spearman: 0.1122
2023-08-02 18:24:38 - Dot-Product-Similarity:	Pearson: 0.1240	Spearman: 0.1285
2023-08-02 18:28:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-02 18:28:38 - Cosine-Similarity :	Pearson: 0.6168	Spearman: 0.6218
2023-08-02 18:28:38 - Manhattan-Distance:	Pearson: 0.6107	Spearman: 0.6239
2023-08-02 18:28:38 - Euclidean-Distance:	Pearson: 0.6097	Spearman: 0.6228
2023-08-02 18:28:38 - Dot-Product-Similarity:	Pearson: 0.6090	Spearman: 0.6129
2023-08-02 18:28:38 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:32:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-02 18:32:48 - Cosine-Similarity :	Pearson: 0.6448	Spearman: 0.6529
2023-08-02 18:32:48 - Manhattan-Distance:	Pearson: 0.6430	Spearman: 0.6555
2023-08-02 18:32:48 - Euclidean-Distance:	Pearson: 0.6413	Spearman: 0.6538
2023-08-02 18:32:48 - Dot-Product-Similarity:	Pearson: 0.6383	Spearman: 0.6440
2023-08-02 18:32:48 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:36:31 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-02 18:36:54 - Cosine-Similarity :	Pearson: 0.6597	Spearman: 0.6726
2023-08-02 18:36:54 - Manhattan-Distance:	Pearson: 0.6647	Spearman: 0.6747
2023-08-02 18:36:54 - Euclidean-Distance:	Pearson: 0.6632	Spearman: 0.6733
2023-08-02 18:36:54 - Dot-Product-Similarity:	Pearson: 0.6550	Spearman: 0.6658
2023-08-02 18:36:54 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:40:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-02 18:41:01 - Cosine-Similarity :	Pearson: 0.6726	Spearman: 0.6880
2023-08-02 18:41:01 - Manhattan-Distance:	Pearson: 0.6750	Spearman: 0.6892
2023-08-02 18:41:01 - Euclidean-Distance:	Pearson: 0.6734	Spearman: 0.6880
2023-08-02 18:41:01 - Dot-Product-Similarity:	Pearson: 0.6707	Spearman: 0.6857
2023-08-02 18:41:01 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:44:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-02 18:45:09 - Cosine-Similarity :	Pearson: 0.6859	Spearman: 0.6927
2023-08-02 18:45:09 - Manhattan-Distance:	Pearson: 0.6841	Spearman: 0.6953
2023-08-02 18:45:09 - Euclidean-Distance:	Pearson: 0.6815	Spearman: 0.6930
2023-08-02 18:45:09 - Dot-Product-Similarity:	Pearson: 0.6826	Spearman: 0.6886
2023-08-02 18:45:09 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:48:53 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-02 18:49:17 - Cosine-Similarity :	Pearson: 0.6868	Spearman: 0.6997
2023-08-02 18:49:17 - Manhattan-Distance:	Pearson: 0.6872	Spearman: 0.7005
2023-08-02 18:49:17 - Euclidean-Distance:	Pearson: 0.6859	Spearman: 0.6994
2023-08-02 18:49:17 - Dot-Product-Similarity:	Pearson: 0.6856	Spearman: 0.6982
2023-08-02 18:49:17 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:53:00 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-02 18:53:23 - Cosine-Similarity :	Pearson: 0.6949	Spearman: 0.7081
2023-08-02 18:53:23 - Manhattan-Distance:	Pearson: 0.6966	Spearman: 0.7087
2023-08-02 18:53:23 - Euclidean-Distance:	Pearson: 0.6952	Spearman: 0.7076
2023-08-02 18:53:23 - Dot-Product-Similarity:	Pearson: 0.6957	Spearman: 0.7089
2023-08-02 18:53:23 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 18:57:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-02 18:57:30 - Cosine-Similarity :	Pearson: 0.6980	Spearman: 0.7095
2023-08-02 18:57:30 - Manhattan-Distance:	Pearson: 0.6983	Spearman: 0.7110
2023-08-02 18:57:30 - Euclidean-Distance:	Pearson: 0.6964	Spearman: 0.7093
2023-08-02 18:57:30 - Dot-Product-Similarity:	Pearson: 0.6970	Spearman: 0.7083
2023-08-02 18:57:30 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:00:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-02 19:00:32 - Cosine-Similarity :	Pearson: 0.6965	Spearman: 0.7096
2023-08-02 19:00:32 - Manhattan-Distance:	Pearson: 0.6959	Spearman: 0.7100
2023-08-02 19:00:32 - Euclidean-Distance:	Pearson: 0.6944	Spearman: 0.7088
2023-08-02 19:00:32 - Dot-Product-Similarity:	Pearson: 0.6982	Spearman: 0.7120
2023-08-02 19:00:32 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:03:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-02 19:03:35 - Cosine-Similarity :	Pearson: 0.7049	Spearman: 0.7153
2023-08-02 19:03:35 - Manhattan-Distance:	Pearson: 0.7013	Spearman: 0.7157
2023-08-02 19:03:35 - Euclidean-Distance:	Pearson: 0.6999	Spearman: 0.7145
2023-08-02 19:03:35 - Dot-Product-Similarity:	Pearson: 0.7062	Spearman: 0.7178
2023-08-02 19:03:35 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:03:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-02 19:03:57 - Cosine-Similarity :	Pearson: 0.7049	Spearman: 0.7153
2023-08-02 19:03:57 - Manhattan-Distance:	Pearson: 0.7013	Spearman: 0.7157
2023-08-02 19:03:57 - Euclidean-Distance:	Pearson: 0.6999	Spearman: 0.7145
2023-08-02 19:03:57 - Dot-Product-Similarity:	Pearson: 0.7062	Spearman: 0.7178
2023-08-02 19:06:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-02 19:06:55 - Cosine-Similarity :	Pearson: 0.7046	Spearman: 0.7160
2023-08-02 19:06:55 - Manhattan-Distance:	Pearson: 0.7029	Spearman: 0.7170
2023-08-02 19:06:55 - Euclidean-Distance:	Pearson: 0.7011	Spearman: 0.7155
2023-08-02 19:06:55 - Dot-Product-Similarity:	Pearson: 0.7045	Spearman: 0.7168
2023-08-02 19:06:55 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:09:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-02 19:09:57 - Cosine-Similarity :	Pearson: 0.7015	Spearman: 0.7181
2023-08-02 19:09:57 - Manhattan-Distance:	Pearson: 0.7025	Spearman: 0.7193
2023-08-02 19:09:57 - Euclidean-Distance:	Pearson: 0.7005	Spearman: 0.7177
2023-08-02 19:09:57 - Dot-Product-Similarity:	Pearson: 0.7009	Spearman: 0.7180
2023-08-02 19:09:57 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:12:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-02 19:12:57 - Cosine-Similarity :	Pearson: 0.7053	Spearman: 0.7181
2023-08-02 19:12:57 - Manhattan-Distance:	Pearson: 0.7038	Spearman: 0.7186
2023-08-02 19:12:57 - Euclidean-Distance:	Pearson: 0.7023	Spearman: 0.7173
2023-08-02 19:12:57 - Dot-Product-Similarity:	Pearson: 0.7069	Spearman: 0.7203
2023-08-02 19:15:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-02 19:15:55 - Cosine-Similarity :	Pearson: 0.7049	Spearman: 0.7198
2023-08-02 19:15:55 - Manhattan-Distance:	Pearson: 0.7062	Spearman: 0.7210
2023-08-02 19:15:55 - Euclidean-Distance:	Pearson: 0.7040	Spearman: 0.7191
2023-08-02 19:15:55 - Dot-Product-Similarity:	Pearson: 0.7061	Spearman: 0.7212
2023-08-02 19:15:55 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:18:40 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-02 19:18:58 - Cosine-Similarity :	Pearson: 0.7099	Spearman: 0.7236
2023-08-02 19:18:58 - Manhattan-Distance:	Pearson: 0.7076	Spearman: 0.7243
2023-08-02 19:18:58 - Euclidean-Distance:	Pearson: 0.7057	Spearman: 0.7229
2023-08-02 19:18:58 - Dot-Product-Similarity:	Pearson: 0.7110	Spearman: 0.7250
2023-08-02 19:18:58 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:21:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-02 19:21:58 - Cosine-Similarity :	Pearson: 0.7114	Spearman: 0.7244
2023-08-02 19:21:58 - Manhattan-Distance:	Pearson: 0.7096	Spearman: 0.7252
2023-08-02 19:21:58 - Euclidean-Distance:	Pearson: 0.7079	Spearman: 0.7238
2023-08-02 19:21:58 - Dot-Product-Similarity:	Pearson: 0.7120	Spearman: 0.7254
2023-08-02 19:21:58 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:24:44 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-02 19:25:02 - Cosine-Similarity :	Pearson: 0.7120	Spearman: 0.7260
2023-08-02 19:25:02 - Manhattan-Distance:	Pearson: 0.7124	Spearman: 0.7270
2023-08-02 19:25:02 - Euclidean-Distance:	Pearson: 0.7106	Spearman: 0.7255
2023-08-02 19:25:02 - Dot-Product-Similarity:	Pearson: 0.7124	Spearman: 0.7269
2023-08-02 19:25:02 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:27:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-02 19:28:00 - Cosine-Similarity :	Pearson: 0.7132	Spearman: 0.7280
2023-08-02 19:28:00 - Manhattan-Distance:	Pearson: 0.7129	Spearman: 0.7285
2023-08-02 19:28:00 - Euclidean-Distance:	Pearson: 0.7114	Spearman: 0.7274
2023-08-02 19:28:00 - Dot-Product-Similarity:	Pearson: 0.7139	Spearman: 0.7290
2023-08-02 19:28:00 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:29:56 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-02 19:30:08 - Cosine-Similarity :	Pearson: 0.7127	Spearman: 0.7281
2023-08-02 19:30:08 - Manhattan-Distance:	Pearson: 0.7128	Spearman: 0.7288
2023-08-02 19:30:08 - Euclidean-Distance:	Pearson: 0.7110	Spearman: 0.7275
2023-08-02 19:30:08 - Dot-Product-Similarity:	Pearson: 0.7134	Spearman: 0.7290
2023-08-02 19:30:08 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:32:02 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-02 19:32:10 - Cosine-Similarity :	Pearson: 0.7141	Spearman: 0.7287
2023-08-02 19:32:10 - Manhattan-Distance:	Pearson: 0.7133	Spearman: 0.7294
2023-08-02 19:32:10 - Euclidean-Distance:	Pearson: 0.7115	Spearman: 0.7280
2023-08-02 19:32:10 - Dot-Product-Similarity:	Pearson: 0.7149	Spearman: 0.7297
2023-08-02 19:32:10 - Save model to ./outputs/simcse-snli-sup-macbert-2-OnlineContrastiveLoss-2023-08-02_18-23-59
2023-08-02 19:32:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-02 19:32:22 - Cosine-Similarity :	Pearson: 0.7141	Spearman: 0.7287
2023-08-02 19:32:22 - Manhattan-Distance:	Pearson: 0.7133	Spearman: 0.7294
2023-08-02 19:32:22 - Euclidean-Distance:	Pearson: 0.7115	Spearman: 0.7280
2023-08-02 19:32:22 - Dot-Product-Similarity:	Pearson: 0.7149	Spearman: 0.7297
2023-08-02 19:32:22 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-02 19:32:31 - Cosine-Similarity :	Pearson: 0.7051	Spearman: 0.7202
2023-08-02 19:32:31 - Manhattan-Distance:	Pearson: 0.7053	Spearman: 0.7210
2023-08-02 19:32:31 - Euclidean-Distance:	Pearson: 0.7039	Spearman: 0.7198
2023-08-02 19:32:31 - Dot-Product-Similarity:	Pearson: 0.7048	Spearman: 0.7198
[2023-08-03 10:11:18,242] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 10:12:02,371] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 10:11:24 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:11:24 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 10462
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 10462
Warmup-steps: 33
Performance before training
2023-08-03 10:11:25 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset:
2023-08-03 10:11:29 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:11:29 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:11:29 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:11:29 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:11:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 16 steps:
2023-08-03 10:11:32 - Cosine-Similarity :	Pearson: 0.6624	Spearman: 0.6767
2023-08-03 10:11:32 - Manhattan-Distance:	Pearson: 0.6616	Spearman: 0.6794
2023-08-03 10:11:32 - Euclidean-Distance:	Pearson: 0.6547	Spearman: 0.6733
2023-08-03 10:11:32 - Dot-Product-Similarity:	Pearson: 0.4998	Spearman: 0.5154
2023-08-03 10:11:32 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:11:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 32 steps:
2023-08-03 10:11:43 - Cosine-Similarity :	Pearson: 0.7254	Spearman: 0.7289
2023-08-03 10:11:43 - Manhattan-Distance:	Pearson: 0.7078	Spearman: 0.7235
2023-08-03 10:11:43 - Euclidean-Distance:	Pearson: 0.7037	Spearman: 0.7195
2023-08-03 10:11:43 - Dot-Product-Similarity:	Pearson: 0.6839	Spearman: 0.6889
2023-08-03 10:11:43 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:11:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 48 steps:
2023-08-03 10:11:50 - Cosine-Similarity :	Pearson: 0.7404	Spearman: 0.7439
2023-08-03 10:11:50 - Manhattan-Distance:	Pearson: 0.7138	Spearman: 0.7314
2023-08-03 10:11:50 - Euclidean-Distance:	Pearson: 0.7109	Spearman: 0.7277
2023-08-03 10:11:50 - Dot-Product-Similarity:	Pearson: 0.7061	Spearman: 0.7126
2023-08-03 10:11:50 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:11:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 64 steps:
2023-08-03 10:11:56 - Cosine-Similarity :	Pearson: 0.7451	Spearman: 0.7485
2023-08-03 10:11:56 - Manhattan-Distance:	Pearson: 0.7168	Spearman: 0.7346
2023-08-03 10:11:56 - Euclidean-Distance:	Pearson: 0.7136	Spearman: 0.7308
2023-08-03 10:11:56 - Dot-Product-Similarity:	Pearson: 0.7192	Spearman: 0.7261
2023-08-03 10:11:56 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:12:02 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 80 steps:
2023-08-03 10:12:03 - Cosine-Similarity :	Pearson: 0.7425	Spearman: 0.7464
2023-08-03 10:12:03 - Manhattan-Distance:	Pearson: 0.7154	Spearman: 0.7335
2023-08-03 10:12:03 - Euclidean-Distance:	Pearson: 0.7124	Spearman: 0.7301
2023-08-03 10:12:03 - Dot-Product-Similarity:	Pearson: 0.7175	Spearman: 0.7249
2023-08-03 10:12:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 96 steps:
2023-08-03 10:12:07 - Cosine-Similarity :	Pearson: 0.7508	Spearman: 0.7553
2023-08-03 10:12:07 - Manhattan-Distance:	Pearson: 0.7215	Spearman: 0.7405
2023-08-03 10:12:07 - Euclidean-Distance:	Pearson: 0.7190	Spearman: 0.7377
2023-08-03 10:12:07 - Dot-Product-Similarity:	Pearson: 0.7235	Spearman: 0.7318
2023-08-03 10:12:07 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:12:12 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 112 steps:
2023-08-03 10:12:13 - Cosine-Similarity :	Pearson: 0.7517	Spearman: 0.7567
2023-08-03 10:12:13 - Manhattan-Distance:	Pearson: 0.7191	Spearman: 0.7389
2023-08-03 10:12:13 - Euclidean-Distance:	Pearson: 0.7164	Spearman: 0.7357
2023-08-03 10:12:13 - Dot-Product-Similarity:	Pearson: 0.7230	Spearman: 0.7326
2023-08-03 10:12:13 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:12:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 128 steps:
2023-08-03 10:12:22 - Cosine-Similarity :	Pearson: 0.7497	Spearman: 0.7545
2023-08-03 10:12:22 - Manhattan-Distance:	Pearson: 0.7160	Spearman: 0.7357
2023-08-03 10:12:22 - Euclidean-Distance:	Pearson: 0.7132	Spearman: 0.7327
2023-08-03 10:12:22 - Dot-Product-Similarity:	Pearson: 0.7197	Spearman: 0.7302
2023-08-03 10:12:24 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 144 steps:
2023-08-03 10:12:27 - Cosine-Similarity :	Pearson: 0.7486	Spearman: 0.7531
2023-08-03 10:12:27 - Manhattan-Distance:	Pearson: 0.7155	Spearman: 0.7348
2023-08-03 10:12:27 - Euclidean-Distance:	Pearson: 0.7124	Spearman: 0.7314
2023-08-03 10:12:27 - Dot-Product-Similarity:	Pearson: 0.7186	Spearman: 0.7294
2023-08-03 10:12:29 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 160 steps:
2023-08-03 10:12:31 - Cosine-Similarity :	Pearson: 0.7473	Spearman: 0.7516
2023-08-03 10:12:31 - Manhattan-Distance:	Pearson: 0.7142	Spearman: 0.7334
2023-08-03 10:12:31 - Euclidean-Distance:	Pearson: 0.7108	Spearman: 0.7297
2023-08-03 10:12:31 - Dot-Product-Similarity:	Pearson: 0.7180	Spearman: 0.7281
2023-08-03 10:12:32 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 0:
2023-08-03 10:12:34 - Cosine-Similarity :	Pearson: 0.7466	Spearman: 0.7508
2023-08-03 10:12:34 - Manhattan-Distance:	Pearson: 0.7134	Spearman: 0.7325
2023-08-03 10:12:34 - Euclidean-Distance:	Pearson: 0.7100	Spearman: 0.7291
2023-08-03 10:12:34 - Dot-Product-Similarity:	Pearson: 0.7172	Spearman: 0.7270
2023-08-03 10:12:37 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 16 steps:
2023-08-03 10:12:39 - Cosine-Similarity :	Pearson: 0.7489	Spearman: 0.7530
2023-08-03 10:12:39 - Manhattan-Distance:	Pearson: 0.7155	Spearman: 0.7351
2023-08-03 10:12:39 - Euclidean-Distance:	Pearson: 0.7124	Spearman: 0.7318
2023-08-03 10:12:39 - Dot-Product-Similarity:	Pearson: 0.7178	Spearman: 0.7274
2023-08-03 10:12:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 32 steps:
2023-08-03 10:12:44 - Cosine-Similarity :	Pearson: 0.7527	Spearman: 0.7566
2023-08-03 10:12:44 - Manhattan-Distance:	Pearson: 0.7178	Spearman: 0.7373
2023-08-03 10:12:44 - Euclidean-Distance:	Pearson: 0.7152	Spearman: 0.7346
2023-08-03 10:12:44 - Dot-Product-Similarity:	Pearson: 0.7222	Spearman: 0.7316
2023-08-03 10:12:47 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 48 steps:
2023-08-03 10:12:49 - Cosine-Similarity :	Pearson: 0.7530	Spearman: 0.7568
2023-08-03 10:12:49 - Manhattan-Distance:	Pearson: 0.7184	Spearman: 0.7376
2023-08-03 10:12:49 - Euclidean-Distance:	Pearson: 0.7157	Spearman: 0.7344
2023-08-03 10:12:49 - Dot-Product-Similarity:	Pearson: 0.7212	Spearman: 0.7300
2023-08-03 10:12:49 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:12:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 64 steps:
2023-08-03 10:12:57 - Cosine-Similarity :	Pearson: 0.7534	Spearman: 0.7572
2023-08-03 10:12:57 - Manhattan-Distance:	Pearson: 0.7189	Spearman: 0.7381
2023-08-03 10:12:57 - Euclidean-Distance:	Pearson: 0.7161	Spearman: 0.7350
2023-08-03 10:12:57 - Dot-Product-Similarity:	Pearson: 0.7216	Spearman: 0.7302
2023-08-03 10:12:57 - Save model to ./outputs/sbert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-11-16
2023-08-03 10:13:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 80 steps:
2023-08-03 10:13:05 - Cosine-Similarity :	Pearson: 0.7510	Spearman: 0.7550
2023-08-03 10:13:05 - Manhattan-Distance:	Pearson: 0.7171	Spearman: 0.7361
2023-08-03 10:13:05 - Euclidean-Distance:	Pearson: 0.7142	Spearman: 0.7332
2023-08-03 10:13:05 - Dot-Product-Similarity:	Pearson: 0.7197	Spearman: 0.7288
2023-08-03 10:13:08 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 96 steps:
2023-08-03 10:13:10 - Cosine-Similarity :	Pearson: 0.7516	Spearman: 0.7558
2023-08-03 10:13:10 - Manhattan-Distance:	Pearson: 0.7177	Spearman: 0.7368
2023-08-03 10:13:10 - Euclidean-Distance:	Pearson: 0.7148	Spearman: 0.7339
2023-08-03 10:13:10 - Dot-Product-Similarity:	Pearson: 0.7208	Spearman: 0.7300
2023-08-03 10:13:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 112 steps:
2023-08-03 10:13:15 - Cosine-Similarity :	Pearson: 0.7522	Spearman: 0.7561
2023-08-03 10:13:15 - Manhattan-Distance:	Pearson: 0.7182	Spearman: 0.7378
2023-08-03 10:13:15 - Euclidean-Distance:	Pearson: 0.7155	Spearman: 0.7347
2023-08-03 10:13:15 - Dot-Product-Similarity:	Pearson: 0.7218	Spearman: 0.7309
2023-08-03 10:13:18 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 128 steps:
2023-08-03 10:13:20 - Cosine-Similarity :	Pearson: 0.7524	Spearman: 0.7562
2023-08-03 10:13:20 - Manhattan-Distance:	Pearson: 0.7181	Spearman: 0.7378
2023-08-03 10:13:20 - Euclidean-Distance:	Pearson: 0.7155	Spearman: 0.7347
2023-08-03 10:13:20 - Dot-Product-Similarity:	Pearson: 0.7222	Spearman: 0.7316
2023-08-03 10:13:23 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 144 steps:
2023-08-03 10:13:25 - Cosine-Similarity :	Pearson: 0.7525	Spearman: 0.7565
2023-08-03 10:13:25 - Manhattan-Distance:	Pearson: 0.7188	Spearman: 0.7388
2023-08-03 10:13:25 - Euclidean-Distance:	Pearson: 0.7163	Spearman: 0.7354
2023-08-03 10:13:25 - Dot-Product-Similarity:	Pearson: 0.7223	Spearman: 0.7315
2023-08-03 10:13:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 160 steps:
2023-08-03 10:13:30 - Cosine-Similarity :	Pearson: 0.7528	Spearman: 0.7568
2023-08-03 10:13:30 - Manhattan-Distance:	Pearson: 0.7193	Spearman: 0.7391
2023-08-03 10:13:30 - Euclidean-Distance:	Pearson: 0.7167	Spearman: 0.7357
2023-08-03 10:13:30 - Dot-Product-Similarity:	Pearson: 0.7225	Spearman: 0.7315
2023-08-03 10:13:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 1:
2023-08-03 10:13:33 - Cosine-Similarity :	Pearson: 0.7528	Spearman: 0.7568
2023-08-03 10:13:33 - Manhattan-Distance:	Pearson: 0.7193	Spearman: 0.7391
2023-08-03 10:13:33 - Euclidean-Distance:	Pearson: 0.7167	Spearman: 0.7357
2023-08-03 10:13:33 - Dot-Product-Similarity:	Pearson: 0.7225	Spearman: 0.7316
2023-08-03 10:13:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-test dataset:
2023-08-03 10:13:35 - Cosine-Similarity :	Pearson: 0.7169	Spearman: 0.7085
2023-08-03 10:13:35 - Manhattan-Distance:	Pearson: 0.6866	Spearman: 0.6861
2023-08-03 10:13:35 - Euclidean-Distance:	Pearson: 0.6845	Spearman: 0.6840
2023-08-03 10:13:35 - Dot-Product-Similarity:	Pearson: 0.6912	Spearman: 0.6836
Traceback (most recent call last):
  File "/data/yf_center/Embeddings_demo/main_train.py", line 1, in <module>
    from models import *
  File "/data/yf_center/Embeddings_demo/models.py", line 10, in <module>
    from config import *
  File "/data/yf_center/Embeddings_demo/config.py", line 88, in <module>
    raise Exception("Unkown LOSS_FUNCTION :( ")
Exception: Unkown LOSS_FUNCTION :( 
[2023-08-03 10:20:48,429] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
The len of sts-unsup data is 10462
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 10462
Warmup-steps: 33
Performance before training
2023-08-03 10:20:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset:
2023-08-03 10:21:00 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 10:21:00 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 10:21:00 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 10:21:00 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 10:21:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 16 steps:
2023-08-03 10:21:05 - Cosine-Similarity :	Pearson: 0.5103	Spearman: 0.5237
2023-08-03 10:21:05 - Manhattan-Distance:	Pearson: 0.5107	Spearman: 0.5235
2023-08-03 10:21:05 - Euclidean-Distance:	Pearson: 0.5067	Spearman: 0.5200
2023-08-03 10:21:05 - Dot-Product-Similarity:	Pearson: 0.5041	Spearman: 0.5202
2023-08-03 10:21:05 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:21:14 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 32 steps:
2023-08-03 10:21:17 - Cosine-Similarity :	Pearson: 0.7097	Spearman: 0.7119
2023-08-03 10:21:17 - Manhattan-Distance:	Pearson: 0.6864	Spearman: 0.7129
2023-08-03 10:21:17 - Euclidean-Distance:	Pearson: 0.6863	Spearman: 0.7124
2023-08-03 10:21:17 - Dot-Product-Similarity:	Pearson: 0.7016	Spearman: 0.7058
2023-08-03 10:21:17 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:21:23 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 48 steps:
2023-08-03 10:21:25 - Cosine-Similarity :	Pearson: 0.7385	Spearman: 0.7399
2023-08-03 10:21:25 - Manhattan-Distance:	Pearson: 0.7184	Spearman: 0.7405
2023-08-03 10:21:25 - Euclidean-Distance:	Pearson: 0.7184	Spearman: 0.7404
2023-08-03 10:21:25 - Dot-Product-Similarity:	Pearson: 0.7313	Spearman: 0.7340
2023-08-03 10:21:25 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:21:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 64 steps:
2023-08-03 10:21:34 - Cosine-Similarity :	Pearson: 0.7371	Spearman: 0.7393
2023-08-03 10:21:34 - Manhattan-Distance:	Pearson: 0.7177	Spearman: 0.7403
2023-08-03 10:21:34 - Euclidean-Distance:	Pearson: 0.7176	Spearman: 0.7402
2023-08-03 10:21:34 - Dot-Product-Similarity:	Pearson: 0.7293	Spearman: 0.7333
2023-08-03 10:21:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 80 steps:
2023-08-03 10:21:38 - Cosine-Similarity :	Pearson: 0.7330	Spearman: 0.7372
2023-08-03 10:21:38 - Manhattan-Distance:	Pearson: 0.7120	Spearman: 0.7377
2023-08-03 10:21:38 - Euclidean-Distance:	Pearson: 0.7122	Spearman: 0.7377
2023-08-03 10:21:38 - Dot-Product-Similarity:	Pearson: 0.7266	Spearman: 0.7323
2023-08-03 10:21:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 96 steps:
2023-08-03 10:21:43 - Cosine-Similarity :	Pearson: 0.7342	Spearman: 0.7389
2023-08-03 10:21:43 - Manhattan-Distance:	Pearson: 0.7136	Spearman: 0.7388
2023-08-03 10:21:43 - Euclidean-Distance:	Pearson: 0.7141	Spearman: 0.7392
2023-08-03 10:21:43 - Dot-Product-Similarity:	Pearson: 0.7278	Spearman: 0.7337
2023-08-03 10:21:46 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 112 steps:
2023-08-03 10:21:48 - Cosine-Similarity :	Pearson: 0.7388	Spearman: 0.7433
2023-08-03 10:21:48 - Manhattan-Distance:	Pearson: 0.7174	Spearman: 0.7425
2023-08-03 10:21:48 - Euclidean-Distance:	Pearson: 0.7181	Spearman: 0.7432
2023-08-03 10:21:48 - Dot-Product-Similarity:	Pearson: 0.7334	Spearman: 0.7392
2023-08-03 10:21:48 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:21:54 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 128 steps:
2023-08-03 10:21:57 - Cosine-Similarity :	Pearson: 0.7434	Spearman: 0.7480
2023-08-03 10:21:57 - Manhattan-Distance:	Pearson: 0.7226	Spearman: 0.7480
2023-08-03 10:21:57 - Euclidean-Distance:	Pearson: 0.7227	Spearman: 0.7482
2023-08-03 10:21:57 - Dot-Product-Similarity:	Pearson: 0.7379	Spearman: 0.7437
2023-08-03 10:21:57 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:22:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 144 steps:
2023-08-03 10:22:06 - Cosine-Similarity :	Pearson: 0.7425	Spearman: 0.7471
2023-08-03 10:22:06 - Manhattan-Distance:	Pearson: 0.7213	Spearman: 0.7474
2023-08-03 10:22:06 - Euclidean-Distance:	Pearson: 0.7211	Spearman: 0.7469
2023-08-03 10:22:06 - Dot-Product-Similarity:	Pearson: 0.7380	Spearman: 0.7435
2023-08-03 10:22:08 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 160 steps:
2023-08-03 10:22:11 - Cosine-Similarity :	Pearson: 0.7373	Spearman: 0.7417
2023-08-03 10:22:11 - Manhattan-Distance:	Pearson: 0.7165	Spearman: 0.7419
2023-08-03 10:22:11 - Euclidean-Distance:	Pearson: 0.7163	Spearman: 0.7417
2023-08-03 10:22:11 - Dot-Product-Similarity:	Pearson: 0.7330	Spearman: 0.7386
2023-08-03 10:22:11 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 0:
2023-08-03 10:22:14 - Cosine-Similarity :	Pearson: 0.7385	Spearman: 0.7431
2023-08-03 10:22:14 - Manhattan-Distance:	Pearson: 0.7177	Spearman: 0.7430
2023-08-03 10:22:14 - Euclidean-Distance:	Pearson: 0.7176	Spearman: 0.7428
2023-08-03 10:22:14 - Dot-Product-Similarity:	Pearson: 0.7343	Spearman: 0.7399
2023-08-03 10:22:16 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 16 steps:
2023-08-03 10:22:19 - Cosine-Similarity :	Pearson: 0.7443	Spearman: 0.7484
2023-08-03 10:22:19 - Manhattan-Distance:	Pearson: 0.7232	Spearman: 0.7478
2023-08-03 10:22:19 - Euclidean-Distance:	Pearson: 0.7232	Spearman: 0.7481
2023-08-03 10:22:19 - Dot-Product-Similarity:	Pearson: 0.7401	Spearman: 0.7453
2023-08-03 10:22:19 - Save model to ./outputs/simcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-20-46
2023-08-03 10:22:24 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 32 steps:
2023-08-03 10:22:26 - Cosine-Similarity :	Pearson: 0.7428	Spearman: 0.7474
2023-08-03 10:22:26 - Manhattan-Distance:	Pearson: 0.7209	Spearman: 0.7465
2023-08-03 10:22:26 - Euclidean-Distance:	Pearson: 0.7211	Spearman: 0.7468
2023-08-03 10:22:26 - Dot-Product-Similarity:	Pearson: 0.7388	Spearman: 0.7445
2023-08-03 10:22:29 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 48 steps:
2023-08-03 10:22:31 - Cosine-Similarity :	Pearson: 0.7425	Spearman: 0.7475
2023-08-03 10:22:31 - Manhattan-Distance:	Pearson: 0.7207	Spearman: 0.7465
2023-08-03 10:22:31 - Euclidean-Distance:	Pearson: 0.7209	Spearman: 0.7468
2023-08-03 10:22:31 - Dot-Product-Similarity:	Pearson: 0.7385	Spearman: 0.7447
2023-08-03 10:22:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 64 steps:
2023-08-03 10:22:36 - Cosine-Similarity :	Pearson: 0.7408	Spearman: 0.7463
2023-08-03 10:22:36 - Manhattan-Distance:	Pearson: 0.7191	Spearman: 0.7457
2023-08-03 10:22:36 - Euclidean-Distance:	Pearson: 0.7192	Spearman: 0.7460
2023-08-03 10:22:36 - Dot-Product-Similarity:	Pearson: 0.7365	Spearman: 0.7433
2023-08-03 10:22:38 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 80 steps:
2023-08-03 10:22:41 - Cosine-Similarity :	Pearson: 0.7397	Spearman: 0.7452
2023-08-03 10:22:41 - Manhattan-Distance:	Pearson: 0.7186	Spearman: 0.7450
2023-08-03 10:22:41 - Euclidean-Distance:	Pearson: 0.7185	Spearman: 0.7451
2023-08-03 10:22:41 - Dot-Product-Similarity:	Pearson: 0.7353	Spearman: 0.7419
2023-08-03 10:22:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 96 steps:
2023-08-03 10:22:46 - Cosine-Similarity :	Pearson: 0.7410	Spearman: 0.7464
2023-08-03 10:22:46 - Manhattan-Distance:	Pearson: 0.7200	Spearman: 0.7463
2023-08-03 10:22:46 - Euclidean-Distance:	Pearson: 0.7198	Spearman: 0.7462
2023-08-03 10:22:46 - Dot-Product-Similarity:	Pearson: 0.7367	Spearman: 0.7431
2023-08-03 10:22:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 112 steps:
2023-08-03 10:22:50 - Cosine-Similarity :	Pearson: 0.7405	Spearman: 0.7459
2023-08-03 10:22:50 - Manhattan-Distance:	Pearson: 0.7196	Spearman: 0.7457
2023-08-03 10:22:50 - Euclidean-Distance:	Pearson: 0.7194	Spearman: 0.7457
2023-08-03 10:22:50 - Dot-Product-Similarity:	Pearson: 0.7363	Spearman: 0.7427
2023-08-03 10:22:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 128 steps:
2023-08-03 10:22:55 - Cosine-Similarity :	Pearson: 0.7396	Spearman: 0.7452
2023-08-03 10:22:55 - Manhattan-Distance:	Pearson: 0.7186	Spearman: 0.7450
2023-08-03 10:22:55 - Euclidean-Distance:	Pearson: 0.7184	Spearman: 0.7450
2023-08-03 10:22:55 - Dot-Product-Similarity:	Pearson: 0.7354	Spearman: 0.7418
2023-08-03 10:22:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 144 steps:
2023-08-03 10:23:00 - Cosine-Similarity :	Pearson: 0.7387	Spearman: 0.7444
2023-08-03 10:23:00 - Manhattan-Distance:	Pearson: 0.7178	Spearman: 0.7444
2023-08-03 10:23:00 - Euclidean-Distance:	Pearson: 0.7176	Spearman: 0.7442
2023-08-03 10:23:00 - Dot-Product-Similarity:	Pearson: 0.7345	Spearman: 0.7411
2023-08-03 10:23:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 160 steps:
2023-08-03 10:23:05 - Cosine-Similarity :	Pearson: 0.7382	Spearman: 0.7440
2023-08-03 10:23:05 - Manhattan-Distance:	Pearson: 0.7172	Spearman: 0.7438
2023-08-03 10:23:05 - Euclidean-Distance:	Pearson: 0.7170	Spearman: 0.7437
2023-08-03 10:23:05 - Dot-Product-Similarity:	Pearson: 0.7340	Spearman: 0.7407
2023-08-03 10:23:06 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 1:
2023-08-03 10:23:08 - Cosine-Similarity :	Pearson: 0.7382	Spearman: 0.7440
2023-08-03 10:23:08 - Manhattan-Distance:	Pearson: 0.7172	Spearman: 0.7438
2023-08-03 10:23:08 - Euclidean-Distance:	Pearson: 0.7170	Spearman: 0.7437
2023-08-03 10:23:08 - Dot-Product-Similarity:	Pearson: 0.7340	Spearman: 0.7407
2023-08-03 10:23:08 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-test dataset:
2023-08-03 10:23:10 - Cosine-Similarity :	Pearson: 0.7082	Spearman: 0.6977
2023-08-03 10:23:10 - Manhattan-Distance:	Pearson: 0.6874	Spearman: 0.6978
2023-08-03 10:23:10 - Euclidean-Distance:	Pearson: 0.6870	Spearman: 0.6977
2023-08-03 10:23:10 - Dot-Product-Similarity:	Pearson: 0.7057	Spearman: 0.6947
2023-08-03 10:12:08 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:12:08 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 10:12:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 10:12:15 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:12:15 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:12:15 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:12:15 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:12:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 10:12:56 - Cosine-Similarity :	Pearson: 0.7699	Spearman: 0.7890
2023-08-03 10:12:56 - Manhattan-Distance:	Pearson: 0.7710	Spearman: 0.7788
2023-08-03 10:12:56 - Euclidean-Distance:	Pearson: 0.7722	Spearman: 0.7801
2023-08-03 10:12:56 - Dot-Product-Similarity:	Pearson: 0.7214	Spearman: 0.7268
2023-08-03 10:12:56 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:13:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 10:13:40 - Cosine-Similarity :	Pearson: 0.7718	Spearman: 0.7954
2023-08-03 10:13:40 - Manhattan-Distance:	Pearson: 0.7790	Spearman: 0.7862
2023-08-03 10:13:40 - Euclidean-Distance:	Pearson: 0.7801	Spearman: 0.7872
2023-08-03 10:13:40 - Dot-Product-Similarity:	Pearson: 0.7262	Spearman: 0.7323
2023-08-03 10:13:40 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:14:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 10:14:18 - Cosine-Similarity :	Pearson: 0.7845	Spearman: 0.8038
2023-08-03 10:14:18 - Manhattan-Distance:	Pearson: 0.7925	Spearman: 0.7976
2023-08-03 10:14:18 - Euclidean-Distance:	Pearson: 0.7936	Spearman: 0.7988
2023-08-03 10:14:18 - Dot-Product-Similarity:	Pearson: 0.7384	Spearman: 0.7422
2023-08-03 10:14:18 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:14:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 10:14:54 - Cosine-Similarity :	Pearson: 0.7846	Spearman: 0.8045
2023-08-03 10:14:54 - Manhattan-Distance:	Pearson: 0.7905	Spearman: 0.7958
2023-08-03 10:14:54 - Euclidean-Distance:	Pearson: 0.7913	Spearman: 0.7967
2023-08-03 10:14:54 - Dot-Product-Similarity:	Pearson: 0.7530	Spearman: 0.7619
2023-08-03 10:14:54 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:15:29 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 10:15:31 - Cosine-Similarity :	Pearson: 0.7855	Spearman: 0.8024
2023-08-03 10:15:31 - Manhattan-Distance:	Pearson: 0.7912	Spearman: 0.7956
2023-08-03 10:15:31 - Euclidean-Distance:	Pearson: 0.7922	Spearman: 0.7968
2023-08-03 10:15:31 - Dot-Product-Similarity:	Pearson: 0.7418	Spearman: 0.7444
2023-08-03 10:16:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 10:16:05 - Cosine-Similarity :	Pearson: 0.7833	Spearman: 0.8023
2023-08-03 10:16:05 - Manhattan-Distance:	Pearson: 0.7945	Spearman: 0.7986
2023-08-03 10:16:05 - Euclidean-Distance:	Pearson: 0.7952	Spearman: 0.7994
2023-08-03 10:16:05 - Dot-Product-Similarity:	Pearson: 0.7408	Spearman: 0.7435
2023-08-03 10:16:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 10:16:39 - Cosine-Similarity :	Pearson: 0.7804	Spearman: 0.8014
2023-08-03 10:16:39 - Manhattan-Distance:	Pearson: 0.7924	Spearman: 0.7968
2023-08-03 10:16:39 - Euclidean-Distance:	Pearson: 0.7932	Spearman: 0.7977
2023-08-03 10:16:39 - Dot-Product-Similarity:	Pearson: 0.7430	Spearman: 0.7482
2023-08-03 10:17:12 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 10:17:15 - Cosine-Similarity :	Pearson: 0.7870	Spearman: 0.8057
2023-08-03 10:17:15 - Manhattan-Distance:	Pearson: 0.7966	Spearman: 0.8005
2023-08-03 10:17:15 - Euclidean-Distance:	Pearson: 0.7978	Spearman: 0.8019
2023-08-03 10:17:15 - Dot-Product-Similarity:	Pearson: 0.7466	Spearman: 0.7512
2023-08-03 10:17:15 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:17:53 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 10:17:54 - Cosine-Similarity :	Pearson: 0.7863	Spearman: 0.8050
2023-08-03 10:17:54 - Manhattan-Distance:	Pearson: 0.7947	Spearman: 0.7995
2023-08-03 10:17:54 - Euclidean-Distance:	Pearson: 0.7957	Spearman: 0.8004
2023-08-03 10:17:54 - Dot-Product-Similarity:	Pearson: 0.7450	Spearman: 0.7495
2023-08-03 10:18:26 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 10:18:28 - Cosine-Similarity :	Pearson: 0.7866	Spearman: 0.8057
2023-08-03 10:18:28 - Manhattan-Distance:	Pearson: 0.7948	Spearman: 0.7997
2023-08-03 10:18:28 - Euclidean-Distance:	Pearson: 0.7959	Spearman: 0.8013
2023-08-03 10:18:28 - Dot-Product-Similarity:	Pearson: 0.7450	Spearman: 0.7489
2023-08-03 10:18:28 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:18:32 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 10:18:33 - Cosine-Similarity :	Pearson: 0.7849	Spearman: 0.8050
2023-08-03 10:18:33 - Manhattan-Distance:	Pearson: 0.7938	Spearman: 0.7991
2023-08-03 10:18:33 - Euclidean-Distance:	Pearson: 0.7950	Spearman: 0.8006
2023-08-03 10:18:33 - Dot-Product-Similarity:	Pearson: 0.7405	Spearman: 0.7444
2023-08-03 10:19:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 10:19:11 - Cosine-Similarity :	Pearson: 0.7926	Spearman: 0.8066
2023-08-03 10:19:11 - Manhattan-Distance:	Pearson: 0.7967	Spearman: 0.8007
2023-08-03 10:19:11 - Euclidean-Distance:	Pearson: 0.7976	Spearman: 0.8020
2023-08-03 10:19:11 - Dot-Product-Similarity:	Pearson: 0.7542	Spearman: 0.7570
2023-08-03 10:19:11 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:19:51 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 10:19:53 - Cosine-Similarity :	Pearson: 0.7895	Spearman: 0.8051
2023-08-03 10:19:53 - Manhattan-Distance:	Pearson: 0.7971	Spearman: 0.8016
2023-08-03 10:19:53 - Euclidean-Distance:	Pearson: 0.7983	Spearman: 0.8027
2023-08-03 10:19:53 - Dot-Product-Similarity:	Pearson: 0.7510	Spearman: 0.7553
2023-08-03 10:20:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 10:20:27 - Cosine-Similarity :	Pearson: 0.7868	Spearman: 0.8035
2023-08-03 10:20:27 - Manhattan-Distance:	Pearson: 0.7963	Spearman: 0.8004
2023-08-03 10:20:27 - Euclidean-Distance:	Pearson: 0.7975	Spearman: 0.8020
2023-08-03 10:20:27 - Dot-Product-Similarity:	Pearson: 0.7404	Spearman: 0.7425
2023-08-03 10:21:00 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 10:21:02 - Cosine-Similarity :	Pearson: 0.7903	Spearman: 0.8058
2023-08-03 10:21:02 - Manhattan-Distance:	Pearson: 0.7981	Spearman: 0.8023
2023-08-03 10:21:02 - Euclidean-Distance:	Pearson: 0.7993	Spearman: 0.8035
2023-08-03 10:21:02 - Dot-Product-Similarity:	Pearson: 0.7461	Spearman: 0.7481
2023-08-03 10:21:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 10:21:41 - Cosine-Similarity :	Pearson: 0.7895	Spearman: 0.8050
2023-08-03 10:21:41 - Manhattan-Distance:	Pearson: 0.7971	Spearman: 0.8018
2023-08-03 10:21:41 - Euclidean-Distance:	Pearson: 0.7982	Spearman: 0.8029
2023-08-03 10:21:41 - Dot-Product-Similarity:	Pearson: 0.7429	Spearman: 0.7446
2023-08-03 10:22:20 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 10:22:21 - Cosine-Similarity :	Pearson: 0.7944	Spearman: 0.8082
2023-08-03 10:22:21 - Manhattan-Distance:	Pearson: 0.7999	Spearman: 0.8041
2023-08-03 10:22:21 - Euclidean-Distance:	Pearson: 0.8009	Spearman: 0.8052
2023-08-03 10:22:21 - Dot-Product-Similarity:	Pearson: 0.7483	Spearman: 0.7495
2023-08-03 10:22:21 - Save model to ./outputs/sbert-snli-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_10-12-00
2023-08-03 10:23:05 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 10:23:07 - Cosine-Similarity :	Pearson: 0.7922	Spearman: 0.8053
2023-08-03 10:23:07 - Manhattan-Distance:	Pearson: 0.7960	Spearman: 0.8005
2023-08-03 10:23:07 - Euclidean-Distance:	Pearson: 0.7969	Spearman: 0.8015
2023-08-03 10:23:07 - Dot-Product-Similarity:	Pearson: 0.7456	Spearman: 0.7467
2023-08-03 10:23:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 10:23:41 - Cosine-Similarity :	Pearson: 0.7893	Spearman: 0.8047
2023-08-03 10:23:41 - Manhattan-Distance:	Pearson: 0.7964	Spearman: 0.8004
2023-08-03 10:23:41 - Euclidean-Distance:	Pearson: 0.7973	Spearman: 0.8013
2023-08-03 10:23:41 - Dot-Product-Similarity:	Pearson: 0.7412	Spearman: 0.7421
2023-08-03 10:24:13 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 10:24:15 - Cosine-Similarity :	Pearson: 0.7890	Spearman: 0.8039
2023-08-03 10:24:15 - Manhattan-Distance:	Pearson: 0.7961	Spearman: 0.8000
2023-08-03 10:24:15 - Euclidean-Distance:	Pearson: 0.7971	Spearman: 0.8011
2023-08-03 10:24:15 - Dot-Product-Similarity:	Pearson: 0.7421	Spearman: 0.7434
2023-08-03 10:24:51 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 10:24:53 - Cosine-Similarity :	Pearson: 0.7884	Spearman: 0.8036
2023-08-03 10:24:53 - Manhattan-Distance:	Pearson: 0.7965	Spearman: 0.8002
2023-08-03 10:24:53 - Euclidean-Distance:	Pearson: 0.7974	Spearman: 0.8012
2023-08-03 10:24:53 - Dot-Product-Similarity:	Pearson: 0.7400	Spearman: 0.7410
2023-08-03 10:24:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 10:24:55 - Cosine-Similarity :	Pearson: 0.7884	Spearman: 0.8036
2023-08-03 10:24:55 - Manhattan-Distance:	Pearson: 0.7965	Spearman: 0.8002
2023-08-03 10:24:55 - Euclidean-Distance:	Pearson: 0.7974	Spearman: 0.8012
2023-08-03 10:24:55 - Dot-Product-Similarity:	Pearson: 0.7400	Spearman: 0.7410
2023-08-03 10:24:55 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 10:24:57 - Cosine-Similarity :	Pearson: 0.7731	Spearman: 0.7817
2023-08-03 10:24:57 - Manhattan-Distance:	Pearson: 0.7820	Spearman: 0.7727
2023-08-03 10:24:57 - Euclidean-Distance:	Pearson: 0.7820	Spearman: 0.7728
2023-08-03 10:24:57 - Dot-Product-Similarity:	Pearson: 0.7327	Spearman: 0.7143
[2023-08-03 10:32:40,698] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-03 10:32:44,954] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 10:32:50,747] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 10:32:55,127] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 10:32:57 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:32:57 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 10:33:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 10:33:07 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 10:33:07 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 10:33:07 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 10:33:07 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:99 in train                        │
│                                                                              │
│    96 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    97 │                                                                      │
│    98 │                                                                      │
│ ❱  99 │   model.fit(**training_params)                                       │
│   100 │   test_evaluator(model)                                              │
│   101 │   return model                                                       │
│   102                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
2023-08-03 10:32:47 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:32:47 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-03 10:32:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-03 10:32:52 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 10:32:52 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 10:32:52 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 10:32:52 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 10:32:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-03 10:32:55 - Cosine-Similarity :	Pearson: 0.4382	Spearman: 0.4575
2023-08-03 10:32:55 - Manhattan-Distance:	Pearson: 0.4558	Spearman: 0.4590
2023-08-03 10:32:55 - Euclidean-Distance:	Pearson: 0.4529	Spearman: 0.4569
2023-08-03 10:32:55 - Dot-Product-Similarity:	Pearson: 0.4386	Spearman: 0.4525
2023-08-03 10:32:55 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-03 10:33:05 - Cosine-Similarity :	Pearson: 0.6393	Spearman: 0.6456
2023-08-03 10:33:05 - Manhattan-Distance:	Pearson: 0.6315	Spearman: 0.6489
2023-08-03 10:33:05 - Euclidean-Distance:	Pearson: 0.6296	Spearman: 0.6468
2023-08-03 10:33:05 - Dot-Product-Similarity:	Pearson: 0.5983	Spearman: 0.6096
2023-08-03 10:33:05 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:12 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-03 10:33:17 - Cosine-Similarity :	Pearson: 0.6997	Spearman: 0.7045
2023-08-03 10:33:17 - Manhattan-Distance:	Pearson: 0.6977	Spearman: 0.7053
2023-08-03 10:33:17 - Euclidean-Distance:	Pearson: 0.6986	Spearman: 0.7063
2023-08-03 10:33:17 - Dot-Product-Similarity:	Pearson: 0.6790	Spearman: 0.6787
2023-08-03 10:33:17 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:24 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-03 10:33:27 - Cosine-Similarity :	Pearson: 0.7120	Spearman: 0.7212
2023-08-03 10:33:27 - Manhattan-Distance:	Pearson: 0.7107	Spearman: 0.7183
2023-08-03 10:33:27 - Euclidean-Distance:	Pearson: 0.7123	Spearman: 0.7199
2023-08-03 10:33:27 - Dot-Product-Similarity:	Pearson: 0.7030	Spearman: 0.7096
2023-08-03 10:33:27 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-03 10:33:36 - Cosine-Similarity :	Pearson: 0.7222	Spearman: 0.7300
2023-08-03 10:33:36 - Manhattan-Distance:	Pearson: 0.7199	Spearman: 0.7276
2023-08-03 10:33:36 - Euclidean-Distance:	Pearson: 0.7216	Spearman: 0.7294
2023-08-03 10:33:36 - Dot-Product-Similarity:	Pearson: 0.7129	Spearman: 0.7201
2023-08-03 10:33:36 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-03 10:33:45 - Cosine-Similarity :	Pearson: 0.7273	Spearman: 0.7337
2023-08-03 10:33:45 - Manhattan-Distance:	Pearson: 0.7234	Spearman: 0.7317
2023-08-03 10:33:45 - Euclidean-Distance:	Pearson: 0.7249	Spearman: 0.7330
2023-08-03 10:33:45 - Dot-Product-Similarity:	Pearson: 0.7170	Spearman: 0.7233
2023-08-03 10:33:45 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:33:52 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-03 10:33:55 - Cosine-Similarity :	Pearson: 0.7200	Spearman: 0.7275
2023-08-03 10:33:55 - Manhattan-Distance:	Pearson: 0.7173	Spearman: 0.7254
2023-08-03 10:33:55 - Euclidean-Distance:	Pearson: 0.7186	Spearman: 0.7266
2023-08-03 10:33:55 - Dot-Product-Similarity:	Pearson: 0.7103	Spearman: 0.7173
2023-08-03 10:33:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-03 10:34:00 - Cosine-Similarity :	Pearson: 0.7268	Spearman: 0.7343
2023-08-03 10:34:00 - Manhattan-Distance:	Pearson: 0.7243	Spearman: 0.7328
2023-08-03 10:34:00 - Euclidean-Distance:	Pearson: 0.7253	Spearman: 0.7336
2023-08-03 10:34:00 - Dot-Product-Similarity:	Pearson: 0.7168	Spearman: 0.7233
2023-08-03 10:34:00 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:34:07 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-03 10:34:09 - Cosine-Similarity :	Pearson: 0.7299	Spearman: 0.7382
2023-08-03 10:34:09 - Manhattan-Distance:	Pearson: 0.7283	Spearman: 0.7375
2023-08-03 10:34:09 - Euclidean-Distance:	Pearson: 0.7290	Spearman: 0.7380
2023-08-03 10:34:09 - Dot-Product-Similarity:	Pearson: 0.7199	Spearman: 0.7272
2023-08-03 10:34:09 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:34:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-03 10:34:19 - Cosine-Similarity :	Pearson: 0.7318	Spearman: 0.7408
2023-08-03 10:34:19 - Manhattan-Distance:	Pearson: 0.7306	Spearman: 0.7405
2023-08-03 10:34:19 - Euclidean-Distance:	Pearson: 0.7313	Spearman: 0.7409
2023-08-03 10:34:19 - Dot-Product-Similarity:	Pearson: 0.7208	Spearman: 0.7286
2023-08-03 10:34:19 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:34:24 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-03 10:34:26 - Cosine-Similarity :	Pearson: 0.7343	Spearman: 0.7429
2023-08-03 10:34:26 - Manhattan-Distance:	Pearson: 0.7330	Spearman: 0.7425
2023-08-03 10:34:26 - Euclidean-Distance:	Pearson: 0.7337	Spearman: 0.7431
2023-08-03 10:34:26 - Dot-Product-Similarity:	Pearson: 0.7228	Spearman: 0.7304
2023-08-03 10:34:26 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:34:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-03 10:34:36 - Cosine-Similarity :	Pearson: 0.7363	Spearman: 0.7446
2023-08-03 10:34:36 - Manhattan-Distance:	Pearson: 0.7349	Spearman: 0.7444
2023-08-03 10:34:36 - Euclidean-Distance:	Pearson: 0.7357	Spearman: 0.7449
2023-08-03 10:34:36 - Dot-Product-Similarity:	Pearson: 0.7241	Spearman: 0.7312
2023-08-03 10:34:36 - Save model to ./outputs/esimcse-sts-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-39
2023-08-03 10:34:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-03 10:34:47 - Cosine-Similarity :	Pearson: 0.7329	Spearman: 0.7423
2023-08-03 10:34:47 - Manhattan-Distance:	Pearson: 0.7331	Spearman: 0.7417
2023-08-03 10:34:47 - Euclidean-Distance:	Pearson: 0.7337	Spearman: 0.7423
2023-08-03 10:34:47 - Dot-Product-Similarity:	Pearson: 0.7214	Spearman: 0.7294
2023-08-03 10:34:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-03 10:34:53 - Cosine-Similarity :	Pearson: 0.7348	Spearman: 0.7440
2023-08-03 10:34:53 - Manhattan-Distance:	Pearson: 0.7352	Spearman: 0.7438
2023-08-03 10:34:53 - Euclidean-Distance:	Pearson: 0.7358	Spearman: 0.7442
2023-08-03 10:34:53 - Dot-Product-Similarity:	Pearson: 0.7229	Spearman: 0.7309
2023-08-03 10:34:56 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-03 10:35:00 - Cosine-Similarity :	Pearson: 0.7340	Spearman: 0.7431
2023-08-03 10:35:00 - Manhattan-Distance:	Pearson: 0.7344	Spearman: 0.7427
2023-08-03 10:35:00 - Euclidean-Distance:	Pearson: 0.7350	Spearman: 0.7431
2023-08-03 10:35:00 - Dot-Product-Similarity:	Pearson: 0.7223	Spearman: 0.7303
2023-08-03 10:35:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-03 10:35:07 - Cosine-Similarity :	Pearson: 0.7315	Spearman: 0.7411
2023-08-03 10:35:07 - Manhattan-Distance:	Pearson: 0.7322	Spearman: 0.7404
2023-08-03 10:35:07 - Euclidean-Distance:	Pearson: 0.7327	Spearman: 0.7408
2023-08-03 10:35:07 - Dot-Product-Similarity:	Pearson: 0.7204	Spearman: 0.7287
2023-08-03 10:35:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-03 10:35:13 - Cosine-Similarity :	Pearson: 0.7316	Spearman: 0.7410
2023-08-03 10:35:13 - Manhattan-Distance:	Pearson: 0.7316	Spearman: 0.7399
2023-08-03 10:35:13 - Euclidean-Distance:	Pearson: 0.7322	Spearman: 0.7405
2023-08-03 10:35:13 - Dot-Product-Similarity:	Pearson: 0.7207	Spearman: 0.7288
2023-08-03 10:35:16 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-03 10:35:20 - Cosine-Similarity :	Pearson: 0.7344	Spearman: 0.7433
2023-08-03 10:35:20 - Manhattan-Distance:	Pearson: 0.7336	Spearman: 0.7421
2023-08-03 10:35:20 - Euclidean-Distance:	Pearson: 0.7341	Spearman: 0.7427
2023-08-03 10:35:20 - Dot-Product-Similarity:	Pearson: 0.7233	Spearman: 0.7310
2023-08-03 10:35:23 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-03 10:35:27 - Cosine-Similarity :	Pearson: 0.7322	Spearman: 0.7412
2023-08-03 10:35:27 - Manhattan-Distance:	Pearson: 0.7314	Spearman: 0.7400
2023-08-03 10:35:27 - Euclidean-Distance:	Pearson: 0.7320	Spearman: 0.7404
2023-08-03 10:35:27 - Dot-Product-Similarity:	Pearson: 0.7216	Spearman: 0.7296
2023-08-03 10:35:30 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-03 10:35:34 - Cosine-Similarity :	Pearson: 0.7303	Spearman: 0.7394
2023-08-03 10:35:34 - Manhattan-Distance:	Pearson: 0.7296	Spearman: 0.7379
2023-08-03 10:35:34 - Euclidean-Distance:	Pearson: 0.7302	Spearman: 0.7385
2023-08-03 10:35:34 - Dot-Product-Similarity:	Pearson: 0.7200	Spearman: 0.7282
2023-08-03 10:35:37 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-03 10:35:40 - Cosine-Similarity :	Pearson: 0.7302	Spearman: 0.7394
2023-08-03 10:35:40 - Manhattan-Distance:	Pearson: 0.7296	Spearman: 0.7377
2023-08-03 10:35:40 - Euclidean-Distance:	Pearson: 0.7301	Spearman: 0.7383
2023-08-03 10:35:40 - Dot-Product-Similarity:	Pearson: 0.7199	Spearman: 0.7280
2023-08-03 10:35:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-03 10:35:45 - Cosine-Similarity :	Pearson: 0.7302	Spearman: 0.7394
2023-08-03 10:35:45 - Manhattan-Distance:	Pearson: 0.7296	Spearman: 0.7377
2023-08-03 10:35:45 - Euclidean-Distance:	Pearson: 0.7301	Spearman: 0.7383
2023-08-03 10:35:45 - Dot-Product-Similarity:	Pearson: 0.7199	Spearman: 0.7280
2023-08-03 10:35:45 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-03 10:35:48 - Cosine-Similarity :	Pearson: 0.6896	Spearman: 0.6908
2023-08-03 10:35:48 - Manhattan-Distance:	Pearson: 0.6895	Spearman: 0.6891
2023-08-03 10:35:48 - Euclidean-Distance:	Pearson: 0.6892	Spearman: 0.6892
2023-08-03 10:35:48 - Dot-Product-Similarity:	Pearson: 0.6783	Spearman: 0.6752
2023-08-03 10:32:52 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:32:52 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 10462
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 10462
Warmup-steps: 33
Performance before training
2023-08-03 10:32:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset:
2023-08-03 10:32:58 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 10:32:58 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 10:32:58 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 10:32:58 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 10:33:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 16 steps:
2023-08-03 10:33:02 - Cosine-Similarity :	Pearson: 0.5152	Spearman: 0.5292
2023-08-03 10:33:02 - Manhattan-Distance:	Pearson: 0.5172	Spearman: 0.5286
2023-08-03 10:33:02 - Euclidean-Distance:	Pearson: 0.5130	Spearman: 0.5252
2023-08-03 10:33:02 - Dot-Product-Similarity:	Pearson: 0.5127	Spearman: 0.5295
2023-08-03 10:33:02 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:33:16 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 32 steps:
2023-08-03 10:33:20 - Cosine-Similarity :	Pearson: 0.7210	Spearman: 0.7198
2023-08-03 10:33:20 - Manhattan-Distance:	Pearson: 0.7049	Spearman: 0.7207
2023-08-03 10:33:20 - Euclidean-Distance:	Pearson: 0.7056	Spearman: 0.7214
2023-08-03 10:33:20 - Dot-Product-Similarity:	Pearson: 0.7084	Spearman: 0.7082
2023-08-03 10:33:20 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:33:29 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 48 steps:
2023-08-03 10:33:32 - Cosine-Similarity :	Pearson: 0.7630	Spearman: 0.7635
2023-08-03 10:33:32 - Manhattan-Distance:	Pearson: 0.7481	Spearman: 0.7634
2023-08-03 10:33:32 - Euclidean-Distance:	Pearson: 0.7478	Spearman: 0.7631
2023-08-03 10:33:32 - Dot-Product-Similarity:	Pearson: 0.7579	Spearman: 0.7593
2023-08-03 10:33:32 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:33:39 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 64 steps:
2023-08-03 10:33:43 - Cosine-Similarity :	Pearson: 0.7625	Spearman: 0.7660
2023-08-03 10:33:43 - Manhattan-Distance:	Pearson: 0.7512	Spearman: 0.7672
2023-08-03 10:33:43 - Euclidean-Distance:	Pearson: 0.7505	Spearman: 0.7662
2023-08-03 10:33:43 - Dot-Product-Similarity:	Pearson: 0.7570	Spearman: 0.7610
2023-08-03 10:33:43 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:33:52 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 80 steps:
2023-08-03 10:33:56 - Cosine-Similarity :	Pearson: 0.7645	Spearman: 0.7681
2023-08-03 10:33:56 - Manhattan-Distance:	Pearson: 0.7532	Spearman: 0.7686
2023-08-03 10:33:56 - Euclidean-Distance:	Pearson: 0.7525	Spearman: 0.7678
2023-08-03 10:33:56 - Dot-Product-Similarity:	Pearson: 0.7597	Spearman: 0.7634
2023-08-03 10:33:56 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:34:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 96 steps:
2023-08-03 10:34:07 - Cosine-Similarity :	Pearson: 0.7650	Spearman: 0.7687
2023-08-03 10:34:07 - Manhattan-Distance:	Pearson: 0.7539	Spearman: 0.7698
2023-08-03 10:34:07 - Euclidean-Distance:	Pearson: 0.7529	Spearman: 0.7687
2023-08-03 10:34:07 - Dot-Product-Similarity:	Pearson: 0.7603	Spearman: 0.7645
2023-08-03 10:34:07 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:34:17 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 112 steps:
2023-08-03 10:34:20 - Cosine-Similarity :	Pearson: 0.7669	Spearman: 0.7699
2023-08-03 10:34:20 - Manhattan-Distance:	Pearson: 0.7541	Spearman: 0.7711
2023-08-03 10:34:20 - Euclidean-Distance:	Pearson: 0.7531	Spearman: 0.7698
2023-08-03 10:34:20 - Dot-Product-Similarity:	Pearson: 0.7617	Spearman: 0.7654
2023-08-03 10:34:20 - Save model to ./outputs/esimcse-sts-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-43
2023-08-03 10:34:27 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 128 steps:
2023-08-03 10:34:28 - Cosine-Similarity :	Pearson: 0.7650	Spearman: 0.7677
2023-08-03 10:34:28 - Manhattan-Distance:	Pearson: 0.7507	Spearman: 0.7689
2023-08-03 10:34:28 - Euclidean-Distance:	Pearson: 0.7497	Spearman: 0.7678
2023-08-03 10:34:28 - Dot-Product-Similarity:	Pearson: 0.7598	Spearman: 0.7637
2023-08-03 10:34:34 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 144 steps:
2023-08-03 10:34:37 - Cosine-Similarity :	Pearson: 0.7629	Spearman: 0.7660
2023-08-03 10:34:37 - Manhattan-Distance:	Pearson: 0.7470	Spearman: 0.7665
2023-08-03 10:34:37 - Euclidean-Distance:	Pearson: 0.7463	Spearman: 0.7655
2023-08-03 10:34:37 - Dot-Product-Similarity:	Pearson: 0.7578	Spearman: 0.7620
2023-08-03 10:34:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 160 steps:
2023-08-03 10:34:46 - Cosine-Similarity :	Pearson: 0.7607	Spearman: 0.7644
2023-08-03 10:34:46 - Manhattan-Distance:	Pearson: 0.7440	Spearman: 0.7646
2023-08-03 10:34:46 - Euclidean-Distance:	Pearson: 0.7435	Spearman: 0.7637
2023-08-03 10:34:46 - Dot-Product-Similarity:	Pearson: 0.7559	Spearman: 0.7605
2023-08-03 10:34:47 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 0:
2023-08-03 10:34:51 - Cosine-Similarity :	Pearson: 0.7604	Spearman: 0.7643
2023-08-03 10:34:51 - Manhattan-Distance:	Pearson: 0.7436	Spearman: 0.7641
2023-08-03 10:34:51 - Euclidean-Distance:	Pearson: 0.7431	Spearman: 0.7633
2023-08-03 10:34:51 - Dot-Product-Similarity:	Pearson: 0.7557	Spearman: 0.7606
2023-08-03 10:34:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 16 steps:
2023-08-03 10:35:00 - Cosine-Similarity :	Pearson: 0.7632	Spearman: 0.7667
2023-08-03 10:35:00 - Manhattan-Distance:	Pearson: 0.7457	Spearman: 0.7666
2023-08-03 10:35:00 - Euclidean-Distance:	Pearson: 0.7450	Spearman: 0.7657
2023-08-03 10:35:00 - Dot-Product-Similarity:	Pearson: 0.7585	Spearman: 0.7632
2023-08-03 10:35:06 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 32 steps:
2023-08-03 10:35:10 - Cosine-Similarity :	Pearson: 0.7637	Spearman: 0.7674
2023-08-03 10:35:10 - Manhattan-Distance:	Pearson: 0.7457	Spearman: 0.7669
2023-08-03 10:35:10 - Euclidean-Distance:	Pearson: 0.7451	Spearman: 0.7663
2023-08-03 10:35:10 - Dot-Product-Similarity:	Pearson: 0.7592	Spearman: 0.7644
2023-08-03 10:35:16 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 48 steps:
2023-08-03 10:35:20 - Cosine-Similarity :	Pearson: 0.7636	Spearman: 0.7670
2023-08-03 10:35:20 - Manhattan-Distance:	Pearson: 0.7457	Spearman: 0.7668
2023-08-03 10:35:20 - Euclidean-Distance:	Pearson: 0.7450	Spearman: 0.7660
2023-08-03 10:35:20 - Dot-Product-Similarity:	Pearson: 0.7592	Spearman: 0.7639
2023-08-03 10:35:26 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 64 steps:
2023-08-03 10:35:29 - Cosine-Similarity :	Pearson: 0.7613	Spearman: 0.7649
2023-08-03 10:35:29 - Manhattan-Distance:	Pearson: 0.7429	Spearman: 0.7645
2023-08-03 10:35:29 - Euclidean-Distance:	Pearson: 0.7423	Spearman: 0.7638
2023-08-03 10:35:29 - Dot-Product-Similarity:	Pearson: 0.7570	Spearman: 0.7620
2023-08-03 10:35:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 80 steps:
2023-08-03 10:35:39 - Cosine-Similarity :	Pearson: 0.7583	Spearman: 0.7619
2023-08-03 10:35:39 - Manhattan-Distance:	Pearson: 0.7399	Spearman: 0.7618
2023-08-03 10:35:39 - Euclidean-Distance:	Pearson: 0.7392	Spearman: 0.7609
2023-08-03 10:35:39 - Dot-Product-Similarity:	Pearson: 0.7540	Spearman: 0.7590
2023-08-03 10:35:45 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 96 steps:
2023-08-03 10:35:48 - Cosine-Similarity :	Pearson: 0.7574	Spearman: 0.7613
2023-08-03 10:35:48 - Manhattan-Distance:	Pearson: 0.7391	Spearman: 0.7609
2023-08-03 10:35:48 - Euclidean-Distance:	Pearson: 0.7386	Spearman: 0.7603
2023-08-03 10:35:48 - Dot-Product-Similarity:	Pearson: 0.7530	Spearman: 0.7579
2023-08-03 10:35:52 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 112 steps:
2023-08-03 10:35:54 - Cosine-Similarity :	Pearson: 0.7588	Spearman: 0.7626
2023-08-03 10:35:54 - Manhattan-Distance:	Pearson: 0.7406	Spearman: 0.7622
2023-08-03 10:35:54 - Euclidean-Distance:	Pearson: 0.7401	Spearman: 0.7617
2023-08-03 10:35:54 - Dot-Product-Similarity:	Pearson: 0.7543	Spearman: 0.7592
2023-08-03 10:35:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 128 steps:
2023-08-03 10:35:59 - Cosine-Similarity :	Pearson: 0.7598	Spearman: 0.7636
2023-08-03 10:35:59 - Manhattan-Distance:	Pearson: 0.7417	Spearman: 0.7630
2023-08-03 10:35:59 - Euclidean-Distance:	Pearson: 0.7412	Spearman: 0.7626
2023-08-03 10:35:59 - Dot-Product-Similarity:	Pearson: 0.7554	Spearman: 0.7602
2023-08-03 10:36:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 144 steps:
2023-08-03 10:36:06 - Cosine-Similarity :	Pearson: 0.7596	Spearman: 0.7632
2023-08-03 10:36:06 - Manhattan-Distance:	Pearson: 0.7414	Spearman: 0.7626
2023-08-03 10:36:06 - Euclidean-Distance:	Pearson: 0.7410	Spearman: 0.7621
2023-08-03 10:36:06 - Dot-Product-Similarity:	Pearson: 0.7552	Spearman: 0.7600
2023-08-03 10:36:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 160 steps:
2023-08-03 10:36:12 - Cosine-Similarity :	Pearson: 0.7598	Spearman: 0.7634
2023-08-03 10:36:12 - Manhattan-Distance:	Pearson: 0.7416	Spearman: 0.7626
2023-08-03 10:36:12 - Euclidean-Distance:	Pearson: 0.7412	Spearman: 0.7623
2023-08-03 10:36:12 - Dot-Product-Similarity:	Pearson: 0.7555	Spearman: 0.7603
2023-08-03 10:36:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 1:
2023-08-03 10:36:16 - Cosine-Similarity :	Pearson: 0.7598	Spearman: 0.7634
2023-08-03 10:36:16 - Manhattan-Distance:	Pearson: 0.7416	Spearman: 0.7626
2023-08-03 10:36:16 - Euclidean-Distance:	Pearson: 0.7412	Spearman: 0.7623
2023-08-03 10:36:16 - Dot-Product-Similarity:	Pearson: 0.7555	Spearman: 0.7603
2023-08-03 10:36:16 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-test dataset:
2023-08-03 10:36:19 - Cosine-Similarity :	Pearson: 0.7214	Spearman: 0.7111
2023-08-03 10:36:19 - Manhattan-Distance:	Pearson: 0.7040	Spearman: 0.7101
2023-08-03 10:36:19 - Euclidean-Distance:	Pearson: 0.7043	Spearman: 0.7108
2023-08-03 10:36:19 - Dot-Product-Similarity:	Pearson: 0.7166	Spearman: 0.7068
[2023-08-03 10:45:43,413] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 10:45:56,403] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-03 10:45:59,475] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 10:46:03,593] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 10:45:49 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:45:49 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 5231
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 5231
Warmup-steps: 17
Performance before training
2023-08-03 10:45:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset:
2023-08-03 10:45:56 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:45:56 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:45:56 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:45:56 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:45:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 8 steps:
2023-08-03 10:46:01 - Cosine-Similarity :	Pearson: 0.6096	Spearman: 0.6259
2023-08-03 10:46:01 - Manhattan-Distance:	Pearson: 0.6205	Spearman: 0.6349
2023-08-03 10:46:01 - Euclidean-Distance:	Pearson: 0.6137	Spearman: 0.6291
2023-08-03 10:46:01 - Dot-Product-Similarity:	Pearson: 0.3560	Spearman: 0.3452
2023-08-03 10:46:01 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 16 steps:
2023-08-03 10:46:12 - Cosine-Similarity :	Pearson: 0.5583	Spearman: 0.5769
2023-08-03 10:46:12 - Manhattan-Distance:	Pearson: 0.5994	Spearman: 0.6111
2023-08-03 10:46:12 - Euclidean-Distance:	Pearson: 0.5881	Spearman: 0.6023
2023-08-03 10:46:12 - Dot-Product-Similarity:	Pearson: 0.3060	Spearman: 0.3033
2023-08-03 10:46:14 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 24 steps:
2023-08-03 10:46:16 - Cosine-Similarity :	Pearson: 0.6547	Spearman: 0.6640
2023-08-03 10:46:16 - Manhattan-Distance:	Pearson: 0.6633	Spearman: 0.6784
2023-08-03 10:46:16 - Euclidean-Distance:	Pearson: 0.6597	Spearman: 0.6744
2023-08-03 10:46:16 - Dot-Product-Similarity:	Pearson: 0.4152	Spearman: 0.4122
2023-08-03 10:46:16 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:22 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 32 steps:
2023-08-03 10:46:24 - Cosine-Similarity :	Pearson: 0.6938	Spearman: 0.7006
2023-08-03 10:46:24 - Manhattan-Distance:	Pearson: 0.6868	Spearman: 0.7015
2023-08-03 10:46:24 - Euclidean-Distance:	Pearson: 0.6841	Spearman: 0.6985
2023-08-03 10:46:24 - Dot-Product-Similarity:	Pearson: 0.5251	Spearman: 0.5384
2023-08-03 10:46:24 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:30 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 40 steps:
2023-08-03 10:46:32 - Cosine-Similarity :	Pearson: 0.7270	Spearman: 0.7326
2023-08-03 10:46:32 - Manhattan-Distance:	Pearson: 0.7116	Spearman: 0.7252
2023-08-03 10:46:32 - Euclidean-Distance:	Pearson: 0.7105	Spearman: 0.7239
2023-08-03 10:46:32 - Dot-Product-Similarity:	Pearson: 0.5877	Spearman: 0.6065
2023-08-03 10:46:32 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:37 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 48 steps:
2023-08-03 10:46:40 - Cosine-Similarity :	Pearson: 0.7450	Spearman: 0.7501
2023-08-03 10:46:40 - Manhattan-Distance:	Pearson: 0.7282	Spearman: 0.7405
2023-08-03 10:46:40 - Euclidean-Distance:	Pearson: 0.7280	Spearman: 0.7406
2023-08-03 10:46:40 - Dot-Product-Similarity:	Pearson: 0.6124	Spearman: 0.6312
2023-08-03 10:46:40 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:45 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 56 steps:
2023-08-03 10:46:48 - Cosine-Similarity :	Pearson: 0.7511	Spearman: 0.7569
2023-08-03 10:46:48 - Manhattan-Distance:	Pearson: 0.7338	Spearman: 0.7470
2023-08-03 10:46:48 - Euclidean-Distance:	Pearson: 0.7335	Spearman: 0.7468
2023-08-03 10:46:48 - Dot-Product-Similarity:	Pearson: 0.6364	Spearman: 0.6538
2023-08-03 10:46:48 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:46:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 64 steps:
2023-08-03 10:46:56 - Cosine-Similarity :	Pearson: 0.7580	Spearman: 0.7653
2023-08-03 10:46:56 - Manhattan-Distance:	Pearson: 0.7373	Spearman: 0.7513
2023-08-03 10:46:56 - Euclidean-Distance:	Pearson: 0.7370	Spearman: 0.7505
2023-08-03 10:46:56 - Dot-Product-Similarity:	Pearson: 0.6698	Spearman: 0.6860
2023-08-03 10:46:56 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 72 steps:
2023-08-03 10:47:04 - Cosine-Similarity :	Pearson: 0.7645	Spearman: 0.7705
2023-08-03 10:47:04 - Manhattan-Distance:	Pearson: 0.7441	Spearman: 0.7574
2023-08-03 10:47:04 - Euclidean-Distance:	Pearson: 0.7440	Spearman: 0.7570
2023-08-03 10:47:04 - Dot-Product-Similarity:	Pearson: 0.6763	Spearman: 0.6909
2023-08-03 10:47:04 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 0 after 80 steps:
2023-08-03 10:47:11 - Cosine-Similarity :	Pearson: 0.7731	Spearman: 0.7792
2023-08-03 10:47:11 - Manhattan-Distance:	Pearson: 0.7512	Spearman: 0.7636
2023-08-03 10:47:11 - Euclidean-Distance:	Pearson: 0.7516	Spearman: 0.7641
2023-08-03 10:47:11 - Dot-Product-Similarity:	Pearson: 0.6874	Spearman: 0.7005
2023-08-03 10:47:11 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 0:
2023-08-03 10:47:18 - Cosine-Similarity :	Pearson: 0.7745	Spearman: 0.7807
2023-08-03 10:47:18 - Manhattan-Distance:	Pearson: 0.7523	Spearman: 0.7646
2023-08-03 10:47:18 - Euclidean-Distance:	Pearson: 0.7528	Spearman: 0.7652
2023-08-03 10:47:18 - Dot-Product-Similarity:	Pearson: 0.6901	Spearman: 0.7027
2023-08-03 10:47:18 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:23 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 8 steps:
2023-08-03 10:47:26 - Cosine-Similarity :	Pearson: 0.7775	Spearman: 0.7834
2023-08-03 10:47:26 - Manhattan-Distance:	Pearson: 0.7543	Spearman: 0.7668
2023-08-03 10:47:26 - Euclidean-Distance:	Pearson: 0.7549	Spearman: 0.7672
2023-08-03 10:47:26 - Dot-Product-Similarity:	Pearson: 0.6926	Spearman: 0.7045
2023-08-03 10:47:26 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 16 steps:
2023-08-03 10:47:34 - Cosine-Similarity :	Pearson: 0.7790	Spearman: 0.7852
2023-08-03 10:47:34 - Manhattan-Distance:	Pearson: 0.7564	Spearman: 0.7687
2023-08-03 10:47:34 - Euclidean-Distance:	Pearson: 0.7570	Spearman: 0.7694
2023-08-03 10:47:34 - Dot-Product-Similarity:	Pearson: 0.6913	Spearman: 0.7037
2023-08-03 10:47:34 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:40 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 24 steps:
2023-08-03 10:47:42 - Cosine-Similarity :	Pearson: 0.7796	Spearman: 0.7863
2023-08-03 10:47:42 - Manhattan-Distance:	Pearson: 0.7573	Spearman: 0.7696
2023-08-03 10:47:42 - Euclidean-Distance:	Pearson: 0.7578	Spearman: 0.7701
2023-08-03 10:47:42 - Dot-Product-Similarity:	Pearson: 0.6986	Spearman: 0.7092
2023-08-03 10:47:42 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 32 steps:
2023-08-03 10:47:50 - Cosine-Similarity :	Pearson: 0.7812	Spearman: 0.7888
2023-08-03 10:47:50 - Manhattan-Distance:	Pearson: 0.7576	Spearman: 0.7702
2023-08-03 10:47:50 - Euclidean-Distance:	Pearson: 0.7580	Spearman: 0.7707
2023-08-03 10:47:50 - Dot-Product-Similarity:	Pearson: 0.7113	Spearman: 0.7209
2023-08-03 10:47:50 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:47:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 40 steps:
2023-08-03 10:47:58 - Cosine-Similarity :	Pearson: 0.7827	Spearman: 0.7916
2023-08-03 10:47:58 - Manhattan-Distance:	Pearson: 0.7575	Spearman: 0.7704
2023-08-03 10:47:58 - Euclidean-Distance:	Pearson: 0.7579	Spearman: 0.7710
2023-08-03 10:47:58 - Dot-Product-Similarity:	Pearson: 0.7257	Spearman: 0.7348
2023-08-03 10:47:58 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:03 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 48 steps:
2023-08-03 10:48:05 - Cosine-Similarity :	Pearson: 0.7850	Spearman: 0.7931
2023-08-03 10:48:05 - Manhattan-Distance:	Pearson: 0.7597	Spearman: 0.7724
2023-08-03 10:48:05 - Euclidean-Distance:	Pearson: 0.7602	Spearman: 0.7730
2023-08-03 10:48:05 - Dot-Product-Similarity:	Pearson: 0.7285	Spearman: 0.7362
2023-08-03 10:48:06 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:11 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 56 steps:
2023-08-03 10:48:14 - Cosine-Similarity :	Pearson: 0.7866	Spearman: 0.7936
2023-08-03 10:48:14 - Manhattan-Distance:	Pearson: 0.7617	Spearman: 0.7741
2023-08-03 10:48:14 - Euclidean-Distance:	Pearson: 0.7622	Spearman: 0.7747
2023-08-03 10:48:14 - Dot-Product-Similarity:	Pearson: 0.7272	Spearman: 0.7340
2023-08-03 10:48:14 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 64 steps:
2023-08-03 10:48:22 - Cosine-Similarity :	Pearson: 0.7871	Spearman: 0.7938
2023-08-03 10:48:22 - Manhattan-Distance:	Pearson: 0.7624	Spearman: 0.7748
2023-08-03 10:48:22 - Euclidean-Distance:	Pearson: 0.7629	Spearman: 0.7753
2023-08-03 10:48:22 - Dot-Product-Similarity:	Pearson: 0.7277	Spearman: 0.7344
2023-08-03 10:48:22 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:27 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 72 steps:
2023-08-03 10:48:29 - Cosine-Similarity :	Pearson: 0.7874	Spearman: 0.7941
2023-08-03 10:48:29 - Manhattan-Distance:	Pearson: 0.7626	Spearman: 0.7749
2023-08-03 10:48:29 - Euclidean-Distance:	Pearson: 0.7631	Spearman: 0.7754
2023-08-03 10:48:29 - Dot-Product-Similarity:	Pearson: 0.7297	Spearman: 0.7362
2023-08-03 10:48:30 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset in epoch 1 after 80 steps:
2023-08-03 10:48:38 - Cosine-Similarity :	Pearson: 0.7875	Spearman: 0.7942
2023-08-03 10:48:38 - Manhattan-Distance:	Pearson: 0.7626	Spearman: 0.7750
2023-08-03 10:48:38 - Euclidean-Distance:	Pearson: 0.7632	Spearman: 0.7756
2023-08-03 10:48:38 - Dot-Product-Similarity:	Pearson: 0.7300	Spearman: 0.7366
2023-08-03 10:48:38 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-dev dataset after epoch 1:
2023-08-03 10:48:44 - Cosine-Similarity :	Pearson: 0.7875	Spearman: 0.7943
2023-08-03 10:48:44 - Manhattan-Distance:	Pearson: 0.7626	Spearman: 0.7750
2023-08-03 10:48:44 - Euclidean-Distance:	Pearson: 0.7632	Spearman: 0.7756
2023-08-03 10:48:44 - Dot-Product-Similarity:	Pearson: 0.7301	Spearman: 0.7366
2023-08-03 10:48:44 - Save model to ./outputs/consert-sts-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-41
2023-08-03 10:48:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-sup-test dataset:
2023-08-03 10:48:50 - Cosine-Similarity :	Pearson: 0.7429	Spearman: 0.7304
2023-08-03 10:48:50 - Manhattan-Distance:	Pearson: 0.7276	Spearman: 0.7142
2023-08-03 10:48:50 - Euclidean-Distance:	Pearson: 0.7276	Spearman: 0.7143
2023-08-03 10:48:50 - Dot-Product-Similarity:	Pearson: 0.6795	Spearman: 0.6668
2023-08-03 10:33:02 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:33:02 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 10:33:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 10:33:14 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 10:33:14 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 10:33:14 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 10:33:14 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 10:34:21 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 10:34:22 - Cosine-Similarity :	Pearson: 0.7585	Spearman: 0.7821
2023-08-03 10:34:22 - Manhattan-Distance:	Pearson: 0.7780	Spearman: 0.7847
2023-08-03 10:34:22 - Euclidean-Distance:	Pearson: 0.7788	Spearman: 0.7855
2023-08-03 10:34:22 - Dot-Product-Similarity:	Pearson: 0.7458	Spearman: 0.7632
2023-08-03 10:34:23 - Save model to ./outputs/esimcse-snli-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-53
2023-08-03 10:35:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 10:35:52 - Cosine-Similarity :	Pearson: 0.7715	Spearman: 0.7966
2023-08-03 10:35:52 - Manhattan-Distance:	Pearson: 0.7931	Spearman: 0.7973
2023-08-03 10:35:52 - Euclidean-Distance:	Pearson: 0.7938	Spearman: 0.7981
2023-08-03 10:35:52 - Dot-Product-Similarity:	Pearson: 0.7659	Spearman: 0.7860
2023-08-03 10:35:52 - Save model to ./outputs/esimcse-snli-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-53
2023-08-03 10:36:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 10:36:50 - Cosine-Similarity :	Pearson: 0.7763	Spearman: 0.7986
2023-08-03 10:36:50 - Manhattan-Distance:	Pearson: 0.7941	Spearman: 0.7979
2023-08-03 10:36:50 - Euclidean-Distance:	Pearson: 0.7948	Spearman: 0.7984
2023-08-03 10:36:50 - Dot-Product-Similarity:	Pearson: 0.7750	Spearman: 0.7942
2023-08-03 10:36:50 - Save model to ./outputs/esimcse-snli-unsup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_10-32-53
2023-08-03 10:37:32 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 10:37:34 - Cosine-Similarity :	Pearson: 0.7767	Spearman: 0.7977
2023-08-03 10:37:34 - Manhattan-Distance:	Pearson: 0.7941	Spearman: 0.7973
2023-08-03 10:37:34 - Euclidean-Distance:	Pearson: 0.7947	Spearman: 0.7978
2023-08-03 10:37:34 - Dot-Product-Similarity:	Pearson: 0.7753	Spearman: 0.7922
2023-08-03 10:38:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 10:38:19 - Cosine-Similarity :	Pearson: 0.7787	Spearman: 0.7974
2023-08-03 10:38:19 - Manhattan-Distance:	Pearson: 0.7948	Spearman: 0.7964
2023-08-03 10:38:19 - Euclidean-Distance:	Pearson: 0.7953	Spearman: 0.7971
2023-08-03 10:38:19 - Dot-Product-Similarity:	Pearson: 0.7771	Spearman: 0.7923
2023-08-03 10:39:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 10:39:12 - Cosine-Similarity :	Pearson: 0.7788	Spearman: 0.7982
2023-08-03 10:39:12 - Manhattan-Distance:	Pearson: 0.7942	Spearman: 0.7974
2023-08-03 10:39:12 - Euclidean-Distance:	Pearson: 0.7947	Spearman: 0.7979
2023-08-03 10:39:12 - Dot-Product-Similarity:	Pearson: 0.7774	Spearman: 0.7933
2023-08-03 10:40:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 10:40:06 - Cosine-Similarity :	Pearson: 0.7714	Spearman: 0.7966
2023-08-03 10:40:06 - Manhattan-Distance:	Pearson: 0.7913	Spearman: 0.7949
2023-08-03 10:40:06 - Euclidean-Distance:	Pearson: 0.7917	Spearman: 0.7955
2023-08-03 10:40:06 - Dot-Product-Similarity:	Pearson: 0.7717	Spearman: 0.7926
2023-08-03 10:40:57 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 10:41:00 - Cosine-Similarity :	Pearson: 0.7772	Spearman: 0.7960
2023-08-03 10:41:00 - Manhattan-Distance:	Pearson: 0.7921	Spearman: 0.7951
2023-08-03 10:41:00 - Euclidean-Distance:	Pearson: 0.7922	Spearman: 0.7951
2023-08-03 10:41:00 - Dot-Product-Similarity:	Pearson: 0.7763	Spearman: 0.7930
2023-08-03 10:41:55 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 10:41:57 - Cosine-Similarity :	Pearson: 0.7710	Spearman: 0.7902
2023-08-03 10:41:57 - Manhattan-Distance:	Pearson: 0.7867	Spearman: 0.7887
2023-08-03 10:41:57 - Euclidean-Distance:	Pearson: 0.7870	Spearman: 0.7890
2023-08-03 10:41:57 - Dot-Product-Similarity:	Pearson: 0.7708	Spearman: 0.7876
2023-08-03 10:42:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 10:42:51 - Cosine-Similarity :	Pearson: 0.7716	Spearman: 0.7934
2023-08-03 10:42:51 - Manhattan-Distance:	Pearson: 0.7900	Spearman: 0.7919
2023-08-03 10:42:51 - Euclidean-Distance:	Pearson: 0.7906	Spearman: 0.7927
2023-08-03 10:42:51 - Dot-Product-Similarity:	Pearson: 0.7707	Spearman: 0.7894
2023-08-03 10:42:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 10:42:55 - Cosine-Similarity :	Pearson: 0.7720	Spearman: 0.7929
2023-08-03 10:42:55 - Manhattan-Distance:	Pearson: 0.7898	Spearman: 0.7916
2023-08-03 10:42:55 - Euclidean-Distance:	Pearson: 0.7903	Spearman: 0.7924
2023-08-03 10:42:55 - Dot-Product-Similarity:	Pearson: 0.7708	Spearman: 0.7887
2023-08-03 10:43:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 10:43:51 - Cosine-Similarity :	Pearson: 0.7708	Spearman: 0.7866
2023-08-03 10:43:51 - Manhattan-Distance:	Pearson: 0.7841	Spearman: 0.7860
2023-08-03 10:43:51 - Euclidean-Distance:	Pearson: 0.7837	Spearman: 0.7857
2023-08-03 10:43:51 - Dot-Product-Similarity:	Pearson: 0.7700	Spearman: 0.7835
2023-08-03 10:44:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 10:44:47 - Cosine-Similarity :	Pearson: 0.7707	Spearman: 0.7864
2023-08-03 10:44:47 - Manhattan-Distance:	Pearson: 0.7836	Spearman: 0.7848
2023-08-03 10:44:47 - Euclidean-Distance:	Pearson: 0.7836	Spearman: 0.7850
2023-08-03 10:44:47 - Dot-Product-Similarity:	Pearson: 0.7707	Spearman: 0.7843
2023-08-03 10:45:33 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 10:45:34 - Cosine-Similarity :	Pearson: 0.7738	Spearman: 0.7917
2023-08-03 10:45:34 - Manhattan-Distance:	Pearson: 0.7863	Spearman: 0.7894
2023-08-03 10:45:34 - Euclidean-Distance:	Pearson: 0.7864	Spearman: 0.7896
2023-08-03 10:45:34 - Dot-Product-Similarity:	Pearson: 0.7750	Spearman: 0.7902
2023-08-03 10:46:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 10:46:20 - Cosine-Similarity :	Pearson: 0.7688	Spearman: 0.7855
2023-08-03 10:46:20 - Manhattan-Distance:	Pearson: 0.7818	Spearman: 0.7834
2023-08-03 10:46:20 - Euclidean-Distance:	Pearson: 0.7816	Spearman: 0.7832
2023-08-03 10:46:20 - Dot-Product-Similarity:	Pearson: 0.7703	Spearman: 0.7849
2023-08-03 10:47:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 10:47:09 - Cosine-Similarity :	Pearson: 0.7733	Spearman: 0.7896
2023-08-03 10:47:09 - Manhattan-Distance:	Pearson: 0.7859	Spearman: 0.7874
2023-08-03 10:47:09 - Euclidean-Distance:	Pearson: 0.7859	Spearman: 0.7874
2023-08-03 10:47:09 - Dot-Product-Similarity:	Pearson: 0.7745	Spearman: 0.7889
2023-08-03 10:47:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 10:47:56 - Cosine-Similarity :	Pearson: 0.7718	Spearman: 0.7875
2023-08-03 10:47:56 - Manhattan-Distance:	Pearson: 0.7837	Spearman: 0.7856
2023-08-03 10:47:56 - Euclidean-Distance:	Pearson: 0.7835	Spearman: 0.7853
2023-08-03 10:47:56 - Dot-Product-Similarity:	Pearson: 0.7728	Spearman: 0.7864
2023-08-03 10:48:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 10:48:45 - Cosine-Similarity :	Pearson: 0.7656	Spearman: 0.7810
2023-08-03 10:48:45 - Manhattan-Distance:	Pearson: 0.7777	Spearman: 0.7789
2023-08-03 10:48:45 - Euclidean-Distance:	Pearson: 0.7772	Spearman: 0.7785
2023-08-03 10:48:45 - Dot-Product-Similarity:	Pearson: 0.7678	Spearman: 0.7813
2023-08-03 10:49:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 10:49:26 - Cosine-Similarity :	Pearson: 0.7712	Spearman: 0.7870
2023-08-03 10:49:26 - Manhattan-Distance:	Pearson: 0.7834	Spearman: 0.7852
2023-08-03 10:49:26 - Euclidean-Distance:	Pearson: 0.7830	Spearman: 0.7846
2023-08-03 10:49:26 - Dot-Product-Similarity:	Pearson: 0.7726	Spearman: 0.7866
2023-08-03 10:50:05 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 10:50:07 - Cosine-Similarity :	Pearson: 0.7696	Spearman: 0.7872
2023-08-03 10:50:07 - Manhattan-Distance:	Pearson: 0.7835	Spearman: 0.7851
2023-08-03 10:50:07 - Euclidean-Distance:	Pearson: 0.7832	Spearman: 0.7850
2023-08-03 10:50:07 - Dot-Product-Similarity:	Pearson: 0.7716	Spearman: 0.7868
2023-08-03 10:50:46 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 10:50:48 - Cosine-Similarity :	Pearson: 0.7697	Spearman: 0.7859
2023-08-03 10:50:48 - Manhattan-Distance:	Pearson: 0.7824	Spearman: 0.7839
2023-08-03 10:50:48 - Euclidean-Distance:	Pearson: 0.7820	Spearman: 0.7836
2023-08-03 10:50:48 - Dot-Product-Similarity:	Pearson: 0.7715	Spearman: 0.7859
2023-08-03 10:50:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 10:50:50 - Cosine-Similarity :	Pearson: 0.7696	Spearman: 0.7859
2023-08-03 10:50:50 - Manhattan-Distance:	Pearson: 0.7824	Spearman: 0.7839
2023-08-03 10:50:50 - Euclidean-Distance:	Pearson: 0.7820	Spearman: 0.7836
2023-08-03 10:50:50 - Dot-Product-Similarity:	Pearson: 0.7715	Spearman: 0.7859
2023-08-03 10:50:50 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 10:50:51 - Cosine-Similarity :	Pearson: 0.7682	Spearman: 0.7782
2023-08-03 10:50:51 - Manhattan-Distance:	Pearson: 0.7825	Spearman: 0.7746
2023-08-03 10:50:51 - Euclidean-Distance:	Pearson: 0.7832	Spearman: 0.7752
2023-08-03 10:50:51 - Dot-Product-Similarity:	Pearson: 0.7632	Spearman: 0.7702
2023-08-03 10:46:09 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:46:09 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 10:46:11 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 10:46:18 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:46:18 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:46:18 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:46:18 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:47:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 10:47:36 - Cosine-Similarity :	Pearson: 0.3362	Spearman: 0.3425
2023-08-03 10:47:36 - Manhattan-Distance:	Pearson: 0.3681	Spearman: 0.3711
2023-08-03 10:47:36 - Euclidean-Distance:	Pearson: 0.3511	Spearman: 0.3522
2023-08-03 10:47:36 - Dot-Product-Similarity:	Pearson: 0.2546	Spearman: 0.2788
2023-08-03 10:47:36 - Save model to ./outputs/consert-snli-unsup-macbert-2-TripletLoss-2023-08-03_10-46-01
2023-08-03 10:48:59 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 10:49:01 - Cosine-Similarity :	Pearson: 0.3402	Spearman: 0.3459
2023-08-03 10:49:01 - Manhattan-Distance:	Pearson: 0.3386	Spearman: 0.3488
2023-08-03 10:49:01 - Euclidean-Distance:	Pearson: 0.3363	Spearman: 0.3453
2023-08-03 10:49:01 - Dot-Product-Similarity:	Pearson: 0.3046	Spearman: 0.3293
2023-08-03 10:49:01 - Save model to ./outputs/consert-snli-unsup-macbert-2-TripletLoss-2023-08-03_10-46-01
2023-08-03 10:50:20 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 10:50:23 - Cosine-Similarity :	Pearson: 0.3466	Spearman: 0.3577
2023-08-03 10:50:23 - Manhattan-Distance:	Pearson: 0.3173	Spearman: 0.3374
2023-08-03 10:50:23 - Euclidean-Distance:	Pearson: 0.3170	Spearman: 0.3355
2023-08-03 10:50:23 - Dot-Product-Similarity:	Pearson: 0.3059	Spearman: 0.3444
2023-08-03 10:50:23 - Save model to ./outputs/consert-snli-unsup-macbert-2-TripletLoss-2023-08-03_10-46-01
2023-08-03 10:51:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 10:51:39 - Cosine-Similarity :	Pearson: 0.3225	Spearman: 0.3311
2023-08-03 10:51:39 - Manhattan-Distance:	Pearson: 0.2922	Spearman: 0.3146
2023-08-03 10:51:39 - Euclidean-Distance:	Pearson: 0.2941	Spearman: 0.3154
2023-08-03 10:51:39 - Dot-Product-Similarity:	Pearson: 0.2754	Spearman: 0.3082
2023-08-03 10:52:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 10:52:56 - Cosine-Similarity :	Pearson: 0.3007	Spearman: 0.3031
2023-08-03 10:52:56 - Manhattan-Distance:	Pearson: 0.2823	Spearman: 0.2971
2023-08-03 10:52:56 - Euclidean-Distance:	Pearson: 0.2888	Spearman: 0.3066
2023-08-03 10:52:56 - Dot-Product-Similarity:	Pearson: 0.2676	Spearman: 0.2876
2023-08-03 10:54:12 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 10:54:15 - Cosine-Similarity :	Pearson: 0.2435	Spearman: 0.2528
2023-08-03 10:54:15 - Manhattan-Distance:	Pearson: 0.2080	Spearman: 0.2472
2023-08-03 10:54:15 - Euclidean-Distance:	Pearson: 0.2128	Spearman: 0.2519
2023-08-03 10:54:15 - Dot-Product-Similarity:	Pearson: 0.1989	Spearman: 0.2318
2023-08-03 10:55:31 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 10:55:33 - Cosine-Similarity :	Pearson: 0.2809	Spearman: 0.2823
2023-08-03 10:55:33 - Manhattan-Distance:	Pearson: 0.2634	Spearman: 0.2865
2023-08-03 10:55:33 - Euclidean-Distance:	Pearson: 0.2677	Spearman: 0.2911
2023-08-03 10:55:33 - Dot-Product-Similarity:	Pearson: 0.2427	Spearman: 0.2555
2023-08-03 10:56:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 10:56:51 - Cosine-Similarity :	Pearson: 0.2133	Spearman: 0.2174
2023-08-03 10:56:51 - Manhattan-Distance:	Pearson: 0.1731	Spearman: 0.2052
2023-08-03 10:56:51 - Euclidean-Distance:	Pearson: 0.1821	Spearman: 0.2160
2023-08-03 10:56:51 - Dot-Product-Similarity:	Pearson: 0.1766	Spearman: 0.1956
2023-08-03 10:58:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 10:58:09 - Cosine-Similarity :	Pearson: 0.2089	Spearman: 0.2178
2023-08-03 10:58:09 - Manhattan-Distance:	Pearson: 0.1764	Spearman: 0.1942
2023-08-03 10:58:09 - Euclidean-Distance:	Pearson: 0.1866	Spearman: 0.2112
2023-08-03 10:58:09 - Dot-Product-Similarity:	Pearson: 0.1876	Spearman: 0.2084
2023-08-03 10:59:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 10:59:28 - Cosine-Similarity :	Pearson: 0.1750	Spearman: 0.1818
2023-08-03 10:59:28 - Manhattan-Distance:	Pearson: 0.1817	Spearman: 0.1768
2023-08-03 10:59:28 - Euclidean-Distance:	Pearson: 0.1903	Spearman: 0.1842
2023-08-03 10:59:28 - Dot-Product-Similarity:	Pearson: 0.1698	Spearman: 0.1742
2023-08-03 10:59:29 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 10:59:32 - Cosine-Similarity :	Pearson: 0.1767	Spearman: 0.1836
2023-08-03 10:59:32 - Manhattan-Distance:	Pearson: 0.1820	Spearman: 0.1798
2023-08-03 10:59:32 - Euclidean-Distance:	Pearson: 0.1899	Spearman: 0.1859
2023-08-03 10:59:32 - Dot-Product-Similarity:	Pearson: 0.1716	Spearman: 0.1769
2023-08-03 11:00:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 11:00:51 - Cosine-Similarity :	Pearson: 0.2257	Spearman: 0.2279
2023-08-03 11:00:51 - Manhattan-Distance:	Pearson: 0.2085	Spearman: 0.2061
2023-08-03 11:00:51 - Euclidean-Distance:	Pearson: 0.2201	Spearman: 0.2233
2023-08-03 11:00:51 - Dot-Product-Similarity:	Pearson: 0.2106	Spearman: 0.2174
2023-08-03 11:02:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 11:02:09 - Cosine-Similarity :	Pearson: 0.2522	Spearman: 0.2551
2023-08-03 11:02:09 - Manhattan-Distance:	Pearson: 0.2394	Spearman: 0.2332
2023-08-03 11:02:09 - Euclidean-Distance:	Pearson: 0.2481	Spearman: 0.2444
2023-08-03 11:02:09 - Dot-Product-Similarity:	Pearson: 0.2424	Spearman: 0.2475
2023-08-03 11:03:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 11:03:28 - Cosine-Similarity :	Pearson: 0.2271	Spearman: 0.2251
2023-08-03 11:03:28 - Manhattan-Distance:	Pearson: 0.2019	Spearman: 0.2029
2023-08-03 11:03:28 - Euclidean-Distance:	Pearson: 0.2137	Spearman: 0.2191
2023-08-03 11:03:28 - Dot-Product-Similarity:	Pearson: 0.2090	Spearman: 0.2137
2023-08-03 11:04:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 11:04:46 - Cosine-Similarity :	Pearson: 0.2113	Spearman: 0.2146
2023-08-03 11:04:46 - Manhattan-Distance:	Pearson: 0.1957	Spearman: 0.1922
2023-08-03 11:04:46 - Euclidean-Distance:	Pearson: 0.2076	Spearman: 0.2060
2023-08-03 11:04:46 - Dot-Product-Similarity:	Pearson: 0.2031	Spearman: 0.2087
2023-08-03 11:06:02 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 11:06:05 - Cosine-Similarity :	Pearson: 0.2435	Spearman: 0.2414
2023-08-03 11:06:05 - Manhattan-Distance:	Pearson: 0.2242	Spearman: 0.2206
2023-08-03 11:06:05 - Euclidean-Distance:	Pearson: 0.2363	Spearman: 0.2376
2023-08-03 11:06:05 - Dot-Product-Similarity:	Pearson: 0.2351	Spearman: 0.2361
2023-08-03 11:07:21 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 11:07:23 - Cosine-Similarity :	Pearson: 0.2180	Spearman: 0.2149
2023-08-03 11:07:23 - Manhattan-Distance:	Pearson: 0.2116	Spearman: 0.2010
2023-08-03 11:07:23 - Euclidean-Distance:	Pearson: 0.2223	Spearman: 0.2142
2023-08-03 11:07:23 - Dot-Product-Similarity:	Pearson: 0.2058	Spearman: 0.2032
2023-08-03 11:08:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 11:08:41 - Cosine-Similarity :	Pearson: 0.2029	Spearman: 0.2028
2023-08-03 11:08:41 - Manhattan-Distance:	Pearson: 0.1973	Spearman: 0.1913
2023-08-03 11:08:41 - Euclidean-Distance:	Pearson: 0.2071	Spearman: 0.2053
2023-08-03 11:08:41 - Dot-Product-Similarity:	Pearson: 0.1946	Spearman: 0.1940
2023-08-03 11:09:58 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 11:10:00 - Cosine-Similarity :	Pearson: 0.2068	Spearman: 0.2059
2023-08-03 11:10:00 - Manhattan-Distance:	Pearson: 0.1990	Spearman: 0.1863
2023-08-03 11:10:00 - Euclidean-Distance:	Pearson: 0.2105	Spearman: 0.2041
2023-08-03 11:10:00 - Dot-Product-Similarity:	Pearson: 0.2037	Spearman: 0.1996
2023-08-03 11:11:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 11:11:18 - Cosine-Similarity :	Pearson: 0.1964	Spearman: 0.1946
2023-08-03 11:11:18 - Manhattan-Distance:	Pearson: 0.1861	Spearman: 0.1782
2023-08-03 11:11:18 - Euclidean-Distance:	Pearson: 0.1984	Spearman: 0.1971
2023-08-03 11:11:18 - Dot-Product-Similarity:	Pearson: 0.1910	Spearman: 0.1883
2023-08-03 11:12:35 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 11:12:38 - Cosine-Similarity :	Pearson: 0.2021	Spearman: 0.2008
2023-08-03 11:12:38 - Manhattan-Distance:	Pearson: 0.1925	Spearman: 0.1854
2023-08-03 11:12:38 - Euclidean-Distance:	Pearson: 0.2040	Spearman: 0.2020
2023-08-03 11:12:38 - Dot-Product-Similarity:	Pearson: 0.1976	Spearman: 0.1957
2023-08-03 11:12:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 11:12:42 - Cosine-Similarity :	Pearson: 0.2021	Spearman: 0.2008
2023-08-03 11:12:42 - Manhattan-Distance:	Pearson: 0.1925	Spearman: 0.1853
2023-08-03 11:12:42 - Euclidean-Distance:	Pearson: 0.2040	Spearman: 0.2020
2023-08-03 11:12:42 - Dot-Product-Similarity:	Pearson: 0.1975	Spearman: 0.1957
2023-08-03 11:12:42 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 11:12:44 - Cosine-Similarity :	Pearson: 0.2162	Spearman: 0.2140
2023-08-03 11:12:44 - Manhattan-Distance:	Pearson: 0.1719	Spearman: 0.1547
2023-08-03 11:12:44 - Euclidean-Distance:	Pearson: 0.1838	Spearman: 0.1743
2023-08-03 11:12:44 - Dot-Product-Similarity:	Pearson: 0.2291	Spearman: 0.2280
[2023-08-03 11:21:05,165] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 11:23:30,286] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 11:25:27,016] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2023-08-03 11:23:37 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 11:23:37 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 11:23:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 11:23:51 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 11:23:51 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 11:23:51 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 11:23:51 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 10:46:02 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:46:02 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 10:46:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 10:46:11 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:46:11 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:46:11 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:46:11 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:50:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-03 10:50:42 - Cosine-Similarity :	Pearson: 0.7397	Spearman: 0.7594
2023-08-03 10:50:42 - Manhattan-Distance:	Pearson: 0.7551	Spearman: 0.7608
2023-08-03 10:50:42 - Euclidean-Distance:	Pearson: 0.7527	Spearman: 0.7594
2023-08-03 10:50:42 - Dot-Product-Similarity:	Pearson: 0.6314	Spearman: 0.6339
2023-08-03 10:50:42 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-54
2023-08-03 10:55:26 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-03 10:55:28 - Cosine-Similarity :	Pearson: 0.7089	Spearman: 0.7404
2023-08-03 10:55:28 - Manhattan-Distance:	Pearson: 0.7426	Spearman: 0.7500
2023-08-03 10:55:28 - Euclidean-Distance:	Pearson: 0.7384	Spearman: 0.7465
2023-08-03 10:55:28 - Dot-Product-Similarity:	Pearson: 0.5899	Spearman: 0.5905
2023-08-03 11:00:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-03 11:00:11 - Cosine-Similarity :	Pearson: 0.7177	Spearman: 0.7489
2023-08-03 11:00:11 - Manhattan-Distance:	Pearson: 0.7506	Spearman: 0.7585
2023-08-03 11:00:11 - Euclidean-Distance:	Pearson: 0.7496	Spearman: 0.7573
2023-08-03 11:00:11 - Dot-Product-Similarity:	Pearson: 0.5961	Spearman: 0.5896
2023-08-03 11:04:50 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-03 11:04:52 - Cosine-Similarity :	Pearson: 0.7064	Spearman: 0.7429
2023-08-03 11:04:52 - Manhattan-Distance:	Pearson: 0.7456	Spearman: 0.7516
2023-08-03 11:04:52 - Euclidean-Distance:	Pearson: 0.7446	Spearman: 0.7502
2023-08-03 11:04:52 - Dot-Product-Similarity:	Pearson: 0.5883	Spearman: 0.5796
2023-08-03 11:09:33 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-03 11:09:35 - Cosine-Similarity :	Pearson: 0.7187	Spearman: 0.7503
2023-08-03 11:09:35 - Manhattan-Distance:	Pearson: 0.7587	Spearman: 0.7629
2023-08-03 11:09:35 - Euclidean-Distance:	Pearson: 0.7571	Spearman: 0.7617
2023-08-03 11:09:35 - Dot-Product-Similarity:	Pearson: 0.6002	Spearman: 0.5957
2023-08-03 11:13:35 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-03 11:13:38 - Cosine-Similarity :	Pearson: 0.7166	Spearman: 0.7479
2023-08-03 11:13:38 - Manhattan-Distance:	Pearson: 0.7497	Spearman: 0.7548
2023-08-03 11:13:38 - Euclidean-Distance:	Pearson: 0.7492	Spearman: 0.7538
2023-08-03 11:13:38 - Dot-Product-Similarity:	Pearson: 0.6236	Spearman: 0.6195
2023-08-03 11:16:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-03 11:16:16 - Cosine-Similarity :	Pearson: 0.7045	Spearman: 0.7384
2023-08-03 11:16:16 - Manhattan-Distance:	Pearson: 0.7419	Spearman: 0.7474
2023-08-03 11:16:16 - Euclidean-Distance:	Pearson: 0.7413	Spearman: 0.7471
2023-08-03 11:16:16 - Dot-Product-Similarity:	Pearson: 0.5890	Spearman: 0.5799
2023-08-03 11:18:55 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-03 11:18:58 - Cosine-Similarity :	Pearson: 0.7106	Spearman: 0.7415
2023-08-03 11:18:58 - Manhattan-Distance:	Pearson: 0.7442	Spearman: 0.7477
2023-08-03 11:18:58 - Euclidean-Distance:	Pearson: 0.7433	Spearman: 0.7471
2023-08-03 11:18:58 - Dot-Product-Similarity:	Pearson: 0.6331	Spearman: 0.6314
2023-08-03 11:21:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-03 11:21:51 - Cosine-Similarity :	Pearson: 0.7014	Spearman: 0.7379
2023-08-03 11:21:51 - Manhattan-Distance:	Pearson: 0.7424	Spearman: 0.7464
2023-08-03 11:21:51 - Euclidean-Distance:	Pearson: 0.7420	Spearman: 0.7459
2023-08-03 11:21:51 - Dot-Product-Similarity:	Pearson: 0.6265	Spearman: 0.6253
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/SentenceTransformer.py │
│ :731 in fit                                                                  │
│                                                                              │
│   728 │   │   │   │   │   │   │   loss_value = loss_model(features, labels)  │
│   729 │   │   │   │   │   │                                                  │
│   730 │   │   │   │   │   │   scale_before_step = scaler.get_scale()         │
│ ❱ 731 │   │   │   │   │   │   scaler.scale(loss_value).backward()            │
│   732 │   │   │   │   │   │   scaler.unscale_(optimizer)                     │
│   733 │   │   │   │   │   │   torch.nn.utils.clip_grad_norm_(loss_model.para │
│   734 │   │   │   │   │   │   scaler.step(optimizer)                         │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/_tensor.py:488 in  │
│ backward                                                                     │
│                                                                              │
│    485 │   │   │   │   create_graph=create_graph,                            │
│    486 │   │   │   │   inputs=inputs,                                        │
│    487 │   │   │   )                                                         │
│ ❱  488 │   │   torch.autograd.backward(                                      │
│    489 │   │   │   self, gradient, retain_graph, create_graph, inputs=inputs │
│    490 │   │   )                                                             │
│    491                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/autograd/__init__. │
│ py:197 in backward                                                           │
│                                                                              │
│   194 │   # The reason we repeat same the comment below is that              │
│   195 │   # some Python versions print out the first line of a multi-line fu │
│   196 │   # calls in the traceback and some print out the last line          │
│ ❱ 197 │   Variable._execution_engine.run_backward(  # Calls into the C++ eng │
│   198 │   │   tensors, grad_tensors_, retain_graph, create_graph, inputs,    │
│   199 │   │   allow_unreachable=True, accumulate_grad=True)  # Calls into th │
│   200                                                                        │
╰──────────────────────────────────────────────────────────────────────────────╯
RuntimeError: Found dtype Long but expected Float
2023-08-03 11:25:32 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 11:25:32 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 10462
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 10462
Warmup-steps: 33
Performance before training
2023-08-03 11:25:34 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset:
2023-08-03 11:25:42 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 11:25:42 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 11:25:42 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 11:25:42 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 11:25:51 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 16 steps:
2023-08-03 11:25:54 - Cosine-Similarity :	Pearson: 0.6718	Spearman: 0.6848
2023-08-03 11:25:54 - Manhattan-Distance:	Pearson: 0.6722	Spearman: 0.6886
2023-08-03 11:25:54 - Euclidean-Distance:	Pearson: 0.6692	Spearman: 0.6860
2023-08-03 11:25:54 - Dot-Product-Similarity:	Pearson: 0.4532	Spearman: 0.4446
2023-08-03 11:25:54 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:26:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 32 steps:
2023-08-03 11:26:13 - Cosine-Similarity :	Pearson: 0.7616	Spearman: 0.7635
2023-08-03 11:26:13 - Manhattan-Distance:	Pearson: 0.7461	Spearman: 0.7573
2023-08-03 11:26:13 - Euclidean-Distance:	Pearson: 0.7476	Spearman: 0.7593
2023-08-03 11:26:13 - Dot-Product-Similarity:	Pearson: 0.6927	Spearman: 0.6935
2023-08-03 11:26:13 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:26:25 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 48 steps:
2023-08-03 11:26:28 - Cosine-Similarity :	Pearson: 0.7730	Spearman: 0.7744
2023-08-03 11:26:28 - Manhattan-Distance:	Pearson: 0.7545	Spearman: 0.7711
2023-08-03 11:26:28 - Euclidean-Distance:	Pearson: 0.7554	Spearman: 0.7722
2023-08-03 11:26:28 - Dot-Product-Similarity:	Pearson: 0.7325	Spearman: 0.7324
2023-08-03 11:26:29 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:26:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 64 steps:
2023-08-03 11:26:44 - Cosine-Similarity :	Pearson: 0.7712	Spearman: 0.7718
2023-08-03 11:26:44 - Manhattan-Distance:	Pearson: 0.7500	Spearman: 0.7672
2023-08-03 11:26:44 - Euclidean-Distance:	Pearson: 0.7506	Spearman: 0.7678
2023-08-03 11:26:44 - Dot-Product-Similarity:	Pearson: 0.7393	Spearman: 0.7397
2023-08-03 11:26:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 80 steps:
2023-08-03 11:26:56 - Cosine-Similarity :	Pearson: 0.7696	Spearman: 0.7709
2023-08-03 11:26:56 - Manhattan-Distance:	Pearson: 0.7470	Spearman: 0.7658
2023-08-03 11:26:56 - Euclidean-Distance:	Pearson: 0.7476	Spearman: 0.7665
2023-08-03 11:26:56 - Dot-Product-Similarity:	Pearson: 0.7392	Spearman: 0.7409
2023-08-03 11:27:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 96 steps:
2023-08-03 11:27:08 - Cosine-Similarity :	Pearson: 0.7710	Spearman: 0.7727
2023-08-03 11:27:08 - Manhattan-Distance:	Pearson: 0.7464	Spearman: 0.7653
2023-08-03 11:27:08 - Euclidean-Distance:	Pearson: 0.7470	Spearman: 0.7663
2023-08-03 11:27:08 - Dot-Product-Similarity:	Pearson: 0.7439	Spearman: 0.7468
2023-08-03 11:27:18 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 112 steps:
2023-08-03 11:27:21 - Cosine-Similarity :	Pearson: 0.7729	Spearman: 0.7747
2023-08-03 11:27:21 - Manhattan-Distance:	Pearson: 0.7477	Spearman: 0.7668
2023-08-03 11:27:21 - Euclidean-Distance:	Pearson: 0.7484	Spearman: 0.7676
2023-08-03 11:27:21 - Dot-Product-Similarity:	Pearson: 0.7487	Spearman: 0.7520
2023-08-03 11:27:21 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:27:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 128 steps:
2023-08-03 11:27:36 - Cosine-Similarity :	Pearson: 0.7727	Spearman: 0.7745
2023-08-03 11:27:36 - Manhattan-Distance:	Pearson: 0.7448	Spearman: 0.7644
2023-08-03 11:27:36 - Euclidean-Distance:	Pearson: 0.7456	Spearman: 0.7658
2023-08-03 11:27:36 - Dot-Product-Similarity:	Pearson: 0.7501	Spearman: 0.7544
2023-08-03 11:27:45 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 144 steps:
2023-08-03 11:27:48 - Cosine-Similarity :	Pearson: 0.7703	Spearman: 0.7728
2023-08-03 11:27:48 - Manhattan-Distance:	Pearson: 0.7423	Spearman: 0.7627
2023-08-03 11:27:48 - Euclidean-Distance:	Pearson: 0.7432	Spearman: 0.7640
2023-08-03 11:27:48 - Dot-Product-Similarity:	Pearson: 0.7485	Spearman: 0.7532
2023-08-03 11:27:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 0 after 160 steps:
2023-08-03 11:28:00 - Cosine-Similarity :	Pearson: 0.7726	Spearman: 0.7750
2023-08-03 11:28:00 - Manhattan-Distance:	Pearson: 0.7453	Spearman: 0.7655
2023-08-03 11:28:00 - Euclidean-Distance:	Pearson: 0.7462	Spearman: 0.7667
2023-08-03 11:28:00 - Dot-Product-Similarity:	Pearson: 0.7494	Spearman: 0.7543
2023-08-03 11:28:00 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:28:06 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 0:
2023-08-03 11:28:09 - Cosine-Similarity :	Pearson: 0.7736	Spearman: 0.7758
2023-08-03 11:28:09 - Manhattan-Distance:	Pearson: 0.7468	Spearman: 0.7668
2023-08-03 11:28:09 - Euclidean-Distance:	Pearson: 0.7476	Spearman: 0.7680
2023-08-03 11:28:09 - Dot-Product-Similarity:	Pearson: 0.7500	Spearman: 0.7548
2023-08-03 11:28:09 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:28:21 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 16 steps:
2023-08-03 11:28:24 - Cosine-Similarity :	Pearson: 0.7746	Spearman: 0.7766
2023-08-03 11:28:24 - Manhattan-Distance:	Pearson: 0.7479	Spearman: 0.7673
2023-08-03 11:28:24 - Euclidean-Distance:	Pearson: 0.7487	Spearman: 0.7685
2023-08-03 11:28:24 - Dot-Product-Similarity:	Pearson: 0.7517	Spearman: 0.7567
2023-08-03 11:28:24 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:28:37 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 32 steps:
2023-08-03 11:28:40 - Cosine-Similarity :	Pearson: 0.7752	Spearman: 0.7776
2023-08-03 11:28:40 - Manhattan-Distance:	Pearson: 0.7491	Spearman: 0.7686
2023-08-03 11:28:40 - Euclidean-Distance:	Pearson: 0.7499	Spearman: 0.7699
2023-08-03 11:28:40 - Dot-Product-Similarity:	Pearson: 0.7517	Spearman: 0.7563
2023-08-03 11:28:40 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:28:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 48 steps:
2023-08-03 11:28:56 - Cosine-Similarity :	Pearson: 0.7739	Spearman: 0.7759
2023-08-03 11:28:56 - Manhattan-Distance:	Pearson: 0.7481	Spearman: 0.7676
2023-08-03 11:28:56 - Euclidean-Distance:	Pearson: 0.7488	Spearman: 0.7685
2023-08-03 11:28:56 - Dot-Product-Similarity:	Pearson: 0.7500	Spearman: 0.7547
2023-08-03 11:29:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 64 steps:
2023-08-03 11:29:04 - Cosine-Similarity :	Pearson: 0.7742	Spearman: 0.7765
2023-08-03 11:29:04 - Manhattan-Distance:	Pearson: 0.7482	Spearman: 0.7678
2023-08-03 11:29:04 - Euclidean-Distance:	Pearson: 0.7489	Spearman: 0.7687
2023-08-03 11:29:04 - Dot-Product-Similarity:	Pearson: 0.7502	Spearman: 0.7551
2023-08-03 11:29:10 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 80 steps:
2023-08-03 11:29:13 - Cosine-Similarity :	Pearson: 0.7771	Spearman: 0.7794
2023-08-03 11:29:13 - Manhattan-Distance:	Pearson: 0.7515	Spearman: 0.7709
2023-08-03 11:29:13 - Euclidean-Distance:	Pearson: 0.7523	Spearman: 0.7719
2023-08-03 11:29:13 - Dot-Product-Similarity:	Pearson: 0.7531	Spearman: 0.7576
2023-08-03 11:29:13 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:29:22 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 96 steps:
2023-08-03 11:29:25 - Cosine-Similarity :	Pearson: 0.7779	Spearman: 0.7799
2023-08-03 11:29:25 - Manhattan-Distance:	Pearson: 0.7525	Spearman: 0.7716
2023-08-03 11:29:25 - Euclidean-Distance:	Pearson: 0.7533	Spearman: 0.7728
2023-08-03 11:29:25 - Dot-Product-Similarity:	Pearson: 0.7541	Spearman: 0.7585
2023-08-03 11:29:25 - Save model to ./outputs/consert-sts-unsup-macbert-2-MultipleNegativesRankingLoss-2023-08-03_11-25-25
2023-08-03 11:29:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 112 steps:
2023-08-03 11:29:38 - Cosine-Similarity :	Pearson: 0.7752	Spearman: 0.7774
2023-08-03 11:29:38 - Manhattan-Distance:	Pearson: 0.7503	Spearman: 0.7693
2023-08-03 11:29:38 - Euclidean-Distance:	Pearson: 0.7511	Spearman: 0.7706
2023-08-03 11:29:38 - Dot-Product-Similarity:	Pearson: 0.7514	Spearman: 0.7561
2023-08-03 11:29:44 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 128 steps:
2023-08-03 11:29:47 - Cosine-Similarity :	Pearson: 0.7750	Spearman: 0.7771
2023-08-03 11:29:47 - Manhattan-Distance:	Pearson: 0.7501	Spearman: 0.7691
2023-08-03 11:29:47 - Euclidean-Distance:	Pearson: 0.7509	Spearman: 0.7703
2023-08-03 11:29:47 - Dot-Product-Similarity:	Pearson: 0.7513	Spearman: 0.7561
2023-08-03 11:29:53 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 144 steps:
2023-08-03 11:29:56 - Cosine-Similarity :	Pearson: 0.7748	Spearman: 0.7770
2023-08-03 11:29:56 - Manhattan-Distance:	Pearson: 0.7497	Spearman: 0.7687
2023-08-03 11:29:56 - Euclidean-Distance:	Pearson: 0.7505	Spearman: 0.7699
2023-08-03 11:29:56 - Dot-Product-Similarity:	Pearson: 0.7512	Spearman: 0.7560
2023-08-03 11:30:02 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset in epoch 1 after 160 steps:
2023-08-03 11:30:05 - Cosine-Similarity :	Pearson: 0.7747	Spearman: 0.7770
2023-08-03 11:30:05 - Manhattan-Distance:	Pearson: 0.7494	Spearman: 0.7685
2023-08-03 11:30:05 - Euclidean-Distance:	Pearson: 0.7502	Spearman: 0.7698
2023-08-03 11:30:05 - Dot-Product-Similarity:	Pearson: 0.7513	Spearman: 0.7562
2023-08-03 11:30:06 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-dev dataset after epoch 1:
2023-08-03 11:30:09 - Cosine-Similarity :	Pearson: 0.7747	Spearman: 0.7770
2023-08-03 11:30:09 - Manhattan-Distance:	Pearson: 0.7494	Spearman: 0.7685
2023-08-03 11:30:09 - Euclidean-Distance:	Pearson: 0.7502	Spearman: 0.7698
2023-08-03 11:30:09 - Dot-Product-Similarity:	Pearson: 0.7513	Spearman: 0.7562
2023-08-03 11:30:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-unsup-test dataset:
2023-08-03 11:30:11 - Cosine-Similarity :	Pearson: 0.7200	Spearman: 0.7110
2023-08-03 11:30:11 - Manhattan-Distance:	Pearson: 0.6979	Spearman: 0.6994
2023-08-03 11:30:11 - Euclidean-Distance:	Pearson: 0.6978	Spearman: 0.6990
2023-08-03 11:30:11 - Dot-Product-Similarity:	Pearson: 0.7047	Spearman: 0.6961
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 11:21:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 11:21:20 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 11:21:20 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 11:21:20 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 11:21:20 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 11:22:01 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 11:22:03 - Cosine-Similarity :	Pearson: 0.6385	Spearman: 0.6631
2023-08-03 11:22:03 - Manhattan-Distance:	Pearson: 0.6699	Spearman: 0.6744
2023-08-03 11:22:03 - Euclidean-Distance:	Pearson: 0.6629	Spearman: 0.6686
2023-08-03 11:22:03 - Dot-Product-Similarity:	Pearson: 0.6186	Spearman: 0.6315
2023-08-03 11:22:03 - Save model to ./outputs/simcse-snli-unsup-macbert-2-TripletLoss-2023-08-03_11-21-01
2023-08-03 11:22:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 11:22:54 - Cosine-Similarity :	Pearson: 0.6026	Spearman: 0.6297
2023-08-03 11:22:54 - Manhattan-Distance:	Pearson: 0.6434	Spearman: 0.6452
2023-08-03 11:22:54 - Euclidean-Distance:	Pearson: 0.6308	Spearman: 0.6350
2023-08-03 11:22:54 - Dot-Product-Similarity:	Pearson: 0.5880	Spearman: 0.6058
2023-08-03 11:23:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 11:23:37 - Cosine-Similarity :	Pearson: 0.6314	Spearman: 0.6554
2023-08-03 11:23:37 - Manhattan-Distance:	Pearson: 0.6616	Spearman: 0.6607
2023-08-03 11:23:37 - Euclidean-Distance:	Pearson: 0.6550	Spearman: 0.6565
2023-08-03 11:23:37 - Dot-Product-Similarity:	Pearson: 0.6250	Spearman: 0.6447
2023-08-03 11:24:23 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 11:24:26 - Cosine-Similarity :	Pearson: 0.6212	Spearman: 0.6490
2023-08-03 11:24:26 - Manhattan-Distance:	Pearson: 0.6541	Spearman: 0.6566
2023-08-03 11:24:26 - Euclidean-Distance:	Pearson: 0.6462	Spearman: 0.6504
2023-08-03 11:24:26 - Dot-Product-Similarity:	Pearson: 0.6177	Spearman: 0.6439
2023-08-03 11:25:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 11:25:19 - Cosine-Similarity :	Pearson: 0.5896	Spearman: 0.6222
2023-08-03 11:25:19 - Manhattan-Distance:	Pearson: 0.6295	Spearman: 0.6313
2023-08-03 11:25:19 - Euclidean-Distance:	Pearson: 0.6199	Spearman: 0.6245
2023-08-03 11:25:19 - Dot-Product-Similarity:	Pearson: 0.5859	Spearman: 0.6180
2023-08-03 11:26:02 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 11:26:05 - Cosine-Similarity :	Pearson: 0.5782	Spearman: 0.6110
2023-08-03 11:26:05 - Manhattan-Distance:	Pearson: 0.6192	Spearman: 0.6215
2023-08-03 11:26:05 - Euclidean-Distance:	Pearson: 0.6094	Spearman: 0.6133
2023-08-03 11:26:05 - Dot-Product-Similarity:	Pearson: 0.5745	Spearman: 0.6056
2023-08-03 11:26:47 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 11:26:50 - Cosine-Similarity :	Pearson: 0.5782	Spearman: 0.6099
2023-08-03 11:26:50 - Manhattan-Distance:	Pearson: 0.6181	Spearman: 0.6200
2023-08-03 11:26:50 - Euclidean-Distance:	Pearson: 0.6104	Spearman: 0.6130
2023-08-03 11:26:50 - Dot-Product-Similarity:	Pearson: 0.5736	Spearman: 0.6041
2023-08-03 11:27:31 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 11:27:34 - Cosine-Similarity :	Pearson: 0.5897	Spearman: 0.6232
2023-08-03 11:27:34 - Manhattan-Distance:	Pearson: 0.6330	Spearman: 0.6340
2023-08-03 11:27:34 - Euclidean-Distance:	Pearson: 0.6247	Spearman: 0.6271
2023-08-03 11:27:34 - Dot-Product-Similarity:	Pearson: 0.5862	Spearman: 0.6166
2023-08-03 11:28:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 11:28:19 - Cosine-Similarity :	Pearson: 0.5863	Spearman: 0.6152
2023-08-03 11:28:19 - Manhattan-Distance:	Pearson: 0.6253	Spearman: 0.6251
2023-08-03 11:28:19 - Euclidean-Distance:	Pearson: 0.6184	Spearman: 0.6190
2023-08-03 11:28:19 - Dot-Product-Similarity:	Pearson: 0.5829	Spearman: 0.6102
2023-08-03 11:29:00 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 11:29:03 - Cosine-Similarity :	Pearson: 0.5988	Spearman: 0.6283
2023-08-03 11:29:03 - Manhattan-Distance:	Pearson: 0.6356	Spearman: 0.6371
2023-08-03 11:29:03 - Euclidean-Distance:	Pearson: 0.6287	Spearman: 0.6319
2023-08-03 11:29:03 - Dot-Product-Similarity:	Pearson: 0.5962	Spearman: 0.6250
2023-08-03 11:29:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 11:29:06 - Cosine-Similarity :	Pearson: 0.6001	Spearman: 0.6287
2023-08-03 11:29:06 - Manhattan-Distance:	Pearson: 0.6354	Spearman: 0.6369
2023-08-03 11:29:06 - Euclidean-Distance:	Pearson: 0.6286	Spearman: 0.6317
2023-08-03 11:29:06 - Dot-Product-Similarity:	Pearson: 0.5980	Spearman: 0.6264
2023-08-03 11:29:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 11:29:50 - Cosine-Similarity :	Pearson: 0.5889	Spearman: 0.6165
2023-08-03 11:29:50 - Manhattan-Distance:	Pearson: 0.6247	Spearman: 0.6262
2023-08-03 11:29:50 - Euclidean-Distance:	Pearson: 0.6173	Spearman: 0.6204
2023-08-03 11:29:50 - Dot-Product-Similarity:	Pearson: 0.5876	Spearman: 0.6159
2023-08-03 11:30:30 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 11:30:32 - Cosine-Similarity :	Pearson: 0.5996	Spearman: 0.6244
2023-08-03 11:30:32 - Manhattan-Distance:	Pearson: 0.6311	Spearman: 0.6325
2023-08-03 11:30:32 - Euclidean-Distance:	Pearson: 0.6245	Spearman: 0.6270
2023-08-03 11:30:32 - Dot-Product-Similarity:	Pearson: 0.5998	Spearman: 0.6259
2023-08-03 11:31:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 11:31:11 - Cosine-Similarity :	Pearson: 0.6031	Spearman: 0.6279
2023-08-03 11:31:11 - Manhattan-Distance:	Pearson: 0.6351	Spearman: 0.6351
2023-08-03 11:31:11 - Euclidean-Distance:	Pearson: 0.6295	Spearman: 0.6307
2023-08-03 11:31:11 - Dot-Product-Similarity:	Pearson: 0.6018	Spearman: 0.6277
2023-08-03 11:31:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 11:31:50 - Cosine-Similarity :	Pearson: 0.6016	Spearman: 0.6270
2023-08-03 11:31:50 - Manhattan-Distance:	Pearson: 0.6344	Spearman: 0.6342
2023-08-03 11:31:50 - Euclidean-Distance:	Pearson: 0.6287	Spearman: 0.6295
2023-08-03 11:31:50 - Dot-Product-Similarity:	Pearson: 0.6003	Spearman: 0.6266
2023-08-03 11:32:27 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 11:32:29 - Cosine-Similarity :	Pearson: 0.6035	Spearman: 0.6280
2023-08-03 11:32:29 - Manhattan-Distance:	Pearson: 0.6342	Spearman: 0.6348
2023-08-03 11:32:29 - Euclidean-Distance:	Pearson: 0.6292	Spearman: 0.6305
2023-08-03 11:32:29 - Dot-Product-Similarity:	Pearson: 0.6025	Spearman: 0.6277
2023-08-03 11:33:06 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 11:33:08 - Cosine-Similarity :	Pearson: 0.5996	Spearman: 0.6238
2023-08-03 11:33:08 - Manhattan-Distance:	Pearson: 0.6301	Spearman: 0.6310
2023-08-03 11:33:08 - Euclidean-Distance:	Pearson: 0.6246	Spearman: 0.6267
2023-08-03 11:33:08 - Dot-Product-Similarity:	Pearson: 0.5990	Spearman: 0.6236
2023-08-03 11:33:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 11:33:48 - Cosine-Similarity :	Pearson: 0.5991	Spearman: 0.6231
2023-08-03 11:33:48 - Manhattan-Distance:	Pearson: 0.6305	Spearman: 0.6305
2023-08-03 11:33:48 - Euclidean-Distance:	Pearson: 0.6246	Spearman: 0.6260
2023-08-03 11:33:48 - Dot-Product-Similarity:	Pearson: 0.5986	Spearman: 0.6233
2023-08-03 11:34:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 11:34:27 - Cosine-Similarity :	Pearson: 0.5965	Spearman: 0.6215
2023-08-03 11:34:27 - Manhattan-Distance:	Pearson: 0.6291	Spearman: 0.6293
2023-08-03 11:34:27 - Euclidean-Distance:	Pearson: 0.6236	Spearman: 0.6249
2023-08-03 11:34:27 - Dot-Product-Similarity:	Pearson: 0.5951	Spearman: 0.6205
2023-08-03 11:35:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 11:35:06 - Cosine-Similarity :	Pearson: 0.6004	Spearman: 0.6228
2023-08-03 11:35:06 - Manhattan-Distance:	Pearson: 0.6286	Spearman: 0.6295
2023-08-03 11:35:06 - Euclidean-Distance:	Pearson: 0.6233	Spearman: 0.6250
2023-08-03 11:35:06 - Dot-Product-Similarity:	Pearson: 0.6011	Spearman: 0.6253
2023-08-03 11:35:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 11:35:45 - Cosine-Similarity :	Pearson: 0.5992	Spearman: 0.6232
2023-08-03 11:35:45 - Manhattan-Distance:	Pearson: 0.6298	Spearman: 0.6304
2023-08-03 11:35:45 - Euclidean-Distance:	Pearson: 0.6243	Spearman: 0.6258
2023-08-03 11:35:45 - Dot-Product-Similarity:	Pearson: 0.5991	Spearman: 0.6239
2023-08-03 11:35:46 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 11:35:48 - Cosine-Similarity :	Pearson: 0.5992	Spearman: 0.6232
2023-08-03 11:35:48 - Manhattan-Distance:	Pearson: 0.6298	Spearman: 0.6304
2023-08-03 11:35:48 - Euclidean-Distance:	Pearson: 0.6243	Spearman: 0.6258
2023-08-03 11:35:48 - Dot-Product-Similarity:	Pearson: 0.5991	Spearman: 0.6239
2023-08-03 11:35:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 11:35:50 - Cosine-Similarity :	Pearson: 0.6131	Spearman: 0.6343
2023-08-03 11:35:50 - Manhattan-Distance:	Pearson: 0.6417	Spearman: 0.6378
2023-08-03 11:35:50 - Euclidean-Distance:	Pearson: 0.6358	Spearman: 0.6335
2023-08-03 11:35:50 - Dot-Product-Similarity:	Pearson: 0.6167	Spearman: 0.6340
2023-08-03 10:46:05 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 10:46:05 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 10:46:11 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 10:46:17 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 10:46:17 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 10:46:17 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 10:46:17 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 10:50:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-03 10:50:48 - Cosine-Similarity :	Pearson: 0.7189	Spearman: 0.7478
2023-08-03 10:50:48 - Manhattan-Distance:	Pearson: 0.7440	Spearman: 0.7528
2023-08-03 10:50:48 - Euclidean-Distance:	Pearson: 0.7408	Spearman: 0.7501
2023-08-03 10:50:48 - Dot-Product-Similarity:	Pearson: 0.5923	Spearman: 0.5871
2023-08-03 10:50:48 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-57
2023-08-03 10:55:33 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-03 10:55:36 - Cosine-Similarity :	Pearson: 0.7126	Spearman: 0.7403
2023-08-03 10:55:36 - Manhattan-Distance:	Pearson: 0.7478	Spearman: 0.7540
2023-08-03 10:55:36 - Euclidean-Distance:	Pearson: 0.7449	Spearman: 0.7514
2023-08-03 10:55:36 - Dot-Product-Similarity:	Pearson: 0.5823	Spearman: 0.5749
2023-08-03 11:00:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-03 11:00:19 - Cosine-Similarity :	Pearson: 0.7076	Spearman: 0.7422
2023-08-03 11:00:19 - Manhattan-Distance:	Pearson: 0.7433	Spearman: 0.7512
2023-08-03 11:00:19 - Euclidean-Distance:	Pearson: 0.7423	Spearman: 0.7497
2023-08-03 11:00:19 - Dot-Product-Similarity:	Pearson: 0.5911	Spearman: 0.5818
2023-08-03 11:04:58 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-03 11:05:00 - Cosine-Similarity :	Pearson: 0.7050	Spearman: 0.7406
2023-08-03 11:05:00 - Manhattan-Distance:	Pearson: 0.7472	Spearman: 0.7519
2023-08-03 11:05:00 - Euclidean-Distance:	Pearson: 0.7453	Spearman: 0.7498
2023-08-03 11:05:00 - Dot-Product-Similarity:	Pearson: 0.5861	Spearman: 0.5760
2023-08-03 11:09:40 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-03 11:09:43 - Cosine-Similarity :	Pearson: 0.7131	Spearman: 0.7421
2023-08-03 11:09:43 - Manhattan-Distance:	Pearson: 0.7414	Spearman: 0.7469
2023-08-03 11:09:43 - Euclidean-Distance:	Pearson: 0.7408	Spearman: 0.7460
2023-08-03 11:09:43 - Dot-Product-Similarity:	Pearson: 0.6200	Spearman: 0.6171
2023-08-03 11:13:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-03 11:13:42 - Cosine-Similarity :	Pearson: 0.7129	Spearman: 0.7466
2023-08-03 11:13:42 - Manhattan-Distance:	Pearson: 0.7481	Spearman: 0.7535
2023-08-03 11:13:42 - Euclidean-Distance:	Pearson: 0.7476	Spearman: 0.7525
2023-08-03 11:13:42 - Dot-Product-Similarity:	Pearson: 0.6253	Spearman: 0.6235
2023-08-03 11:16:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-03 11:16:20 - Cosine-Similarity :	Pearson: 0.7166	Spearman: 0.7454
2023-08-03 11:16:20 - Manhattan-Distance:	Pearson: 0.7493	Spearman: 0.7522
2023-08-03 11:16:20 - Euclidean-Distance:	Pearson: 0.7489	Spearman: 0.7513
2023-08-03 11:16:20 - Dot-Product-Similarity:	Pearson: 0.6389	Spearman: 0.6371
2023-08-03 11:19:00 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-03 11:19:02 - Cosine-Similarity :	Pearson: 0.7236	Spearman: 0.7553
2023-08-03 11:19:02 - Manhattan-Distance:	Pearson: 0.7572	Spearman: 0.7623
2023-08-03 11:19:02 - Euclidean-Distance:	Pearson: 0.7571	Spearman: 0.7615
2023-08-03 11:19:02 - Dot-Product-Similarity:	Pearson: 0.6414	Spearman: 0.6378
2023-08-03 11:19:02 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_10-45-57
2023-08-03 11:22:05 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-03 11:22:07 - Cosine-Similarity :	Pearson: 0.7202	Spearman: 0.7483
2023-08-03 11:22:07 - Manhattan-Distance:	Pearson: 0.7545	Spearman: 0.7574
2023-08-03 11:22:07 - Euclidean-Distance:	Pearson: 0.7541	Spearman: 0.7568
2023-08-03 11:22:07 - Dot-Product-Similarity:	Pearson: 0.6304	Spearman: 0.6284
2023-08-03 11:29:13 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-03 11:29:15 - Cosine-Similarity :	Pearson: 0.7189	Spearman: 0.7467
2023-08-03 11:29:15 - Manhattan-Distance:	Pearson: 0.7525	Spearman: 0.7558
2023-08-03 11:29:15 - Euclidean-Distance:	Pearson: 0.7513	Spearman: 0.7543
2023-08-03 11:29:15 - Dot-Product-Similarity:	Pearson: 0.6301	Spearman: 0.6270
2023-08-03 11:29:15 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-03 11:29:18 - Cosine-Similarity :	Pearson: 0.7189	Spearman: 0.7467
2023-08-03 11:29:18 - Manhattan-Distance:	Pearson: 0.7525	Spearman: 0.7558
2023-08-03 11:29:18 - Euclidean-Distance:	Pearson: 0.7513	Spearman: 0.7543
2023-08-03 11:29:18 - Dot-Product-Similarity:	Pearson: 0.6301	Spearman: 0.6270
2023-08-03 11:32:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-03 11:32:06 - Cosine-Similarity :	Pearson: 0.7195	Spearman: 0.7481
2023-08-03 11:32:06 - Manhattan-Distance:	Pearson: 0.7517	Spearman: 0.7556
2023-08-03 11:32:06 - Euclidean-Distance:	Pearson: 0.7515	Spearman: 0.7552
2023-08-03 11:32:06 - Dot-Product-Similarity:	Pearson: 0.6491	Spearman: 0.6489
2023-08-03 11:34:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-03 11:34:27 - Cosine-Similarity :	Pearson: 0.7220	Spearman: 0.7497
2023-08-03 11:34:27 - Manhattan-Distance:	Pearson: 0.7529	Spearman: 0.7565
2023-08-03 11:34:27 - Euclidean-Distance:	Pearson: 0.7521	Spearman: 0.7553
2023-08-03 11:34:27 - Dot-Product-Similarity:	Pearson: 0.6423	Spearman: 0.6401
2023-08-03 11:36:31 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-03 11:36:32 - Cosine-Similarity :	Pearson: 0.7171	Spearman: 0.7476
2023-08-03 11:36:32 - Manhattan-Distance:	Pearson: 0.7534	Spearman: 0.7573
2023-08-03 11:36:32 - Euclidean-Distance:	Pearson: 0.7529	Spearman: 0.7564
2023-08-03 11:36:32 - Dot-Product-Similarity:	Pearson: 0.6220	Spearman: 0.6169
2023-08-03 11:38:11 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-03 11:38:13 - Cosine-Similarity :	Pearson: 0.7086	Spearman: 0.7400
2023-08-03 11:38:13 - Manhattan-Distance:	Pearson: 0.7487	Spearman: 0.7515
2023-08-03 11:38:13 - Euclidean-Distance:	Pearson: 0.7477	Spearman: 0.7500
2023-08-03 11:38:13 - Dot-Product-Similarity:	Pearson: 0.6125	Spearman: 0.6075
2023-08-03 11:39:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-03 11:39:53 - Cosine-Similarity :	Pearson: 0.7051	Spearman: 0.7384
2023-08-03 11:39:53 - Manhattan-Distance:	Pearson: 0.7430	Spearman: 0.7475
2023-08-03 11:39:53 - Euclidean-Distance:	Pearson: 0.7419	Spearman: 0.7460
2023-08-03 11:39:53 - Dot-Product-Similarity:	Pearson: 0.6213	Spearman: 0.6180
2023-08-03 11:41:35 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-03 11:41:37 - Cosine-Similarity :	Pearson: 0.7019	Spearman: 0.7369
2023-08-03 11:41:37 - Manhattan-Distance:	Pearson: 0.7441	Spearman: 0.7481
2023-08-03 11:41:37 - Euclidean-Distance:	Pearson: 0.7426	Spearman: 0.7464
2023-08-03 11:41:37 - Dot-Product-Similarity:	Pearson: 0.6039	Spearman: 0.5984
2023-08-03 11:43:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-03 11:43:20 - Cosine-Similarity :	Pearson: 0.7025	Spearman: 0.7350
2023-08-03 11:43:20 - Manhattan-Distance:	Pearson: 0.7428	Spearman: 0.7464
2023-08-03 11:43:20 - Euclidean-Distance:	Pearson: 0.7415	Spearman: 0.7447
2023-08-03 11:43:20 - Dot-Product-Similarity:	Pearson: 0.6075	Spearman: 0.6035
2023-08-03 11:45:01 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-03 11:45:02 - Cosine-Similarity :	Pearson: 0.7017	Spearman: 0.7341
2023-08-03 11:45:02 - Manhattan-Distance:	Pearson: 0.7429	Spearman: 0.7458
2023-08-03 11:45:02 - Euclidean-Distance:	Pearson: 0.7420	Spearman: 0.7449
2023-08-03 11:45:02 - Dot-Product-Similarity:	Pearson: 0.6072	Spearman: 0.6025
2023-08-03 11:46:44 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-03 11:46:46 - Cosine-Similarity :	Pearson: 0.7077	Spearman: 0.7384
2023-08-03 11:46:46 - Manhattan-Distance:	Pearson: 0.7469	Spearman: 0.7501
2023-08-03 11:46:46 - Euclidean-Distance:	Pearson: 0.7457	Spearman: 0.7483
2023-08-03 11:46:46 - Dot-Product-Similarity:	Pearson: 0.6124	Spearman: 0.6073
2023-08-03 11:48:23 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-03 11:48:25 - Cosine-Similarity :	Pearson: 0.7081	Spearman: 0.7396
2023-08-03 11:48:25 - Manhattan-Distance:	Pearson: 0.7471	Spearman: 0.7507
2023-08-03 11:48:25 - Euclidean-Distance:	Pearson: 0.7459	Spearman: 0.7490
2023-08-03 11:48:25 - Dot-Product-Similarity:	Pearson: 0.6141	Spearman: 0.6086
2023-08-03 11:48:25 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-03 11:48:27 - Cosine-Similarity :	Pearson: 0.7081	Spearman: 0.7396
2023-08-03 11:48:27 - Manhattan-Distance:	Pearson: 0.7471	Spearman: 0.7507
2023-08-03 11:48:27 - Euclidean-Distance:	Pearson: 0.7459	Spearman: 0.7490
2023-08-03 11:48:27 - Dot-Product-Similarity:	Pearson: 0.6141	Spearman: 0.6086
2023-08-03 11:48:27 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-03 11:48:28 - Cosine-Similarity :	Pearson: 0.6919	Spearman: 0.7244
2023-08-03 11:48:28 - Manhattan-Distance:	Pearson: 0.7355	Spearman: 0.7328
2023-08-03 11:48:28 - Euclidean-Distance:	Pearson: 0.7341	Spearman: 0.7320
2023-08-03 11:48:28 - Dot-Product-Similarity:	Pearson: 0.5944	Spearman: 0.5867
[2023-08-03 14:26:37,825] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 14:27:08,389] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 14:26:45 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 14:26:45 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 14:26:51 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 14:26:54 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 14:26:54 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 14:26:54 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 14:26:54 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-03 14:29:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-03 14:29:39 - Cosine-Similarity :	Pearson: 0.7473	Spearman: 0.7685
2023-08-03 14:29:39 - Manhattan-Distance:	Pearson: 0.7662	Spearman: 0.7684
2023-08-03 14:29:39 - Euclidean-Distance:	Pearson: 0.7672	Spearman: 0.7696
2023-08-03 14:29:39 - Dot-Product-Similarity:	Pearson: 0.7420	Spearman: 0.7586
2023-08-03 14:29:39 - Save model to ./outputs/esimcse-snli-sup-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-03_14-26-34
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
2023-08-03 14:27:13 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 14:27:13 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 14:27:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 14:27:23 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 14:27:23 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 14:27:23 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 14:27:23 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 14:28:13 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 14:28:16 - Cosine-Similarity :	Pearson: 0.3523	Spearman: 0.3617
2023-08-03 14:28:16 - Manhattan-Distance:	Pearson: 0.3776	Spearman: 0.3810
2023-08-03 14:28:16 - Euclidean-Distance:	Pearson: 0.3671	Spearman: 0.3685
2023-08-03 14:28:16 - Dot-Product-Similarity:	Pearson: 0.2805	Spearman: 0.3056
2023-08-03 14:28:16 - Save model to ./outputs/consert-snli-unsup-macbert-2-TripletLoss-2023-08-03_14-27-06
2023-08-03 14:29:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 14:29:17 - Cosine-Similarity :	Pearson: 0.3260	Spearman: 0.3391
2023-08-03 14:29:17 - Manhattan-Distance:	Pearson: 0.3053	Spearman: 0.3169
2023-08-03 14:29:17 - Euclidean-Distance:	Pearson: 0.3028	Spearman: 0.3143
2023-08-03 14:29:17 - Dot-Product-Similarity:	Pearson: 0.2863	Spearman: 0.3260
2023-08-03 14:30:04 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 14:30:07 - Cosine-Similarity :	Pearson: 0.2943	Spearman: 0.3092
2023-08-03 14:30:07 - Manhattan-Distance:	Pearson: 0.2756	Spearman: 0.2942
2023-08-03 14:30:07 - Euclidean-Distance:	Pearson: 0.2741	Spearman: 0.2919
2023-08-03 14:30:07 - Dot-Product-Similarity:	Pearson: 0.2579	Spearman: 0.2920
2023-08-03 14:31:00 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 14:31:02 - Cosine-Similarity :	Pearson: 0.2405	Spearman: 0.2490
2023-08-03 14:31:02 - Manhattan-Distance:	Pearson: 0.2119	Spearman: 0.2394
2023-08-03 14:31:02 - Euclidean-Distance:	Pearson: 0.2181	Spearman: 0.2484
2023-08-03 14:31:02 - Dot-Product-Similarity:	Pearson: 0.2050	Spearman: 0.2325
2023-08-03 14:31:53 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 14:31:55 - Cosine-Similarity :	Pearson: 0.2985	Spearman: 0.3032
2023-08-03 14:31:55 - Manhattan-Distance:	Pearson: 0.2653	Spearman: 0.2843
2023-08-03 14:31:55 - Euclidean-Distance:	Pearson: 0.2766	Spearman: 0.2947
2023-08-03 14:31:55 - Dot-Product-Similarity:	Pearson: 0.2893	Spearman: 0.2981
2023-08-03 14:32:42 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 14:32:44 - Cosine-Similarity :	Pearson: 0.2449	Spearman: 0.2525
2023-08-03 14:32:44 - Manhattan-Distance:	Pearson: 0.2144	Spearman: 0.2472
2023-08-03 14:32:44 - Euclidean-Distance:	Pearson: 0.2198	Spearman: 0.2544
2023-08-03 14:32:44 - Dot-Product-Similarity:	Pearson: 0.2234	Spearman: 0.2446
2023-08-03 14:33:19 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 14:33:21 - Cosine-Similarity :	Pearson: 0.2682	Spearman: 0.2706
2023-08-03 14:33:21 - Manhattan-Distance:	Pearson: 0.2503	Spearman: 0.2657
2023-08-03 14:33:21 - Euclidean-Distance:	Pearson: 0.2547	Spearman: 0.2671
2023-08-03 14:33:21 - Dot-Product-Similarity:	Pearson: 0.2574	Spearman: 0.2661
2023-08-03 14:33:56 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 14:33:58 - Cosine-Similarity :	Pearson: 0.2035	Spearman: 0.2070
2023-08-03 14:33:58 - Manhattan-Distance:	Pearson: 0.1841	Spearman: 0.1863
2023-08-03 14:33:58 - Euclidean-Distance:	Pearson: 0.1948	Spearman: 0.2020
2023-08-03 14:33:58 - Dot-Product-Similarity:	Pearson: 0.1987	Spearman: 0.2070
2023-08-03 14:34:33 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 14:34:35 - Cosine-Similarity :	Pearson: 0.2001	Spearman: 0.2010
2023-08-03 14:34:35 - Manhattan-Distance:	Pearson: 0.1965	Spearman: 0.1978
2023-08-03 14:34:35 - Euclidean-Distance:	Pearson: 0.2026	Spearman: 0.2064
2023-08-03 14:34:35 - Dot-Product-Similarity:	Pearson: 0.1952	Spearman: 0.1970
2023-08-03 14:35:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 14:35:12 - Cosine-Similarity :	Pearson: 0.1789	Spearman: 0.1810
2023-08-03 14:35:12 - Manhattan-Distance:	Pearson: 0.1678	Spearman: 0.1671
2023-08-03 14:35:12 - Euclidean-Distance:	Pearson: 0.1772	Spearman: 0.1815
2023-08-03 14:35:12 - Dot-Product-Similarity:	Pearson: 0.1710	Spearman: 0.1773
2023-08-03 14:35:13 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 14:35:14 - Cosine-Similarity :	Pearson: 0.1865	Spearman: 0.1875
2023-08-03 14:35:14 - Manhattan-Distance:	Pearson: 0.1774	Spearman: 0.1743
2023-08-03 14:35:14 - Euclidean-Distance:	Pearson: 0.1868	Spearman: 0.1882
2023-08-03 14:35:14 - Dot-Product-Similarity:	Pearson: 0.1786	Spearman: 0.1828
2023-08-03 14:35:50 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 14:35:52 - Cosine-Similarity :	Pearson: 0.2300	Spearman: 0.2308
2023-08-03 14:35:52 - Manhattan-Distance:	Pearson: 0.2179	Spearman: 0.2127
2023-08-03 14:35:52 - Euclidean-Distance:	Pearson: 0.2236	Spearman: 0.2216
2023-08-03 14:35:52 - Dot-Product-Similarity:	Pearson: 0.2288	Spearman: 0.2320
2023-08-03 14:36:26 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 14:36:27 - Cosine-Similarity :	Pearson: 0.2280	Spearman: 0.2354
2023-08-03 14:36:27 - Manhattan-Distance:	Pearson: 0.2175	Spearman: 0.2160
2023-08-03 14:36:27 - Euclidean-Distance:	Pearson: 0.2251	Spearman: 0.2287
2023-08-03 14:36:27 - Dot-Product-Similarity:	Pearson: 0.2215	Spearman: 0.2319
2023-08-03 14:37:03 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 14:37:05 - Cosine-Similarity :	Pearson: 0.2338	Spearman: 0.2391
2023-08-03 14:37:05 - Manhattan-Distance:	Pearson: 0.2195	Spearman: 0.2321
2023-08-03 14:37:05 - Euclidean-Distance:	Pearson: 0.2245	Spearman: 0.2408
2023-08-03 14:37:05 - Dot-Product-Similarity:	Pearson: 0.2244	Spearman: 0.2345
2023-08-03 14:37:40 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 14:37:42 - Cosine-Similarity :	Pearson: 0.2181	Spearman: 0.2145
2023-08-03 14:37:42 - Manhattan-Distance:	Pearson: 0.2092	Spearman: 0.2031
2023-08-03 14:37:42 - Euclidean-Distance:	Pearson: 0.2137	Spearman: 0.2120
2023-08-03 14:37:42 - Dot-Product-Similarity:	Pearson: 0.2243	Spearman: 0.2209
2023-08-03 14:38:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 14:38:19 - Cosine-Similarity :	Pearson: 0.2171	Spearman: 0.2175
2023-08-03 14:38:19 - Manhattan-Distance:	Pearson: 0.2140	Spearman: 0.2105
2023-08-03 14:38:19 - Euclidean-Distance:	Pearson: 0.2183	Spearman: 0.2184
2023-08-03 14:38:19 - Dot-Product-Similarity:	Pearson: 0.2165	Spearman: 0.2186
2023-08-03 14:38:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 14:38:56 - Cosine-Similarity :	Pearson: 0.2029	Spearman: 0.2047
2023-08-03 14:38:56 - Manhattan-Distance:	Pearson: 0.2014	Spearman: 0.1976
2023-08-03 14:38:56 - Euclidean-Distance:	Pearson: 0.2078	Spearman: 0.2080
2023-08-03 14:38:56 - Dot-Product-Similarity:	Pearson: 0.2010	Spearman: 0.2037
2023-08-03 14:39:31 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 14:39:33 - Cosine-Similarity :	Pearson: 0.2091	Spearman: 0.2111
2023-08-03 14:39:33 - Manhattan-Distance:	Pearson: 0.2056	Spearman: 0.2043
2023-08-03 14:39:33 - Euclidean-Distance:	Pearson: 0.2122	Spearman: 0.2156
2023-08-03 14:39:33 - Dot-Product-Similarity:	Pearson: 0.2027	Spearman: 0.2066
2023-08-03 14:40:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 14:40:10 - Cosine-Similarity :	Pearson: 0.2013	Spearman: 0.2049
2023-08-03 14:40:10 - Manhattan-Distance:	Pearson: 0.1930	Spearman: 0.1963
2023-08-03 14:40:10 - Euclidean-Distance:	Pearson: 0.1994	Spearman: 0.2066
2023-08-03 14:40:10 - Dot-Product-Similarity:	Pearson: 0.1910	Spearman: 0.1988
2023-08-03 14:40:46 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 14:40:48 - Cosine-Similarity :	Pearson: 0.1955	Spearman: 0.2001
2023-08-03 14:40:48 - Manhattan-Distance:	Pearson: 0.1963	Spearman: 0.1900
2023-08-03 14:40:48 - Euclidean-Distance:	Pearson: 0.2024	Spearman: 0.2007
2023-08-03 14:40:48 - Dot-Product-Similarity:	Pearson: 0.1903	Spearman: 0.1944
2023-08-03 14:41:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 14:41:25 - Cosine-Similarity :	Pearson: 0.1972	Spearman: 0.2015
2023-08-03 14:41:25 - Manhattan-Distance:	Pearson: 0.1989	Spearman: 0.1878
2023-08-03 14:41:25 - Euclidean-Distance:	Pearson: 0.2053	Spearman: 0.1995
2023-08-03 14:41:25 - Dot-Product-Similarity:	Pearson: 0.1934	Spearman: 0.1968
2023-08-03 14:41:26 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 14:41:28 - Cosine-Similarity :	Pearson: 0.1972	Spearman: 0.2015
2023-08-03 14:41:28 - Manhattan-Distance:	Pearson: 0.1989	Spearman: 0.1878
2023-08-03 14:41:28 - Euclidean-Distance:	Pearson: 0.2053	Spearman: 0.1996
2023-08-03 14:41:28 - Dot-Product-Similarity:	Pearson: 0.1934	Spearman: 0.1968
2023-08-03 14:41:28 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 14:41:29 - Cosine-Similarity :	Pearson: 0.2108	Spearman: 0.2064
2023-08-03 14:41:29 - Manhattan-Distance:	Pearson: 0.1854	Spearman: 0.1650
2023-08-03 14:41:29 - Euclidean-Distance:	Pearson: 0.1918	Spearman: 0.1753
2023-08-03 14:41:29 - Dot-Product-Similarity:	Pearson: 0.2136	Spearman: 0.2078
[2023-08-03 15:01:39,175] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 15:01:46 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 15:01:46 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 15:01:53 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 15:01:56 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 15:01:56 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 15:01:56 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 15:01:56 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
[2023-08-03 15:18:16,740] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 15:18:25 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 15:18:25 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 15:18:32 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 15:18:35 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-03 15:18:35 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-03 15:18:35 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-03 15:18:35 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:11 in <module>                 │
│                                                                              │
│    8 │   │   │   │   level=logging.INFO,                                     │
│    9 │   │   │   │   handlers=[LoggingHandler()])                            │
│   10 │                                                                       │
│ ❱ 11 │   train()                                                             │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
[2023-08-03 15:21:06,657] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 15:21:14,356] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-03 15:27:56,489] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-03 15:21:19 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 15:21:19 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 146828
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 146828
Warmup-steps: 459
Performance before training
2023-08-03 15:21:22 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset:
2023-08-03 15:21:27 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 15:21:27 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 15:21:27 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 15:21:27 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 15:22:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 229 steps:
2023-08-03 15:22:19 - Cosine-Similarity :	Pearson: 0.4067	Spearman: 0.4143
2023-08-03 15:22:19 - Manhattan-Distance:	Pearson: 0.4153	Spearman: 0.4191
2023-08-03 15:22:19 - Euclidean-Distance:	Pearson: 0.4091	Spearman: 0.4122
2023-08-03 15:22:19 - Dot-Product-Similarity:	Pearson: 0.3345	Spearman: 0.3653
2023-08-03 15:22:19 - Save model to ./outputs/consert-snli-unsup-macbert-2-TripletLoss-2023-08-03_15-21-12
2023-08-03 15:23:15 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 458 steps:
2023-08-03 15:23:17 - Cosine-Similarity :	Pearson: 0.3081	Spearman: 0.3164
2023-08-03 15:23:17 - Manhattan-Distance:	Pearson: 0.2939	Spearman: 0.3223
2023-08-03 15:23:17 - Euclidean-Distance:	Pearson: 0.2886	Spearman: 0.3141
2023-08-03 15:23:17 - Dot-Product-Similarity:	Pearson: 0.2516	Spearman: 0.2883
2023-08-03 15:24:06 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 687 steps:
2023-08-03 15:24:08 - Cosine-Similarity :	Pearson: 0.3906	Spearman: 0.4026
2023-08-03 15:24:08 - Manhattan-Distance:	Pearson: 0.3633	Spearman: 0.3735
2023-08-03 15:24:08 - Euclidean-Distance:	Pearson: 0.3634	Spearman: 0.3725
2023-08-03 15:24:08 - Dot-Product-Similarity:	Pearson: 0.3576	Spearman: 0.3742
2023-08-03 15:24:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 916 steps:
2023-08-03 15:24:56 - Cosine-Similarity :	Pearson: 0.2467	Spearman: 0.2526
2023-08-03 15:24:56 - Manhattan-Distance:	Pearson: 0.2159	Spearman: 0.2432
2023-08-03 15:24:56 - Euclidean-Distance:	Pearson: 0.2181	Spearman: 0.2456
2023-08-03 15:24:56 - Dot-Product-Similarity:	Pearson: 0.2187	Spearman: 0.2449
2023-08-03 15:25:45 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1145 steps:
2023-08-03 15:25:48 - Cosine-Similarity :	Pearson: 0.2992	Spearman: 0.3054
2023-08-03 15:25:48 - Manhattan-Distance:	Pearson: 0.2717	Spearman: 0.2917
2023-08-03 15:25:48 - Euclidean-Distance:	Pearson: 0.2770	Spearman: 0.2986
2023-08-03 15:25:48 - Dot-Product-Similarity:	Pearson: 0.2718	Spearman: 0.2853
2023-08-03 15:26:37 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1374 steps:
2023-08-03 15:26:39 - Cosine-Similarity :	Pearson: 0.2699	Spearman: 0.2693
2023-08-03 15:26:39 - Manhattan-Distance:	Pearson: 0.2463	Spearman: 0.2462
2023-08-03 15:26:39 - Euclidean-Distance:	Pearson: 0.2519	Spearman: 0.2557
2023-08-03 15:26:39 - Dot-Product-Similarity:	Pearson: 0.2523	Spearman: 0.2611
2023-08-03 15:27:28 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1603 steps:
2023-08-03 15:27:30 - Cosine-Similarity :	Pearson: 0.2673	Spearman: 0.2756
2023-08-03 15:27:30 - Manhattan-Distance:	Pearson: 0.2486	Spearman: 0.2577
2023-08-03 15:27:30 - Euclidean-Distance:	Pearson: 0.2551	Spearman: 0.2665
2023-08-03 15:27:30 - Dot-Product-Similarity:	Pearson: 0.2461	Spearman: 0.2633
2023-08-03 15:28:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 1832 steps:
2023-08-03 15:28:26 - Cosine-Similarity :	Pearson: 0.2871	Spearman: 0.2890
2023-08-03 15:28:26 - Manhattan-Distance:	Pearson: 0.2626	Spearman: 0.2682
2023-08-03 15:28:26 - Euclidean-Distance:	Pearson: 0.2697	Spearman: 0.2780
2023-08-03 15:28:26 - Dot-Product-Similarity:	Pearson: 0.2863	Spearman: 0.2887
2023-08-03 15:29:48 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2061 steps:
2023-08-03 15:29:50 - Cosine-Similarity :	Pearson: 0.2689	Spearman: 0.2713
2023-08-03 15:29:50 - Manhattan-Distance:	Pearson: 0.2402	Spearman: 0.2426
2023-08-03 15:29:50 - Euclidean-Distance:	Pearson: 0.2480	Spearman: 0.2518
2023-08-03 15:29:50 - Dot-Product-Similarity:	Pearson: 0.2746	Spearman: 0.2795
2023-08-03 15:31:29 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 0 after 2290 steps:
2023-08-03 15:31:32 - Cosine-Similarity :	Pearson: 0.2623	Spearman: 0.2622
2023-08-03 15:31:32 - Manhattan-Distance:	Pearson: 0.2327	Spearman: 0.2374
2023-08-03 15:31:32 - Euclidean-Distance:	Pearson: 0.2410	Spearman: 0.2490
2023-08-03 15:31:32 - Dot-Product-Similarity:	Pearson: 0.2493	Spearman: 0.2576
2023-08-03 15:31:34 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 0:
2023-08-03 15:31:36 - Cosine-Similarity :	Pearson: 0.2596	Spearman: 0.2599
2023-08-03 15:31:36 - Manhattan-Distance:	Pearson: 0.2300	Spearman: 0.2341
2023-08-03 15:31:36 - Euclidean-Distance:	Pearson: 0.2377	Spearman: 0.2456
2023-08-03 15:31:36 - Dot-Product-Similarity:	Pearson: 0.2488	Spearman: 0.2573
2023-08-03 15:33:17 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 229 steps:
2023-08-03 15:33:19 - Cosine-Similarity :	Pearson: 0.2702	Spearman: 0.2763
2023-08-03 15:33:19 - Manhattan-Distance:	Pearson: 0.2581	Spearman: 0.2599
2023-08-03 15:33:19 - Euclidean-Distance:	Pearson: 0.2648	Spearman: 0.2678
2023-08-03 15:33:19 - Dot-Product-Similarity:	Pearson: 0.2672	Spearman: 0.2727
2023-08-03 15:34:58 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 458 steps:
2023-08-03 15:35:01 - Cosine-Similarity :	Pearson: 0.2131	Spearman: 0.2172
2023-08-03 15:35:01 - Manhattan-Distance:	Pearson: 0.1944	Spearman: 0.1977
2023-08-03 15:35:01 - Euclidean-Distance:	Pearson: 0.2072	Spearman: 0.2184
2023-08-03 15:35:01 - Dot-Product-Similarity:	Pearson: 0.2002	Spearman: 0.2067
2023-08-03 15:36:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 687 steps:
2023-08-03 15:36:41 - Cosine-Similarity :	Pearson: 0.1948	Spearman: 0.1966
2023-08-03 15:36:41 - Manhattan-Distance:	Pearson: 0.1834	Spearman: 0.1834
2023-08-03 15:36:41 - Euclidean-Distance:	Pearson: 0.1950	Spearman: 0.1970
2023-08-03 15:36:41 - Dot-Product-Similarity:	Pearson: 0.1825	Spearman: 0.1856
2023-08-03 15:38:22 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 916 steps:
2023-08-03 15:38:24 - Cosine-Similarity :	Pearson: 0.2005	Spearman: 0.1987
2023-08-03 15:38:24 - Manhattan-Distance:	Pearson: 0.1929	Spearman: 0.1816
2023-08-03 15:38:24 - Euclidean-Distance:	Pearson: 0.2020	Spearman: 0.1936
2023-08-03 15:38:24 - Dot-Product-Similarity:	Pearson: 0.1965	Spearman: 0.1942
2023-08-03 15:40:06 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1145 steps:
2023-08-03 15:40:09 - Cosine-Similarity :	Pearson: 0.2129	Spearman: 0.2095
2023-08-03 15:40:09 - Manhattan-Distance:	Pearson: 0.2027	Spearman: 0.1973
2023-08-03 15:40:09 - Euclidean-Distance:	Pearson: 0.2111	Spearman: 0.2077
2023-08-03 15:40:09 - Dot-Product-Similarity:	Pearson: 0.2092	Spearman: 0.2061
2023-08-03 15:41:47 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1374 steps:
2023-08-03 15:41:50 - Cosine-Similarity :	Pearson: 0.2264	Spearman: 0.2261
2023-08-03 15:41:50 - Manhattan-Distance:	Pearson: 0.2081	Spearman: 0.2011
2023-08-03 15:41:50 - Euclidean-Distance:	Pearson: 0.2161	Spearman: 0.2128
2023-08-03 15:41:50 - Dot-Product-Similarity:	Pearson: 0.2249	Spearman: 0.2241
2023-08-03 15:43:29 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1603 steps:
2023-08-03 15:43:31 - Cosine-Similarity :	Pearson: 0.2053	Spearman: 0.2015
2023-08-03 15:43:31 - Manhattan-Distance:	Pearson: 0.1889	Spearman: 0.1848
2023-08-03 15:43:31 - Euclidean-Distance:	Pearson: 0.1966	Spearman: 0.1975
2023-08-03 15:43:31 - Dot-Product-Similarity:	Pearson: 0.1970	Spearman: 0.1964
2023-08-03 15:45:11 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 1832 steps:
2023-08-03 15:45:14 - Cosine-Similarity :	Pearson: 0.2301	Spearman: 0.2263
2023-08-03 15:45:14 - Manhattan-Distance:	Pearson: 0.2099	Spearman: 0.1971
2023-08-03 15:45:14 - Euclidean-Distance:	Pearson: 0.2193	Spearman: 0.2092
2023-08-03 15:45:14 - Dot-Product-Similarity:	Pearson: 0.2260	Spearman: 0.2223
2023-08-03 15:46:54 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2061 steps:
2023-08-03 15:46:57 - Cosine-Similarity :	Pearson: 0.2302	Spearman: 0.2256
2023-08-03 15:46:57 - Manhattan-Distance:	Pearson: 0.2166	Spearman: 0.2041
2023-08-03 15:46:57 - Euclidean-Distance:	Pearson: 0.2258	Spearman: 0.2172
2023-08-03 15:46:57 - Dot-Product-Similarity:	Pearson: 0.2239	Spearman: 0.2197
2023-08-03 15:48:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset in epoch 1 after 2290 steps:
2023-08-03 15:48:38 - Cosine-Similarity :	Pearson: 0.2376	Spearman: 0.2326
2023-08-03 15:48:38 - Manhattan-Distance:	Pearson: 0.2222	Spearman: 0.2096
2023-08-03 15:48:38 - Euclidean-Distance:	Pearson: 0.2316	Spearman: 0.2227
2023-08-03 15:48:38 - Dot-Product-Similarity:	Pearson: 0.2324	Spearman: 0.2275
2023-08-03 15:48:40 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-dev dataset after epoch 1:
2023-08-03 15:48:43 - Cosine-Similarity :	Pearson: 0.2376	Spearman: 0.2326
2023-08-03 15:48:43 - Manhattan-Distance:	Pearson: 0.2222	Spearman: 0.2096
2023-08-03 15:48:43 - Euclidean-Distance:	Pearson: 0.2316	Spearman: 0.2227
2023-08-03 15:48:43 - Dot-Product-Similarity:	Pearson: 0.2324	Spearman: 0.2274
2023-08-03 15:48:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-unsup-test dataset:
2023-08-03 15:48:45 - Cosine-Similarity :	Pearson: 0.2480	Spearman: 0.2433
2023-08-03 15:48:45 - Manhattan-Distance:	Pearson: 0.2049	Spearman: 0.1956
2023-08-03 15:48:45 - Euclidean-Distance:	Pearson: 0.2149	Spearman: 0.2095
2023-08-03 15:48:45 - Dot-Product-Similarity:	Pearson: 0.2564	Spearman: 0.2539
2023-08-03 15:21:12 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 15:21:12 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 15:21:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 15:21:22 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 15:21:22 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 15:21:22 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 15:21:22 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 15:24:14 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-03 15:24:16 - Cosine-Similarity :	Pearson: 0.7216	Spearman: 0.7486
2023-08-03 15:24:16 - Manhattan-Distance:	Pearson: 0.7507	Spearman: 0.7573
2023-08-03 15:24:16 - Euclidean-Distance:	Pearson: 0.7452	Spearman: 0.7538
2023-08-03 15:24:16 - Dot-Product-Similarity:	Pearson: 0.5707	Spearman: 0.5638
2023-08-03 15:24:16 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-21-04
2023-08-03 15:27:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-03 15:27:26 - Cosine-Similarity :	Pearson: 0.7108	Spearman: 0.7412
2023-08-03 15:27:26 - Manhattan-Distance:	Pearson: 0.7434	Spearman: 0.7514
2023-08-03 15:27:26 - Euclidean-Distance:	Pearson: 0.7405	Spearman: 0.7487
2023-08-03 15:27:26 - Dot-Product-Similarity:	Pearson: 0.5454	Spearman: 0.5396
2023-08-03 15:32:23 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-03 15:32:26 - Cosine-Similarity :	Pearson: 0.7178	Spearman: 0.7442
2023-08-03 15:32:26 - Manhattan-Distance:	Pearson: 0.7479	Spearman: 0.7536
2023-08-03 15:32:26 - Euclidean-Distance:	Pearson: 0.7463	Spearman: 0.7518
2023-08-03 15:32:26 - Dot-Product-Similarity:	Pearson: 0.6054	Spearman: 0.6051
2023-08-03 15:38:27 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-03 15:38:29 - Cosine-Similarity :	Pearson: 0.7065	Spearman: 0.7380
2023-08-03 15:38:29 - Manhattan-Distance:	Pearson: 0.7475	Spearman: 0.7512
2023-08-03 15:38:29 - Euclidean-Distance:	Pearson: 0.7454	Spearman: 0.7490
2023-08-03 15:38:29 - Dot-Product-Similarity:	Pearson: 0.5648	Spearman: 0.5559
2023-08-03 15:44:30 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-03 15:44:33 - Cosine-Similarity :	Pearson: 0.7159	Spearman: 0.7455
2023-08-03 15:44:33 - Manhattan-Distance:	Pearson: 0.7496	Spearman: 0.7539
2023-08-03 15:44:33 - Euclidean-Distance:	Pearson: 0.7489	Spearman: 0.7528
2023-08-03 15:44:33 - Dot-Product-Similarity:	Pearson: 0.6117	Spearman: 0.6032
2023-08-03 15:50:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-03 15:50:10 - Cosine-Similarity :	Pearson: 0.7146	Spearman: 0.7486
2023-08-03 15:50:10 - Manhattan-Distance:	Pearson: 0.7476	Spearman: 0.7536
2023-08-03 15:50:10 - Euclidean-Distance:	Pearson: 0.7464	Spearman: 0.7525
2023-08-03 15:50:10 - Dot-Product-Similarity:	Pearson: 0.6202	Spearman: 0.6186
2023-08-03 15:50:10 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-21-04
2023-08-03 15:54:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-03 15:54:42 - Cosine-Similarity :	Pearson: 0.7185	Spearman: 0.7457
2023-08-03 15:54:42 - Manhattan-Distance:	Pearson: 0.7548	Spearman: 0.7587
2023-08-03 15:54:42 - Euclidean-Distance:	Pearson: 0.7536	Spearman: 0.7569
2023-08-03 15:54:42 - Dot-Product-Similarity:	Pearson: 0.5962	Spearman: 0.5930
2023-08-03 15:59:08 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-03 15:59:11 - Cosine-Similarity :	Pearson: 0.7223	Spearman: 0.7497
2023-08-03 15:59:11 - Manhattan-Distance:	Pearson: 0.7536	Spearman: 0.7578
2023-08-03 15:59:11 - Euclidean-Distance:	Pearson: 0.7527	Spearman: 0.7563
2023-08-03 15:59:11 - Dot-Product-Similarity:	Pearson: 0.6185	Spearman: 0.6143
2023-08-03 15:59:11 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-21-04
2023-08-03 16:03:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-03 16:03:41 - Cosine-Similarity :	Pearson: 0.7216	Spearman: 0.7526
2023-08-03 16:03:41 - Manhattan-Distance:	Pearson: 0.7560	Spearman: 0.7611
2023-08-03 16:03:41 - Euclidean-Distance:	Pearson: 0.7556	Spearman: 0.7602
2023-08-03 16:03:41 - Dot-Product-Similarity:	Pearson: 0.6417	Spearman: 0.6406
2023-08-03 16:03:41 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-21-04
2023-08-03 16:08:12 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-03 16:08:15 - Cosine-Similarity :	Pearson: 0.7334	Spearman: 0.7626
2023-08-03 16:08:15 - Manhattan-Distance:	Pearson: 0.7641	Spearman: 0.7693
2023-08-03 16:08:15 - Euclidean-Distance:	Pearson: 0.7634	Spearman: 0.7681
2023-08-03 16:08:15 - Dot-Product-Similarity:	Pearson: 0.6370	Spearman: 0.6371
2023-08-03 16:08:15 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-21-04
2023-08-03 16:08:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-03 16:08:20 - Cosine-Similarity :	Pearson: 0.7334	Spearman: 0.7626
2023-08-03 16:08:20 - Manhattan-Distance:	Pearson: 0.7641	Spearman: 0.7693
2023-08-03 16:08:20 - Euclidean-Distance:	Pearson: 0.7634	Spearman: 0.7681
2023-08-03 16:08:20 - Dot-Product-Similarity:	Pearson: 0.6370	Spearman: 0.6371
2023-08-03 16:12:47 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-03 16:12:49 - Cosine-Similarity :	Pearson: 0.7215	Spearman: 0.7508
2023-08-03 16:12:49 - Manhattan-Distance:	Pearson: 0.7587	Spearman: 0.7622
2023-08-03 16:12:49 - Euclidean-Distance:	Pearson: 0.7576	Spearman: 0.7606
2023-08-03 16:12:49 - Dot-Product-Similarity:	Pearson: 0.6105	Spearman: 0.6075
2023-08-03 16:17:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-03 16:17:18 - Cosine-Similarity :	Pearson: 0.7288	Spearman: 0.7576
2023-08-03 16:17:18 - Manhattan-Distance:	Pearson: 0.7635	Spearman: 0.7676
2023-08-03 16:17:18 - Euclidean-Distance:	Pearson: 0.7624	Spearman: 0.7660
2023-08-03 16:17:18 - Dot-Product-Similarity:	Pearson: 0.6357	Spearman: 0.6357
2023-08-03 16:20:49 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-03 16:20:52 - Cosine-Similarity :	Pearson: 0.7264	Spearman: 0.7558
2023-08-03 16:20:52 - Manhattan-Distance:	Pearson: 0.7601	Spearman: 0.7645
2023-08-03 16:20:52 - Euclidean-Distance:	Pearson: 0.7593	Spearman: 0.7631
2023-08-03 16:20:52 - Dot-Product-Similarity:	Pearson: 0.6299	Spearman: 0.6270
2023-08-03 16:23:27 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-03 16:23:30 - Cosine-Similarity :	Pearson: 0.7150	Spearman: 0.7477
2023-08-03 16:23:30 - Manhattan-Distance:	Pearson: 0.7549	Spearman: 0.7589
2023-08-03 16:23:30 - Euclidean-Distance:	Pearson: 0.7538	Spearman: 0.7570
2023-08-03 16:23:30 - Dot-Product-Similarity:	Pearson: 0.6066	Spearman: 0.6007
2023-08-03 16:26:09 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-03 16:26:12 - Cosine-Similarity :	Pearson: 0.7165	Spearman: 0.7477
2023-08-03 16:26:12 - Manhattan-Distance:	Pearson: 0.7540	Spearman: 0.7583
2023-08-03 16:26:12 - Euclidean-Distance:	Pearson: 0.7530	Spearman: 0.7568
2023-08-03 16:26:12 - Dot-Product-Similarity:	Pearson: 0.6065	Spearman: 0.5999
2023-08-03 16:28:51 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-03 16:28:53 - Cosine-Similarity :	Pearson: 0.7178	Spearman: 0.7474
2023-08-03 16:28:53 - Manhattan-Distance:	Pearson: 0.7562	Spearman: 0.7595
2023-08-03 16:28:53 - Euclidean-Distance:	Pearson: 0.7554	Spearman: 0.7581
2023-08-03 16:28:53 - Dot-Product-Similarity:	Pearson: 0.6086	Spearman: 0.6049
2023-08-03 16:31:30 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-03 16:31:32 - Cosine-Similarity :	Pearson: 0.7233	Spearman: 0.7521
2023-08-03 16:31:32 - Manhattan-Distance:	Pearson: 0.7565	Spearman: 0.7604
2023-08-03 16:31:32 - Euclidean-Distance:	Pearson: 0.7559	Spearman: 0.7592
2023-08-03 16:31:32 - Dot-Product-Similarity:	Pearson: 0.6270	Spearman: 0.6258
2023-08-03 16:34:12 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-03 16:34:14 - Cosine-Similarity :	Pearson: 0.7170	Spearman: 0.7487
2023-08-03 16:34:14 - Manhattan-Distance:	Pearson: 0.7546	Spearman: 0.7588
2023-08-03 16:34:14 - Euclidean-Distance:	Pearson: 0.7535	Spearman: 0.7573
2023-08-03 16:34:14 - Dot-Product-Similarity:	Pearson: 0.6133	Spearman: 0.6089
2023-08-03 16:36:52 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-03 16:36:54 - Cosine-Similarity :	Pearson: 0.7142	Spearman: 0.7460
2023-08-03 16:36:54 - Manhattan-Distance:	Pearson: 0.7546	Spearman: 0.7584
2023-08-03 16:36:54 - Euclidean-Distance:	Pearson: 0.7534	Spearman: 0.7569
2023-08-03 16:36:54 - Dot-Product-Similarity:	Pearson: 0.5996	Spearman: 0.5936
2023-08-03 16:39:33 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-03 16:39:36 - Cosine-Similarity :	Pearson: 0.7212	Spearman: 0.7523
2023-08-03 16:39:36 - Manhattan-Distance:	Pearson: 0.7585	Spearman: 0.7623
2023-08-03 16:39:36 - Euclidean-Distance:	Pearson: 0.7577	Spearman: 0.7612
2023-08-03 16:39:36 - Dot-Product-Similarity:	Pearson: 0.6140	Spearman: 0.6092
2023-08-03 16:39:36 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-03 16:39:38 - Cosine-Similarity :	Pearson: 0.7212	Spearman: 0.7523
2023-08-03 16:39:38 - Manhattan-Distance:	Pearson: 0.7585	Spearman: 0.7623
2023-08-03 16:39:38 - Euclidean-Distance:	Pearson: 0.7577	Spearman: 0.7612
2023-08-03 16:39:38 - Dot-Product-Similarity:	Pearson: 0.6140	Spearman: 0.6092
2023-08-03 16:39:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-03 16:39:40 - Cosine-Similarity :	Pearson: 0.6968	Spearman: 0.7288
2023-08-03 16:39:40 - Manhattan-Distance:	Pearson: 0.7397	Spearman: 0.7367
2023-08-03 16:39:40 - Euclidean-Distance:	Pearson: 0.7382	Spearman: 0.7358
2023-08-03 16:39:40 - Dot-Product-Similarity:	Pearson: 0.5870	Spearman: 0.5726
2023-08-03 15:28:02 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-03 15:28:02 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 545859
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 545859
Warmup-steps: 1706
Performance before training
2023-08-03 15:28:07 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset:
2023-08-03 15:28:13 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-03 15:28:13 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-03 15:28:13 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-03 15:28:13 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-03 15:33:56 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 853 steps:
2023-08-03 15:33:59 - Cosine-Similarity :	Pearson: 0.7135	Spearman: 0.7421
2023-08-03 15:33:59 - Manhattan-Distance:	Pearson: 0.7416	Spearman: 0.7491
2023-08-03 15:33:59 - Euclidean-Distance:	Pearson: 0.7377	Spearman: 0.7468
2023-08-03 15:33:59 - Dot-Product-Similarity:	Pearson: 0.5959	Spearman: 0.5876
2023-08-03 15:33:59 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-27-54
2023-08-03 15:40:08 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 1706 steps:
2023-08-03 15:40:11 - Cosine-Similarity :	Pearson: 0.7226	Spearman: 0.7524
2023-08-03 15:40:11 - Manhattan-Distance:	Pearson: 0.7572	Spearman: 0.7637
2023-08-03 15:40:11 - Euclidean-Distance:	Pearson: 0.7541	Spearman: 0.7608
2023-08-03 15:40:11 - Dot-Product-Similarity:	Pearson: 0.5987	Spearman: 0.5962
2023-08-03 15:40:11 - Save model to ./outputs/consert-snli-sup-macbert-2-CosineSimilarityLoss-2023-08-03_15-27-54
2023-08-03 15:46:16 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 2559 steps:
2023-08-03 15:46:19 - Cosine-Similarity :	Pearson: 0.7015	Spearman: 0.7381
2023-08-03 15:46:19 - Manhattan-Distance:	Pearson: 0.7450	Spearman: 0.7512
2023-08-03 15:46:19 - Euclidean-Distance:	Pearson: 0.7410	Spearman: 0.7470
2023-08-03 15:46:19 - Dot-Product-Similarity:	Pearson: 0.5984	Spearman: 0.5961
2023-08-03 15:51:22 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 3412 steps:
2023-08-03 15:51:25 - Cosine-Similarity :	Pearson: 0.7116	Spearman: 0.7433
2023-08-03 15:51:25 - Manhattan-Distance:	Pearson: 0.7492	Spearman: 0.7537
2023-08-03 15:51:25 - Euclidean-Distance:	Pearson: 0.7469	Spearman: 0.7511
2023-08-03 15:51:25 - Dot-Product-Similarity:	Pearson: 0.6041	Spearman: 0.6024
2023-08-03 15:55:51 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 4265 steps:
2023-08-03 15:55:54 - Cosine-Similarity :	Pearson: 0.7185	Spearman: 0.7494
2023-08-03 15:55:54 - Manhattan-Distance:	Pearson: 0.7545	Spearman: 0.7604
2023-08-03 15:55:54 - Euclidean-Distance:	Pearson: 0.7530	Spearman: 0.7585
2023-08-03 15:55:54 - Dot-Product-Similarity:	Pearson: 0.6056	Spearman: 0.6011
2023-08-03 16:00:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5118 steps:
2023-08-03 16:00:20 - Cosine-Similarity :	Pearson: 0.7019	Spearman: 0.7362
2023-08-03 16:00:20 - Manhattan-Distance:	Pearson: 0.7405	Spearman: 0.7446
2023-08-03 16:00:20 - Euclidean-Distance:	Pearson: 0.7390	Spearman: 0.7428
2023-08-03 16:00:20 - Dot-Product-Similarity:	Pearson: 0.6113	Spearman: 0.6092
2023-08-03 16:04:42 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 5971 steps:
2023-08-03 16:04:45 - Cosine-Similarity :	Pearson: 0.7045	Spearman: 0.7382
2023-08-03 16:04:45 - Manhattan-Distance:	Pearson: 0.7440	Spearman: 0.7477
2023-08-03 16:04:45 - Euclidean-Distance:	Pearson: 0.7429	Spearman: 0.7461
2023-08-03 16:04:45 - Dot-Product-Similarity:	Pearson: 0.6160	Spearman: 0.6082
2023-08-03 16:09:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 6824 steps:
2023-08-03 16:09:12 - Cosine-Similarity :	Pearson: 0.7084	Spearman: 0.7428
2023-08-03 16:09:12 - Manhattan-Distance:	Pearson: 0.7466	Spearman: 0.7519
2023-08-03 16:09:12 - Euclidean-Distance:	Pearson: 0.7456	Spearman: 0.7503
2023-08-03 16:09:12 - Dot-Product-Similarity:	Pearson: 0.6000	Spearman: 0.5915
2023-08-03 16:13:39 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 7677 steps:
2023-08-03 16:13:42 - Cosine-Similarity :	Pearson: 0.7221	Spearman: 0.7522
2023-08-03 16:13:42 - Manhattan-Distance:	Pearson: 0.7570	Spearman: 0.7612
2023-08-03 16:13:42 - Euclidean-Distance:	Pearson: 0.7566	Spearman: 0.7603
2023-08-03 16:13:42 - Dot-Product-Similarity:	Pearson: 0.6225	Spearman: 0.6193
2023-08-03 16:18:08 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 0 after 8530 steps:
2023-08-03 16:18:10 - Cosine-Similarity :	Pearson: 0.7086	Spearman: 0.7433
2023-08-03 16:18:10 - Manhattan-Distance:	Pearson: 0.7521	Spearman: 0.7563
2023-08-03 16:18:10 - Euclidean-Distance:	Pearson: 0.7511	Spearman: 0.7550
2023-08-03 16:18:10 - Dot-Product-Similarity:	Pearson: 0.6057	Spearman: 0.6016
2023-08-03 16:18:10 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 0:
2023-08-03 16:18:13 - Cosine-Similarity :	Pearson: 0.7086	Spearman: 0.7433
2023-08-03 16:18:13 - Manhattan-Distance:	Pearson: 0.7521	Spearman: 0.7563
2023-08-03 16:18:13 - Euclidean-Distance:	Pearson: 0.7511	Spearman: 0.7550
2023-08-03 16:18:13 - Dot-Product-Similarity:	Pearson: 0.6057	Spearman: 0.6016
2023-08-03 16:21:20 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 853 steps:
2023-08-03 16:21:22 - Cosine-Similarity :	Pearson: 0.7023	Spearman: 0.7407
2023-08-03 16:21:22 - Manhattan-Distance:	Pearson: 0.7485	Spearman: 0.7541
2023-08-03 16:21:22 - Euclidean-Distance:	Pearson: 0.7470	Spearman: 0.7519
2023-08-03 16:21:22 - Dot-Product-Similarity:	Pearson: 0.5983	Spearman: 0.5973
2023-08-03 16:23:59 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 1706 steps:
2023-08-03 16:24:02 - Cosine-Similarity :	Pearson: 0.7172	Spearman: 0.7500
2023-08-03 16:24:02 - Manhattan-Distance:	Pearson: 0.7543	Spearman: 0.7583
2023-08-03 16:24:02 - Euclidean-Distance:	Pearson: 0.7531	Spearman: 0.7564
2023-08-03 16:24:02 - Dot-Product-Similarity:	Pearson: 0.6240	Spearman: 0.6205
2023-08-03 16:26:41 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 2559 steps:
2023-08-03 16:26:44 - Cosine-Similarity :	Pearson: 0.7014	Spearman: 0.7351
2023-08-03 16:26:44 - Manhattan-Distance:	Pearson: 0.7445	Spearman: 0.7482
2023-08-03 16:26:44 - Euclidean-Distance:	Pearson: 0.7432	Spearman: 0.7465
2023-08-03 16:26:44 - Dot-Product-Similarity:	Pearson: 0.6005	Spearman: 0.5918
2023-08-03 16:29:23 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 3412 steps:
2023-08-03 16:29:25 - Cosine-Similarity :	Pearson: 0.7135	Spearman: 0.7433
2023-08-03 16:29:25 - Manhattan-Distance:	Pearson: 0.7499	Spearman: 0.7533
2023-08-03 16:29:25 - Euclidean-Distance:	Pearson: 0.7486	Spearman: 0.7513
2023-08-03 16:29:25 - Dot-Product-Similarity:	Pearson: 0.6164	Spearman: 0.6116
2023-08-03 16:32:02 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 4265 steps:
2023-08-03 16:32:04 - Cosine-Similarity :	Pearson: 0.7061	Spearman: 0.7383
2023-08-03 16:32:04 - Manhattan-Distance:	Pearson: 0.7473	Spearman: 0.7514
2023-08-03 16:32:04 - Euclidean-Distance:	Pearson: 0.7456	Spearman: 0.7491
2023-08-03 16:32:04 - Dot-Product-Similarity:	Pearson: 0.6087	Spearman: 0.6006
2023-08-03 16:34:43 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5118 steps:
2023-08-03 16:34:45 - Cosine-Similarity :	Pearson: 0.7103	Spearman: 0.7428
2023-08-03 16:34:45 - Manhattan-Distance:	Pearson: 0.7483	Spearman: 0.7522
2023-08-03 16:34:45 - Euclidean-Distance:	Pearson: 0.7471	Spearman: 0.7504
2023-08-03 16:34:45 - Dot-Product-Similarity:	Pearson: 0.6330	Spearman: 0.6310
2023-08-03 16:37:24 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 5971 steps:
2023-08-03 16:37:26 - Cosine-Similarity :	Pearson: 0.7181	Spearman: 0.7469
2023-08-03 16:37:26 - Manhattan-Distance:	Pearson: 0.7548	Spearman: 0.7582
2023-08-03 16:37:26 - Euclidean-Distance:	Pearson: 0.7535	Spearman: 0.7565
2023-08-03 16:37:26 - Dot-Product-Similarity:	Pearson: 0.6256	Spearman: 0.6198
2023-08-03 16:39:56 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 6824 steps:
2023-08-03 16:39:57 - Cosine-Similarity :	Pearson: 0.7136	Spearman: 0.7432
2023-08-03 16:39:57 - Manhattan-Distance:	Pearson: 0.7518	Spearman: 0.7548
2023-08-03 16:39:57 - Euclidean-Distance:	Pearson: 0.7500	Spearman: 0.7528
2023-08-03 16:39:57 - Dot-Product-Similarity:	Pearson: 0.6180	Spearman: 0.6133
2023-08-03 16:41:38 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 7677 steps:
2023-08-03 16:41:39 - Cosine-Similarity :	Pearson: 0.7111	Spearman: 0.7410
2023-08-03 16:41:39 - Manhattan-Distance:	Pearson: 0.7506	Spearman: 0.7539
2023-08-03 16:41:39 - Euclidean-Distance:	Pearson: 0.7490	Spearman: 0.7517
2023-08-03 16:41:39 - Dot-Product-Similarity:	Pearson: 0.6080	Spearman: 0.6010
2023-08-03 16:43:18 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset in epoch 1 after 8530 steps:
2023-08-03 16:43:20 - Cosine-Similarity :	Pearson: 0.7135	Spearman: 0.7432
2023-08-03 16:43:20 - Manhattan-Distance:	Pearson: 0.7528	Spearman: 0.7561
2023-08-03 16:43:20 - Euclidean-Distance:	Pearson: 0.7512	Spearman: 0.7541
2023-08-03 16:43:20 - Dot-Product-Similarity:	Pearson: 0.6082	Spearman: 0.6007
2023-08-03 16:43:20 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-dev dataset after epoch 1:
2023-08-03 16:43:21 - Cosine-Similarity :	Pearson: 0.7135	Spearman: 0.7432
2023-08-03 16:43:21 - Manhattan-Distance:	Pearson: 0.7528	Spearman: 0.7561
2023-08-03 16:43:21 - Euclidean-Distance:	Pearson: 0.7512	Spearman: 0.7541
2023-08-03 16:43:21 - Dot-Product-Similarity:	Pearson: 0.6082	Spearman: 0.6007
2023-08-03 16:43:21 - EmbeddingSimilarityEvaluator: Evaluating the model on snli-sup-test dataset:
2023-08-03 16:43:23 - Cosine-Similarity :	Pearson: 0.6865	Spearman: 0.7208
2023-08-03 16:43:23 - Manhattan-Distance:	Pearson: 0.7324	Spearman: 0.7303
2023-08-03 16:43:23 - Euclidean-Distance:	Pearson: 0.7307	Spearman: 0.7296
2023-08-03 16:43:23 - Dot-Product-Similarity:	Pearson: 0.5834	Spearman: 0.5743
[2023-08-04 16:19:08,689] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-04 16:19:27,807] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-04 16:19:46,983] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-04 16:19:14 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:19:14 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 11692
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11692
Warmup-steps: 10
Performance before training
2023-08-04 16:19:16 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset:
2023-08-04 16:19:20 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-04 16:19:20 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-04 16:19:20 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-04 16:19:20 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-04 16:19:21 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 4 steps:
2023-08-04 16:19:23 - Cosine-Similarity :	Pearson: 0.6111	Spearman: 0.6245
2023-08-04 16:19:23 - Manhattan-Distance:	Pearson: 0.6246	Spearman: 0.6373
2023-08-04 16:19:23 - Euclidean-Distance:	Pearson: 0.6207	Spearman: 0.6334
2023-08-04 16:19:23 - Dot-Product-Similarity:	Pearson: 0.2799	Spearman: 0.2671
2023-08-04 16:19:23 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:19:31 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 8 steps:
2023-08-04 16:19:33 - Cosine-Similarity :	Pearson: 0.6283	Spearman: 0.6414
2023-08-04 16:19:33 - Manhattan-Distance:	Pearson: 0.6391	Spearman: 0.6521
2023-08-04 16:19:33 - Euclidean-Distance:	Pearson: 0.6359	Spearman: 0.6491
2023-08-04 16:19:33 - Dot-Product-Similarity:	Pearson: 0.3371	Spearman: 0.3232
2023-08-04 16:19:33 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:19:38 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 12 steps:
2023-08-04 16:19:40 - Cosine-Similarity :	Pearson: 0.6632	Spearman: 0.6755
2023-08-04 16:19:40 - Manhattan-Distance:	Pearson: 0.6680	Spearman: 0.6812
2023-08-04 16:19:40 - Euclidean-Distance:	Pearson: 0.6666	Spearman: 0.6800
2023-08-04 16:19:40 - Dot-Product-Similarity:	Pearson: 0.4679	Spearman: 0.4529
2023-08-04 16:19:40 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:19:45 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 16 steps:
2023-08-04 16:19:47 - Cosine-Similarity :	Pearson: 0.6973	Spearman: 0.7065
2023-08-04 16:19:47 - Manhattan-Distance:	Pearson: 0.6973	Spearman: 0.7089
2023-08-04 16:19:47 - Euclidean-Distance:	Pearson: 0.6975	Spearman: 0.7093
2023-08-04 16:19:47 - Dot-Product-Similarity:	Pearson: 0.5726	Spearman: 0.5665
2023-08-04 16:19:47 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:19:52 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 20 steps:
2023-08-04 16:19:54 - Cosine-Similarity :	Pearson: 0.7162	Spearman: 0.7232
2023-08-04 16:19:54 - Manhattan-Distance:	Pearson: 0.7143	Spearman: 0.7265
2023-08-04 16:19:54 - Euclidean-Distance:	Pearson: 0.7150	Spearman: 0.7277
2023-08-04 16:19:54 - Dot-Product-Similarity:	Pearson: 0.6102	Spearman: 0.6073
2023-08-04 16:19:54 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:20:03 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 24 steps:
2023-08-04 16:20:06 - Cosine-Similarity :	Pearson: 0.7235	Spearman: 0.7290
2023-08-04 16:20:06 - Manhattan-Distance:	Pearson: 0.7220	Spearman: 0.7354
2023-08-04 16:20:06 - Euclidean-Distance:	Pearson: 0.7227	Spearman: 0.7366
2023-08-04 16:20:06 - Dot-Product-Similarity:	Pearson: 0.6268	Spearman: 0.6255
2023-08-04 16:20:06 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:20:15 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 28 steps:
2023-08-04 16:20:17 - Cosine-Similarity :	Pearson: 0.7270	Spearman: 0.7321
2023-08-04 16:20:17 - Manhattan-Distance:	Pearson: 0.7250	Spearman: 0.7393
2023-08-04 16:20:17 - Euclidean-Distance:	Pearson: 0.7260	Spearman: 0.7405
2023-08-04 16:20:17 - Dot-Product-Similarity:	Pearson: 0.6395	Spearman: 0.6387
2023-08-04 16:20:17 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:20:24 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 32 steps:
2023-08-04 16:20:27 - Cosine-Similarity :	Pearson: 0.7290	Spearman: 0.7342
2023-08-04 16:20:27 - Manhattan-Distance:	Pearson: 0.7269	Spearman: 0.7414
2023-08-04 16:20:27 - Euclidean-Distance:	Pearson: 0.7279	Spearman: 0.7428
2023-08-04 16:20:27 - Dot-Product-Similarity:	Pearson: 0.6475	Spearman: 0.6467
2023-08-04 16:20:27 - Save model to ./outputs_qa/consert-qa-unsup-sts-macbert-2-MultipleNegativesRankingLoss-2023-08-04_16-19-06
2023-08-04 16:20:33 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 36 steps:
2023-08-04 16:20:36 - Cosine-Similarity :	Pearson: 0.7287	Spearman: 0.7339
2023-08-04 16:20:36 - Manhattan-Distance:	Pearson: 0.7272	Spearman: 0.7417
2023-08-04 16:20:36 - Euclidean-Distance:	Pearson: 0.7282	Spearman: 0.7431
2023-08-04 16:20:36 - Dot-Product-Similarity:	Pearson: 0.6511	Spearman: 0.6506
2023-08-04 16:20:39 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 40 steps:
2023-08-04 16:20:41 - Cosine-Similarity :	Pearson: 0.7263	Spearman: 0.7314
2023-08-04 16:20:41 - Manhattan-Distance:	Pearson: 0.7262	Spearman: 0.7405
2023-08-04 16:20:41 - Euclidean-Distance:	Pearson: 0.7272	Spearman: 0.7421
2023-08-04 16:20:41 - Dot-Product-Similarity:	Pearson: 0.6516	Spearman: 0.6511
2023-08-04 16:20:44 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 0 after 44 steps:
2023-08-04 16:20:46 - Cosine-Similarity :	Pearson: 0.7239	Spearman: 0.7291
2023-08-04 16:20:46 - Manhattan-Distance:	Pearson: 0.7251	Spearman: 0.7393
2023-08-04 16:20:46 - Euclidean-Distance:	Pearson: 0.7261	Spearman: 0.7407
2023-08-04 16:20:46 - Dot-Product-Similarity:	Pearson: 0.6514	Spearman: 0.6509
2023-08-04 16:20:47 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset after epoch 0:
2023-08-04 16:20:50 - Cosine-Similarity :	Pearson: 0.7230	Spearman: 0.7283
2023-08-04 16:20:50 - Manhattan-Distance:	Pearson: 0.7248	Spearman: 0.7388
2023-08-04 16:20:50 - Euclidean-Distance:	Pearson: 0.7257	Spearman: 0.7402
2023-08-04 16:20:50 - Dot-Product-Similarity:	Pearson: 0.6514	Spearman: 0.6508
2023-08-04 16:20:53 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 4 steps:
2023-08-04 16:20:55 - Cosine-Similarity :	Pearson: 0.7220	Spearman: 0.7271
2023-08-04 16:20:55 - Manhattan-Distance:	Pearson: 0.7244	Spearman: 0.7382
2023-08-04 16:20:55 - Euclidean-Distance:	Pearson: 0.7253	Spearman: 0.7396
2023-08-04 16:20:55 - Dot-Product-Similarity:	Pearson: 0.6516	Spearman: 0.6509
2023-08-04 16:20:58 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 8 steps:
2023-08-04 16:21:00 - Cosine-Similarity :	Pearson: 0.7210	Spearman: 0.7262
2023-08-04 16:21:00 - Manhattan-Distance:	Pearson: 0.7239	Spearman: 0.7376
2023-08-04 16:21:00 - Euclidean-Distance:	Pearson: 0.7248	Spearman: 0.7390
2023-08-04 16:21:00 - Dot-Product-Similarity:	Pearson: 0.6514	Spearman: 0.6506
2023-08-04 16:21:03 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 12 steps:
2023-08-04 16:21:05 - Cosine-Similarity :	Pearson: 0.7204	Spearman: 0.7257
2023-08-04 16:21:05 - Manhattan-Distance:	Pearson: 0.7235	Spearman: 0.7371
2023-08-04 16:21:05 - Euclidean-Distance:	Pearson: 0.7244	Spearman: 0.7385
2023-08-04 16:21:05 - Dot-Product-Similarity:	Pearson: 0.6515	Spearman: 0.6507
2023-08-04 16:21:08 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 16 steps:
2023-08-04 16:21:11 - Cosine-Similarity :	Pearson: 0.7197	Spearman: 0.7250
2023-08-04 16:21:11 - Manhattan-Distance:	Pearson: 0.7230	Spearman: 0.7365
2023-08-04 16:21:11 - Euclidean-Distance:	Pearson: 0.7238	Spearman: 0.7379
2023-08-04 16:21:11 - Dot-Product-Similarity:	Pearson: 0.6512	Spearman: 0.6505
2023-08-04 16:21:13 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 20 steps:
2023-08-04 16:21:16 - Cosine-Similarity :	Pearson: 0.7193	Spearman: 0.7247
2023-08-04 16:21:16 - Manhattan-Distance:	Pearson: 0.7226	Spearman: 0.7361
2023-08-04 16:21:16 - Euclidean-Distance:	Pearson: 0.7235	Spearman: 0.7375
2023-08-04 16:21:16 - Dot-Product-Similarity:	Pearson: 0.6510	Spearman: 0.6502
2023-08-04 16:21:18 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 24 steps:
2023-08-04 16:21:21 - Cosine-Similarity :	Pearson: 0.7188	Spearman: 0.7243
2023-08-04 16:21:21 - Manhattan-Distance:	Pearson: 0.7223	Spearman: 0.7358
2023-08-04 16:21:21 - Euclidean-Distance:	Pearson: 0.7232	Spearman: 0.7371
2023-08-04 16:21:21 - Dot-Product-Similarity:	Pearson: 0.6508	Spearman: 0.6500
2023-08-04 16:21:23 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 28 steps:
2023-08-04 16:21:25 - Cosine-Similarity :	Pearson: 0.7186	Spearman: 0.7241
2023-08-04 16:21:25 - Manhattan-Distance:	Pearson: 0.7221	Spearman: 0.7356
2023-08-04 16:21:25 - Euclidean-Distance:	Pearson: 0.7230	Spearman: 0.7368
2023-08-04 16:21:25 - Dot-Product-Similarity:	Pearson: 0.6508	Spearman: 0.6501
2023-08-04 16:21:28 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 32 steps:
2023-08-04 16:21:31 - Cosine-Similarity :	Pearson: 0.7185	Spearman: 0.7240
2023-08-04 16:21:31 - Manhattan-Distance:	Pearson: 0.7220	Spearman: 0.7356
2023-08-04 16:21:31 - Euclidean-Distance:	Pearson: 0.7229	Spearman: 0.7367
2023-08-04 16:21:31 - Dot-Product-Similarity:	Pearson: 0.6510	Spearman: 0.6503
2023-08-04 16:21:35 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 36 steps:
2023-08-04 16:21:38 - Cosine-Similarity :	Pearson: 0.7184	Spearman: 0.7239
2023-08-04 16:21:38 - Manhattan-Distance:	Pearson: 0.7219	Spearman: 0.7355
2023-08-04 16:21:38 - Euclidean-Distance:	Pearson: 0.7228	Spearman: 0.7366
2023-08-04 16:21:38 - Dot-Product-Similarity:	Pearson: 0.6509	Spearman: 0.6502
2023-08-04 16:21:40 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 40 steps:
2023-08-04 16:21:43 - Cosine-Similarity :	Pearson: 0.7183	Spearman: 0.7237
2023-08-04 16:21:43 - Manhattan-Distance:	Pearson: 0.7218	Spearman: 0.7353
2023-08-04 16:21:43 - Euclidean-Distance:	Pearson: 0.7227	Spearman: 0.7365
2023-08-04 16:21:43 - Dot-Product-Similarity:	Pearson: 0.6509	Spearman: 0.6501
2023-08-04 16:21:46 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset in epoch 1 after 44 steps:
2023-08-04 16:21:47 - Cosine-Similarity :	Pearson: 0.7182	Spearman: 0.7236
2023-08-04 16:21:47 - Manhattan-Distance:	Pearson: 0.7218	Spearman: 0.7353
2023-08-04 16:21:47 - Euclidean-Distance:	Pearson: 0.7226	Spearman: 0.7364
2023-08-04 16:21:47 - Dot-Product-Similarity:	Pearson: 0.6508	Spearman: 0.6500
2023-08-04 16:21:48 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset after epoch 1:
2023-08-04 16:21:51 - Cosine-Similarity :	Pearson: 0.7181	Spearman: 0.7236
2023-08-04 16:21:51 - Manhattan-Distance:	Pearson: 0.7218	Spearman: 0.7352
2023-08-04 16:21:51 - Euclidean-Distance:	Pearson: 0.7226	Spearman: 0.7364
2023-08-04 16:21:51 - Dot-Product-Similarity:	Pearson: 0.6507	Spearman: 0.6500
2023-08-04 16:21:51 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-test dataset:
2023-08-04 16:21:53 - Cosine-Similarity :	Pearson: 0.6557	Spearman: 0.6537
2023-08-04 16:21:53 - Manhattan-Distance:	Pearson: 0.6668	Spearman: 0.6665
2023-08-04 16:21:53 - Euclidean-Distance:	Pearson: 0.6660	Spearman: 0.6654
2023-08-04 16:21:53 - Dot-Product-Similarity:	Pearson: 0.5740	Spearman: 0.5668
2023-08-04 16:19:34 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:19:34 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 11565
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11565
Warmup-steps: 10
Performance before training
2023-08-04 16:19:35 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset:
2023-08-04 16:19:41 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-04 16:19:41 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-04 16:19:41 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-04 16:19:41 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-04 16:19:42 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 4 steps:
2023-08-04 16:19:44 - Cosine-Similarity :	Pearson: 0.6101	Spearman: 0.6235
2023-08-04 16:19:44 - Manhattan-Distance:	Pearson: 0.6240	Spearman: 0.6367
2023-08-04 16:19:44 - Euclidean-Distance:	Pearson: 0.6199	Spearman: 0.6329
2023-08-04 16:19:44 - Dot-Product-Similarity:	Pearson: 0.2955	Spearman: 0.2831
2023-08-04 16:19:44 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:19:52 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 8 steps:
2023-08-04 16:19:54 - Cosine-Similarity :	Pearson: 0.6092	Spearman: 0.6238
2023-08-04 16:19:54 - Manhattan-Distance:	Pearson: 0.6235	Spearman: 0.6359
2023-08-04 16:19:54 - Euclidean-Distance:	Pearson: 0.6186	Spearman: 0.6319
2023-08-04 16:19:54 - Dot-Product-Similarity:	Pearson: 0.3713	Spearman: 0.3589
2023-08-04 16:19:54 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:02 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 12 steps:
2023-08-04 16:20:05 - Cosine-Similarity :	Pearson: 0.6260	Spearman: 0.6372
2023-08-04 16:20:05 - Manhattan-Distance:	Pearson: 0.6346	Spearman: 0.6470
2023-08-04 16:20:05 - Euclidean-Distance:	Pearson: 0.6302	Spearman: 0.6431
2023-08-04 16:20:05 - Dot-Product-Similarity:	Pearson: 0.4503	Spearman: 0.4466
2023-08-04 16:20:05 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:12 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 16 steps:
2023-08-04 16:20:14 - Cosine-Similarity :	Pearson: 0.6546	Spearman: 0.6631
2023-08-04 16:20:14 - Manhattan-Distance:	Pearson: 0.6566	Spearman: 0.6693
2023-08-04 16:20:14 - Euclidean-Distance:	Pearson: 0.6545	Spearman: 0.6670
2023-08-04 16:20:14 - Dot-Product-Similarity:	Pearson: 0.4992	Spearman: 0.4961
2023-08-04 16:20:14 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:20 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 20 steps:
2023-08-04 16:20:22 - Cosine-Similarity :	Pearson: 0.6734	Spearman: 0.6810
2023-08-04 16:20:22 - Manhattan-Distance:	Pearson: 0.6724	Spearman: 0.6849
2023-08-04 16:20:22 - Euclidean-Distance:	Pearson: 0.6716	Spearman: 0.6844
2023-08-04 16:20:22 - Dot-Product-Similarity:	Pearson: 0.5364	Spearman: 0.5331
2023-08-04 16:20:22 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:28 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 24 steps:
2023-08-04 16:20:29 - Cosine-Similarity :	Pearson: 0.6853	Spearman: 0.6924
2023-08-04 16:20:29 - Manhattan-Distance:	Pearson: 0.6832	Spearman: 0.6952
2023-08-04 16:20:29 - Euclidean-Distance:	Pearson: 0.6831	Spearman: 0.6952
2023-08-04 16:20:29 - Dot-Product-Similarity:	Pearson: 0.5641	Spearman: 0.5616
2023-08-04 16:20:30 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:37 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 28 steps:
2023-08-04 16:20:39 - Cosine-Similarity :	Pearson: 0.6915	Spearman: 0.6982
2023-08-04 16:20:39 - Manhattan-Distance:	Pearson: 0.6894	Spearman: 0.7009
2023-08-04 16:20:39 - Euclidean-Distance:	Pearson: 0.6896	Spearman: 0.7016
2023-08-04 16:20:39 - Dot-Product-Similarity:	Pearson: 0.5793	Spearman: 0.5773
2023-08-04 16:20:39 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:46 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 32 steps:
2023-08-04 16:20:48 - Cosine-Similarity :	Pearson: 0.6976	Spearman: 0.7040
2023-08-04 16:20:48 - Manhattan-Distance:	Pearson: 0.6955	Spearman: 0.7070
2023-08-04 16:20:48 - Euclidean-Distance:	Pearson: 0.6960	Spearman: 0.7077
2023-08-04 16:20:48 - Dot-Product-Similarity:	Pearson: 0.5905	Spearman: 0.5890
2023-08-04 16:20:48 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:20:55 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 36 steps:
2023-08-04 16:20:57 - Cosine-Similarity :	Pearson: 0.7034	Spearman: 0.7091
2023-08-04 16:20:57 - Manhattan-Distance:	Pearson: 0.7010	Spearman: 0.7125
2023-08-04 16:20:57 - Euclidean-Distance:	Pearson: 0.7018	Spearman: 0.7134
2023-08-04 16:20:57 - Dot-Product-Similarity:	Pearson: 0.6001	Spearman: 0.5996
2023-08-04 16:20:57 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:03 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 40 steps:
2023-08-04 16:21:06 - Cosine-Similarity :	Pearson: 0.7068	Spearman: 0.7123
2023-08-04 16:21:06 - Manhattan-Distance:	Pearson: 0.7044	Spearman: 0.7156
2023-08-04 16:21:06 - Euclidean-Distance:	Pearson: 0.7053	Spearman: 0.7168
2023-08-04 16:21:06 - Dot-Product-Similarity:	Pearson: 0.6067	Spearman: 0.6070
2023-08-04 16:21:06 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:12 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 44 steps:
2023-08-04 16:21:15 - Cosine-Similarity :	Pearson: 0.7088	Spearman: 0.7139
2023-08-04 16:21:15 - Manhattan-Distance:	Pearson: 0.7066	Spearman: 0.7180
2023-08-04 16:21:15 - Euclidean-Distance:	Pearson: 0.7074	Spearman: 0.7189
2023-08-04 16:21:15 - Dot-Product-Similarity:	Pearson: 0.6104	Spearman: 0.6111
2023-08-04 16:21:15 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:19 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset after epoch 0:
2023-08-04 16:21:22 - Cosine-Similarity :	Pearson: 0.7090	Spearman: 0.7140
2023-08-04 16:21:22 - Manhattan-Distance:	Pearson: 0.7070	Spearman: 0.7184
2023-08-04 16:21:22 - Euclidean-Distance:	Pearson: 0.7077	Spearman: 0.7190
2023-08-04 16:21:22 - Dot-Product-Similarity:	Pearson: 0.6103	Spearman: 0.6114
2023-08-04 16:21:22 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:29 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 4 steps:
2023-08-04 16:21:31 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7136
2023-08-04 16:21:31 - Manhattan-Distance:	Pearson: 0.7071	Spearman: 0.7186
2023-08-04 16:21:31 - Euclidean-Distance:	Pearson: 0.7075	Spearman: 0.7191
2023-08-04 16:21:31 - Dot-Product-Similarity:	Pearson: 0.6080	Spearman: 0.6096
2023-08-04 16:21:35 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 8 steps:
2023-08-04 16:21:38 - Cosine-Similarity :	Pearson: 0.7086	Spearman: 0.7136
2023-08-04 16:21:38 - Manhattan-Distance:	Pearson: 0.7075	Spearman: 0.7191
2023-08-04 16:21:38 - Euclidean-Distance:	Pearson: 0.7078	Spearman: 0.7195
2023-08-04 16:21:38 - Dot-Product-Similarity:	Pearson: 0.6066	Spearman: 0.6084
2023-08-04 16:21:41 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 12 steps:
2023-08-04 16:21:43 - Cosine-Similarity :	Pearson: 0.7094	Spearman: 0.7143
2023-08-04 16:21:43 - Manhattan-Distance:	Pearson: 0.7087	Spearman: 0.7200
2023-08-04 16:21:43 - Euclidean-Distance:	Pearson: 0.7088	Spearman: 0.7204
2023-08-04 16:21:43 - Dot-Product-Similarity:	Pearson: 0.6059	Spearman: 0.6079
2023-08-04 16:21:43 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 16 steps:
2023-08-04 16:21:53 - Cosine-Similarity :	Pearson: 0.7101	Spearman: 0.7153
2023-08-04 16:21:53 - Manhattan-Distance:	Pearson: 0.7098	Spearman: 0.7210
2023-08-04 16:21:53 - Euclidean-Distance:	Pearson: 0.7098	Spearman: 0.7212
2023-08-04 16:21:53 - Dot-Product-Similarity:	Pearson: 0.6063	Spearman: 0.6089
2023-08-04 16:21:53 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:21:58 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 20 steps:
2023-08-04 16:22:00 - Cosine-Similarity :	Pearson: 0.7106	Spearman: 0.7160
2023-08-04 16:22:00 - Manhattan-Distance:	Pearson: 0.7105	Spearman: 0.7216
2023-08-04 16:22:00 - Euclidean-Distance:	Pearson: 0.7105	Spearman: 0.7216
2023-08-04 16:22:00 - Dot-Product-Similarity:	Pearson: 0.6081	Spearman: 0.6108
2023-08-04 16:22:00 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:05 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 24 steps:
2023-08-04 16:22:07 - Cosine-Similarity :	Pearson: 0.7111	Spearman: 0.7164
2023-08-04 16:22:07 - Manhattan-Distance:	Pearson: 0.7111	Spearman: 0.7220
2023-08-04 16:22:07 - Euclidean-Distance:	Pearson: 0.7110	Spearman: 0.7219
2023-08-04 16:22:07 - Dot-Product-Similarity:	Pearson: 0.6090	Spearman: 0.6117
2023-08-04 16:22:07 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:13 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 28 steps:
2023-08-04 16:22:15 - Cosine-Similarity :	Pearson: 0.7114	Spearman: 0.7168
2023-08-04 16:22:15 - Manhattan-Distance:	Pearson: 0.7115	Spearman: 0.7222
2023-08-04 16:22:15 - Euclidean-Distance:	Pearson: 0.7114	Spearman: 0.7223
2023-08-04 16:22:15 - Dot-Product-Similarity:	Pearson: 0.6098	Spearman: 0.6124
2023-08-04 16:22:15 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:21 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 32 steps:
2023-08-04 16:22:23 - Cosine-Similarity :	Pearson: 0.7113	Spearman: 0.7168
2023-08-04 16:22:23 - Manhattan-Distance:	Pearson: 0.7117	Spearman: 0.7223
2023-08-04 16:22:23 - Euclidean-Distance:	Pearson: 0.7115	Spearman: 0.7222
2023-08-04 16:22:23 - Dot-Product-Similarity:	Pearson: 0.6106	Spearman: 0.6131
2023-08-04 16:22:23 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:29 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 36 steps:
2023-08-04 16:22:31 - Cosine-Similarity :	Pearson: 0.7113	Spearman: 0.7169
2023-08-04 16:22:31 - Manhattan-Distance:	Pearson: 0.7118	Spearman: 0.7225
2023-08-04 16:22:31 - Euclidean-Distance:	Pearson: 0.7116	Spearman: 0.7223
2023-08-04 16:22:31 - Dot-Product-Similarity:	Pearson: 0.6109	Spearman: 0.6134
2023-08-04 16:22:31 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:38 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 40 steps:
2023-08-04 16:22:39 - Cosine-Similarity :	Pearson: 0.7115	Spearman: 0.7171
2023-08-04 16:22:39 - Manhattan-Distance:	Pearson: 0.7120	Spearman: 0.7226
2023-08-04 16:22:39 - Euclidean-Distance:	Pearson: 0.7118	Spearman: 0.7224
2023-08-04 16:22:39 - Dot-Product-Similarity:	Pearson: 0.6113	Spearman: 0.6140
2023-08-04 16:22:39 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:45 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 44 steps:
2023-08-04 16:22:47 - Cosine-Similarity :	Pearson: 0.7116	Spearman: 0.7172
2023-08-04 16:22:47 - Manhattan-Distance:	Pearson: 0.7121	Spearman: 0.7226
2023-08-04 16:22:47 - Euclidean-Distance:	Pearson: 0.7119	Spearman: 0.7224
2023-08-04 16:22:47 - Dot-Product-Similarity:	Pearson: 0.6116	Spearman: 0.6145
2023-08-04 16:22:47 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:52 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset after epoch 1:
2023-08-04 16:22:54 - Cosine-Similarity :	Pearson: 0.7116	Spearman: 0.7172
2023-08-04 16:22:54 - Manhattan-Distance:	Pearson: 0.7121	Spearman: 0.7226
2023-08-04 16:22:54 - Euclidean-Distance:	Pearson: 0.7119	Spearman: 0.7224
2023-08-04 16:22:54 - Dot-Product-Similarity:	Pearson: 0.6116	Spearman: 0.6145
2023-08-04 16:22:54 - Save model to ./outputs_qa/consert-qa-sup-sts-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-25
2023-08-04 16:22:58 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-test dataset:
2023-08-04 16:23:00 - Cosine-Similarity :	Pearson: 0.6493	Spearman: 0.6435
2023-08-04 16:23:00 - Manhattan-Distance:	Pearson: 0.6489	Spearman: 0.6409
2023-08-04 16:23:00 - Euclidean-Distance:	Pearson: 0.6478	Spearman: 0.6398
2023-08-04 16:23:00 - Dot-Product-Similarity:	Pearson: 0.5636	Spearman: 0.5499
2023-08-04 16:19:53 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:19:53 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 11597
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11597
Warmup-steps: 10
Performance before training
2023-08-04 16:19:55 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset:
2023-08-04 16:19:59 - Cosine-Similarity :	Pearson: 0.6100	Spearman: 0.6233
2023-08-04 16:19:59 - Manhattan-Distance:	Pearson: 0.6236	Spearman: 0.6362
2023-08-04 16:19:59 - Euclidean-Distance:	Pearson: 0.6196	Spearman: 0.6324
2023-08-04 16:19:59 - Dot-Product-Similarity:	Pearson: 0.2764	Spearman: 0.2636
2023-08-04 16:20:04 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 4 steps:
2023-08-04 16:20:06 - Cosine-Similarity :	Pearson: 0.6102	Spearman: 0.6235
2023-08-04 16:20:06 - Manhattan-Distance:	Pearson: 0.6242	Spearman: 0.6368
2023-08-04 16:20:06 - Euclidean-Distance:	Pearson: 0.6201	Spearman: 0.6329
2023-08-04 16:20:06 - Dot-Product-Similarity:	Pearson: 0.2955	Spearman: 0.2833
2023-08-04 16:20:06 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:15 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 8 steps:
2023-08-04 16:20:17 - Cosine-Similarity :	Pearson: 0.6103	Spearman: 0.6246
2023-08-04 16:20:17 - Manhattan-Distance:	Pearson: 0.6244	Spearman: 0.6369
2023-08-04 16:20:17 - Euclidean-Distance:	Pearson: 0.6197	Spearman: 0.6326
2023-08-04 16:20:17 - Dot-Product-Similarity:	Pearson: 0.3722	Spearman: 0.3594
2023-08-04 16:20:17 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:24 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 12 steps:
2023-08-04 16:20:26 - Cosine-Similarity :	Pearson: 0.6249	Spearman: 0.6360
2023-08-04 16:20:26 - Manhattan-Distance:	Pearson: 0.6339	Spearman: 0.6463
2023-08-04 16:20:26 - Euclidean-Distance:	Pearson: 0.6295	Spearman: 0.6422
2023-08-04 16:20:26 - Dot-Product-Similarity:	Pearson: 0.4497	Spearman: 0.4457
2023-08-04 16:20:26 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:32 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 16 steps:
2023-08-04 16:20:35 - Cosine-Similarity :	Pearson: 0.6528	Spearman: 0.6611
2023-08-04 16:20:35 - Manhattan-Distance:	Pearson: 0.6548	Spearman: 0.6678
2023-08-04 16:20:35 - Euclidean-Distance:	Pearson: 0.6528	Spearman: 0.6656
2023-08-04 16:20:35 - Dot-Product-Similarity:	Pearson: 0.4930	Spearman: 0.4895
2023-08-04 16:20:35 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:41 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 20 steps:
2023-08-04 16:20:43 - Cosine-Similarity :	Pearson: 0.6714	Spearman: 0.6792
2023-08-04 16:20:43 - Manhattan-Distance:	Pearson: 0.6697	Spearman: 0.6828
2023-08-04 16:20:43 - Euclidean-Distance:	Pearson: 0.6691	Spearman: 0.6822
2023-08-04 16:20:43 - Dot-Product-Similarity:	Pearson: 0.5284	Spearman: 0.5247
2023-08-04 16:20:43 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 24 steps:
2023-08-04 16:20:52 - Cosine-Similarity :	Pearson: 0.6822	Spearman: 0.6893
2023-08-04 16:20:52 - Manhattan-Distance:	Pearson: 0.6787	Spearman: 0.6914
2023-08-04 16:20:52 - Euclidean-Distance:	Pearson: 0.6788	Spearman: 0.6916
2023-08-04 16:20:52 - Dot-Product-Similarity:	Pearson: 0.5569	Spearman: 0.5541
2023-08-04 16:20:52 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:20:59 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 28 steps:
2023-08-04 16:21:01 - Cosine-Similarity :	Pearson: 0.6895	Spearman: 0.6960
2023-08-04 16:21:01 - Manhattan-Distance:	Pearson: 0.6853	Spearman: 0.6979
2023-08-04 16:21:01 - Euclidean-Distance:	Pearson: 0.6856	Spearman: 0.6983
2023-08-04 16:21:01 - Dot-Product-Similarity:	Pearson: 0.5749	Spearman: 0.5727
2023-08-04 16:21:01 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:08 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 32 steps:
2023-08-04 16:21:10 - Cosine-Similarity :	Pearson: 0.6954	Spearman: 0.7015
2023-08-04 16:21:10 - Manhattan-Distance:	Pearson: 0.6911	Spearman: 0.7032
2023-08-04 16:21:10 - Euclidean-Distance:	Pearson: 0.6917	Spearman: 0.7039
2023-08-04 16:21:10 - Dot-Product-Similarity:	Pearson: 0.5875	Spearman: 0.5858
2023-08-04 16:21:10 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:17 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 36 steps:
2023-08-04 16:21:19 - Cosine-Similarity :	Pearson: 0.7004	Spearman: 0.7060
2023-08-04 16:21:19 - Manhattan-Distance:	Pearson: 0.6961	Spearman: 0.7081
2023-08-04 16:21:19 - Euclidean-Distance:	Pearson: 0.6967	Spearman: 0.7090
2023-08-04 16:21:19 - Dot-Product-Similarity:	Pearson: 0.5959	Spearman: 0.5950
2023-08-04 16:21:19 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:25 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 40 steps:
2023-08-04 16:21:28 - Cosine-Similarity :	Pearson: 0.7048	Spearman: 0.7102
2023-08-04 16:21:28 - Manhattan-Distance:	Pearson: 0.7006	Spearman: 0.7125
2023-08-04 16:21:28 - Euclidean-Distance:	Pearson: 0.7013	Spearman: 0.7133
2023-08-04 16:21:28 - Dot-Product-Similarity:	Pearson: 0.6022	Spearman: 0.6019
2023-08-04 16:21:28 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:36 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 44 steps:
2023-08-04 16:21:39 - Cosine-Similarity :	Pearson: 0.7071	Spearman: 0.7124
2023-08-04 16:21:39 - Manhattan-Distance:	Pearson: 0.7034	Spearman: 0.7152
2023-08-04 16:21:39 - Euclidean-Distance:	Pearson: 0.7039	Spearman: 0.7159
2023-08-04 16:21:39 - Dot-Product-Similarity:	Pearson: 0.6049	Spearman: 0.6056
2023-08-04 16:21:39 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:44 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset after epoch 0:
2023-08-04 16:21:46 - Cosine-Similarity :	Pearson: 0.7075	Spearman: 0.7126
2023-08-04 16:21:46 - Manhattan-Distance:	Pearson: 0.7042	Spearman: 0.7160
2023-08-04 16:21:46 - Euclidean-Distance:	Pearson: 0.7046	Spearman: 0.7165
2023-08-04 16:21:46 - Dot-Product-Similarity:	Pearson: 0.6049	Spearman: 0.6060
2023-08-04 16:21:46 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:21:53 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 4 steps:
2023-08-04 16:21:55 - Cosine-Similarity :	Pearson: 0.7079	Spearman: 0.7128
2023-08-04 16:21:55 - Manhattan-Distance:	Pearson: 0.7052	Spearman: 0.7170
2023-08-04 16:21:55 - Euclidean-Distance:	Pearson: 0.7054	Spearman: 0.7173
2023-08-04 16:21:55 - Dot-Product-Similarity:	Pearson: 0.6047	Spearman: 0.6065
2023-08-04 16:21:55 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:01 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 8 steps:
2023-08-04 16:22:02 - Cosine-Similarity :	Pearson: 0.7081	Spearman: 0.7133
2023-08-04 16:22:02 - Manhattan-Distance:	Pearson: 0.7058	Spearman: 0.7177
2023-08-04 16:22:02 - Euclidean-Distance:	Pearson: 0.7058	Spearman: 0.7177
2023-08-04 16:22:02 - Dot-Product-Similarity:	Pearson: 0.6044	Spearman: 0.6062
2023-08-04 16:22:02 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:08 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 12 steps:
2023-08-04 16:22:09 - Cosine-Similarity :	Pearson: 0.7076	Spearman: 0.7128
2023-08-04 16:22:09 - Manhattan-Distance:	Pearson: 0.7059	Spearman: 0.7177
2023-08-04 16:22:09 - Euclidean-Distance:	Pearson: 0.7057	Spearman: 0.7176
2023-08-04 16:22:09 - Dot-Product-Similarity:	Pearson: 0.6037	Spearman: 0.6057
2023-08-04 16:22:11 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 16 steps:
2023-08-04 16:22:13 - Cosine-Similarity :	Pearson: 0.7082	Spearman: 0.7137
2023-08-04 16:22:13 - Manhattan-Distance:	Pearson: 0.7070	Spearman: 0.7186
2023-08-04 16:22:13 - Euclidean-Distance:	Pearson: 0.7068	Spearman: 0.7184
2023-08-04 16:22:13 - Dot-Product-Similarity:	Pearson: 0.6036	Spearman: 0.6056
2023-08-04 16:22:13 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:19 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 20 steps:
2023-08-04 16:22:22 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7140
2023-08-04 16:22:22 - Manhattan-Distance:	Pearson: 0.7077	Spearman: 0.7191
2023-08-04 16:22:22 - Euclidean-Distance:	Pearson: 0.7073	Spearman: 0.7189
2023-08-04 16:22:22 - Dot-Product-Similarity:	Pearson: 0.6030	Spearman: 0.6053
2023-08-04 16:22:22 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:28 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 24 steps:
2023-08-04 16:22:30 - Cosine-Similarity :	Pearson: 0.7084	Spearman: 0.7138
2023-08-04 16:22:30 - Manhattan-Distance:	Pearson: 0.7079	Spearman: 0.7193
2023-08-04 16:22:30 - Euclidean-Distance:	Pearson: 0.7074	Spearman: 0.7191
2023-08-04 16:22:30 - Dot-Product-Similarity:	Pearson: 0.6026	Spearman: 0.6051
2023-08-04 16:22:32 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 28 steps:
2023-08-04 16:22:34 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7139
2023-08-04 16:22:34 - Manhattan-Distance:	Pearson: 0.7080	Spearman: 0.7193
2023-08-04 16:22:34 - Euclidean-Distance:	Pearson: 0.7075	Spearman: 0.7191
2023-08-04 16:22:34 - Dot-Product-Similarity:	Pearson: 0.6025	Spearman: 0.6053
2023-08-04 16:22:36 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 32 steps:
2023-08-04 16:22:38 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7140
2023-08-04 16:22:38 - Manhattan-Distance:	Pearson: 0.7080	Spearman: 0.7193
2023-08-04 16:22:38 - Euclidean-Distance:	Pearson: 0.7075	Spearman: 0.7190
2023-08-04 16:22:38 - Dot-Product-Similarity:	Pearson: 0.6030	Spearman: 0.6058
2023-08-04 16:22:38 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:44 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 36 steps:
2023-08-04 16:22:47 - Cosine-Similarity :	Pearson: 0.7086	Spearman: 0.7141
2023-08-04 16:22:47 - Manhattan-Distance:	Pearson: 0.7082	Spearman: 0.7194
2023-08-04 16:22:47 - Euclidean-Distance:	Pearson: 0.7076	Spearman: 0.7190
2023-08-04 16:22:47 - Dot-Product-Similarity:	Pearson: 0.6037	Spearman: 0.6067
2023-08-04 16:22:47 - Save model to ./outputs_qa/consert-qa-sup-snli-macbert-2-CosineSimilarityLoss-2023-08-04_16-19-45
2023-08-04 16:22:54 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 40 steps:
2023-08-04 16:22:55 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7140
2023-08-04 16:22:55 - Manhattan-Distance:	Pearson: 0.7081	Spearman: 0.7192
2023-08-04 16:22:55 - Euclidean-Distance:	Pearson: 0.7076	Spearman: 0.7190
2023-08-04 16:22:55 - Dot-Product-Similarity:	Pearson: 0.6039	Spearman: 0.6069
2023-08-04 16:22:57 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 44 steps:
2023-08-04 16:22:59 - Cosine-Similarity :	Pearson: 0.7082	Spearman: 0.7138
2023-08-04 16:22:59 - Manhattan-Distance:	Pearson: 0.7080	Spearman: 0.7191
2023-08-04 16:22:59 - Euclidean-Distance:	Pearson: 0.7074	Spearman: 0.7189
2023-08-04 16:22:59 - Dot-Product-Similarity:	Pearson: 0.6038	Spearman: 0.6069
2023-08-04 16:23:00 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset after epoch 1:
2023-08-04 16:23:01 - Cosine-Similarity :	Pearson: 0.7082	Spearman: 0.7137
2023-08-04 16:23:01 - Manhattan-Distance:	Pearson: 0.7080	Spearman: 0.7190
2023-08-04 16:23:01 - Euclidean-Distance:	Pearson: 0.7074	Spearman: 0.7189
2023-08-04 16:23:01 - Dot-Product-Similarity:	Pearson: 0.6038	Spearman: 0.6068
2023-08-04 16:23:01 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-test dataset:
2023-08-04 16:23:03 - Cosine-Similarity :	Pearson: 0.6451	Spearman: 0.6406
2023-08-04 16:23:03 - Manhattan-Distance:	Pearson: 0.6461	Spearman: 0.6386
2023-08-04 16:23:03 - Euclidean-Distance:	Pearson: 0.6442	Spearman: 0.6369
2023-08-04 16:23:03 - Dot-Product-Similarity:	Pearson: 0.5545	Spearman: 0.5410
[2023-08-04 16:28:14,786] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-04 16:28:26,223] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-04 16:28:41,496] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-08-04 16:28:51,149] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-04 16:28:50 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:28:50 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of snil-unsup data is 11597
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11597
Warmup-steps: 10
Performance before training
2023-08-04 16:28:54 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-snli-dev dataset:
2023-08-04 16:28:57 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-04 16:28:57 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-04 16:28:57 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-04 16:28:57 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:10 in <module>                 │
│                                                                              │
│    7 │   │   │   │   level=logging.INFO,                                     │
│    8 │   │   │   │   handlers=[LoggingHandler()])                            │
│    9 │                                                                       │
│ ❱ 10 │   train()                                                             │
│   11 │   # with open("./datasets_QA/QA-16k-sup-STS-train.txt", "r", encoding │
│   12 │   #     for i in f:                                                   │
│   13 │   #         i = i.replace("\n", "")                                   │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:317 in fit  │
│                                                                              │
│   314 │   │   │   │   │                                                      │
│   315 │   │   │   │   │   if use_amp:                                        │
│   316 │   │   │   │   │   │   with autocast():                               │
│ ❱ 317 │   │   │   │   │   │   │   loss_value = loss_model(features, labels,  │
│   318 │   │   │   │   │   │                                                  │
│   319 │   │   │   │   │   │   scale_before_step = scaler.get_scale()         │
│   320 │   │   │   │   │   │   scaler.scale(loss_value).backward()            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/losses/MultipleNegativ │
│ esRankingLoss_embeddings.py:53 in forward                                    │
│                                                                              │
│   50 │                                                                       │
│   51 │                                                                       │
│   52 │   def forward(self, sentence_features: Iterable[Dict[str, Tensor]], l │
│ ❱ 53 │   │   reps = [self.model(sentence_feature)['sentence_embedding'] for  │
│   54 │   │   embeddings_a = reps[0]  # [L, H]                                │
│   55 │   │   embeddings_b = torch.cat(reps[1:])  # [L, H]                    │
│   56                                                                         │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/losses/MultipleNegativ │
│ esRankingLoss_embeddings.py:53 in <listcomp>                                 │
│                                                                              │
│   50 │                                                                       │
│   51 │                                                                       │
│   52 │   def forward(self, sentence_features: Iterable[Dict[str, Tensor]], l │
│ ❱ 53 │   │   reps = [self.model(sentence_feature)['sentence_embedding'] for  │
│   54 │   │   embeddings_a = reps[0]  # [L, H]                                │
│   55 │   │   embeddings_b = torch.cat(reps[1:])  # [L, H]                    │
│   56                                                                         │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/contain │
│ er.py:204 in forward                                                         │
│                                                                              │
│   201 │   # with Any as TorchScript expects a more precise type              │
│   202 │   def forward(self, input):                                          │
│   203 │   │   for module in self:                                            │
│ ❱ 204 │   │   │   input = module(input)                                      │
│   205 │   │   return input                                                   │
│   206 │                                                                      │
│   207 │   def append(self, module: Module) -> 'Sequential':                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/models/Transformer.py: │
│ 54 in forward                                                                │
│                                                                              │
│    51 │   │   if 'token_type_ids' in features:                               │
│    52 │   │   │   trans_features['token_type_ids'] = features['token_type_id │
│    53 │   │                                                                  │
│ ❱  54 │   │   output_states = self.auto_model(**trans_features, return_dict= │
│    55 │   │   output_tokens = output_states[0]                               │
│    56 │   │                                                                  │
│    57 │   │   features.update({'token_embeddings': output_tokens, 'attention │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:1020 in forward                                            │
│                                                                              │
│   1017 │   │   │   inputs_embeds=inputs_embeds,                              │
│   1018 │   │   │   past_key_values_length=past_key_values_length,            │
│   1019 │   │   )                                                             │
│ ❱ 1020 │   │   encoder_outputs = self.encoder(                               │
│   1021 │   │   │   embedding_output,                                         │
│   1022 │   │   │   attention_mask=extended_attention_mask,                   │
│   1023 │   │   │   head_mask=head_mask,                                      │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:610 in forward                                             │
│                                                                              │
│    607 │   │   │   │   │   encoder_attention_mask,                           │
│    608 │   │   │   │   )                                                     │
│    609 │   │   │   else:                                                     │
│ ❱  610 │   │   │   │   layer_outputs = layer_module(                         │
│    611 │   │   │   │   │   hidden_states,                                    │
│    612 │   │   │   │   │   attention_mask,                                   │
│    613 │   │   │   │   │   layer_head_mask,                                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:537 in forward                                             │
│                                                                              │
│    534 │   │   │   cross_attn_present_key_value = cross_attention_outputs[-1 │
│    535 │   │   │   present_key_value = present_key_value + cross_attn_presen │
│    536 │   │                                                                 │
│ ❱  537 │   │   layer_output = apply_chunking_to_forward(                     │
│    538 │   │   │   self.feed_forward_chunk, self.chunk_size_feed_forward, se │
│    539 │   │   )                                                             │
│    540 │   │   outputs = (layer_output,) + outputs                           │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/pytorch_uti │
│ ls.py:237 in apply_chunking_to_forward                                       │
│                                                                              │
│   234 │   │   # concatenate output at same dimension                         │
│   235 │   │   return torch.cat(output_chunks, dim=chunk_dim)                 │
│   236 │                                                                      │
│ ❱ 237 │   return forward_fn(*input_tensors)                                  │
│   238                                                                        │
│   239                                                                        │
│   240 def find_pruneable_heads_and_indices(                                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:550 in feed_forward_chunk                                  │
│                                                                              │
│    547 │                                                                     │
│    548 │   def feed_forward_chunk(self, attention_output):                   │
│    549 │   │   intermediate_output = self.intermediate(attention_output)     │
│ ❱  550 │   │   layer_output = self.output(intermediate_output, attention_out │
│    551 │   │   return layer_output                                           │
│    552                                                                       │
│    553                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:464 in forward                                             │
│                                                                              │
│    461 │   def forward(self, hidden_states: torch.Tensor, input_tensor: torc │
│    462 │   │   hidden_states = self.dense(hidden_states)                     │
│    463 │   │   hidden_states = self.dropout(hidden_states)                   │
│ ❱  464 │   │   hidden_states = self.LayerNorm(hidden_states + input_tensor)  │
│    465 │   │   return hidden_states                                          │
│    466                                                                       │
│    467                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/normali │
│ zation.py:190 in forward                                                     │
│                                                                              │
│   187 │   │   │   init.zeros_(self.bias)                                     │
│   188 │                                                                      │
│   189 │   def forward(self, input: Tensor) -> Tensor:                        │
│ ❱ 190 │   │   return F.layer_norm(                                           │
│   191 │   │   │   input, self.normalized_shape, self.weight, self.bias, self │
│   192 │                                                                      │
│   193 │   def extra_repr(self) -> str:                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/functional.py:2 │
│ 515 in layer_norm                                                            │
│                                                                              │
│   2512 │   │   return handle_torch_function(                                 │
│   2513 │   │   │   layer_norm, (input, weight, bias), input, normalized_shap │
│   2514 │   │   )                                                             │
│ ❱ 2515 │   return torch.layer_norm(input, normalized_shape, weight, bias, ep │
│   2516                                                                       │
│   2517                                                                       │
│   2518 def group_norm(                                                       │
╰──────────────────────────────────────────────────────────────────────────────╯
OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 79.15 
GiB total capacity; 5.17 GiB already allocated; 6.44 MiB free; 5.26 GiB reserved
in total by PyTorch) If reserved memory is >> allocated memory try setting 
max_split_size_mb to avoid fragmentation.  See documentation for Memory 
Management and PYTORCH_CUDA_ALLOC_CONF
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-04 16:29:00 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:29:00 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 11692
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11692
Warmup-steps: 10
Performance before training
2023-08-04 16:29:03 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset:
2023-08-04 16:29:06 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-04 16:29:06 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-04 16:29:06 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-04 16:29:06 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:10 in <module>                 │
│                                                                              │
│    7 │   │   │   │   level=logging.INFO,                                     │
│    8 │   │   │   │   handlers=[LoggingHandler()])                            │
│    9 │                                                                       │
│ ❱ 10 │   train()                                                             │
│   11 │   # with open("./datasets_QA/QA-16k-sup-STS-train.txt", "r", encoding │
│   12 │   #     for i in f:                                                   │
│   13 │   #         i = i.replace("\n", "")                                   │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:317 in fit  │
│                                                                              │
│   314 │   │   │   │   │                                                      │
│   315 │   │   │   │   │   if use_amp:                                        │
│   316 │   │   │   │   │   │   with autocast():                               │
│ ❱ 317 │   │   │   │   │   │   │   loss_value = loss_model(features, labels,  │
│   318 │   │   │   │   │   │                                                  │
│   319 │   │   │   │   │   │   scale_before_step = scaler.get_scale()         │
│   320 │   │   │   │   │   │   scaler.scale(loss_value).backward()            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/losses/MultipleNegativ │
│ esRankingLoss_embeddings.py:53 in forward                                    │
│                                                                              │
│   50 │                                                                       │
│   51 │                                                                       │
│   52 │   def forward(self, sentence_features: Iterable[Dict[str, Tensor]], l │
│ ❱ 53 │   │   reps = [self.model(sentence_feature)['sentence_embedding'] for  │
│   54 │   │   embeddings_a = reps[0]  # [L, H]                                │
│   55 │   │   embeddings_b = torch.cat(reps[1:])  # [L, H]                    │
│   56                                                                         │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/losses/MultipleNegativ │
│ esRankingLoss_embeddings.py:53 in <listcomp>                                 │
│                                                                              │
│   50 │                                                                       │
│   51 │                                                                       │
│   52 │   def forward(self, sentence_features: Iterable[Dict[str, Tensor]], l │
│ ❱ 53 │   │   reps = [self.model(sentence_feature)['sentence_embedding'] for  │
│   54 │   │   embeddings_a = reps[0]  # [L, H]                                │
│   55 │   │   embeddings_b = torch.cat(reps[1:])  # [L, H]                    │
│   56                                                                         │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/contain │
│ er.py:204 in forward                                                         │
│                                                                              │
│   201 │   # with Any as TorchScript expects a more precise type              │
│   202 │   def forward(self, input):                                          │
│   203 │   │   for module in self:                                            │
│ ❱ 204 │   │   │   input = module(input)                                      │
│   205 │   │   return input                                                   │
│   206 │                                                                      │
│   207 │   def append(self, module: Module) -> 'Sequential':                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/models/Transformer.py: │
│ 54 in forward                                                                │
│                                                                              │
│    51 │   │   if 'token_type_ids' in features:                               │
│    52 │   │   │   trans_features['token_type_ids'] = features['token_type_id │
│    53 │   │                                                                  │
│ ❱  54 │   │   output_states = self.auto_model(**trans_features, return_dict= │
│    55 │   │   output_tokens = output_states[0]                               │
│    56 │   │                                                                  │
│    57 │   │   features.update({'token_embeddings': output_tokens, 'attention │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:1020 in forward                                            │
│                                                                              │
│   1017 │   │   │   inputs_embeds=inputs_embeds,                              │
│   1018 │   │   │   past_key_values_length=past_key_values_length,            │
│   1019 │   │   )                                                             │
│ ❱ 1020 │   │   encoder_outputs = self.encoder(                               │
│   1021 │   │   │   embedding_output,                                         │
│   1022 │   │   │   attention_mask=extended_attention_mask,                   │
│   1023 │   │   │   head_mask=head_mask,                                      │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:610 in forward                                             │
│                                                                              │
│    607 │   │   │   │   │   encoder_attention_mask,                           │
│    608 │   │   │   │   )                                                     │
│    609 │   │   │   else:                                                     │
│ ❱  610 │   │   │   │   layer_outputs = layer_module(                         │
│    611 │   │   │   │   │   hidden_states,                                    │
│    612 │   │   │   │   │   attention_mask,                                   │
│    613 │   │   │   │   │   layer_head_mask,                                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:537 in forward                                             │
│                                                                              │
│    534 │   │   │   cross_attn_present_key_value = cross_attention_outputs[-1 │
│    535 │   │   │   present_key_value = present_key_value + cross_attn_presen │
│    536 │   │                                                                 │
│ ❱  537 │   │   layer_output = apply_chunking_to_forward(                     │
│    538 │   │   │   self.feed_forward_chunk, self.chunk_size_feed_forward, se │
│    539 │   │   )                                                             │
│    540 │   │   outputs = (layer_output,) + outputs                           │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/pytorch_uti │
│ ls.py:237 in apply_chunking_to_forward                                       │
│                                                                              │
│   234 │   │   # concatenate output at same dimension                         │
│   235 │   │   return torch.cat(output_chunks, dim=chunk_dim)                 │
│   236 │                                                                      │
│ ❱ 237 │   return forward_fn(*input_tensors)                                  │
│   238                                                                        │
│   239                                                                        │
│   240 def find_pruneable_heads_and_indices(                                  │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:550 in feed_forward_chunk                                  │
│                                                                              │
│    547 │                                                                     │
│    548 │   def feed_forward_chunk(self, attention_output):                   │
│    549 │   │   intermediate_output = self.intermediate(attention_output)     │
│ ❱  550 │   │   layer_output = self.output(intermediate_output, attention_out │
│    551 │   │   return layer_output                                           │
│    552                                                                       │
│    553                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/transformers/models/bert │
│ /modeling_bert.py:464 in forward                                             │
│                                                                              │
│    461 │   def forward(self, hidden_states: torch.Tensor, input_tensor: torc │
│    462 │   │   hidden_states = self.dense(hidden_states)                     │
│    463 │   │   hidden_states = self.dropout(hidden_states)                   │
│ ❱  464 │   │   hidden_states = self.LayerNorm(hidden_states + input_tensor)  │
│    465 │   │   return hidden_states                                          │
│    466                                                                       │
│    467                                                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/module. │
│ py:1194 in _call_impl                                                        │
│                                                                              │
│   1191 │   │   # this function, and just call forward.                       │
│   1192 │   │   if not (self._backward_hooks or self._forward_hooks or self._ │
│   1193 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1194 │   │   │   return forward_call(*input, **kwargs)                     │
│   1195 │   │   # Do not call functions when jit is used                      │
│   1196 │   │   full_backward_hooks, non_full_backward_hooks = [], []         │
│   1197 │   │   if self._backward_hooks or _global_backward_hooks:            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/modules/normali │
│ zation.py:190 in forward                                                     │
│                                                                              │
│   187 │   │   │   init.zeros_(self.bias)                                     │
│   188 │                                                                      │
│   189 │   def forward(self, input: Tensor) -> Tensor:                        │
│ ❱ 190 │   │   return F.layer_norm(                                           │
│   191 │   │   │   input, self.normalized_shape, self.weight, self.bias, self │
│   192 │                                                                      │
│   193 │   def extra_repr(self) -> str:                                       │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/site-packages/torch/nn/functional.py:2 │
│ 515 in layer_norm                                                            │
│                                                                              │
│   2512 │   │   return handle_torch_function(                                 │
│   2513 │   │   │   layer_norm, (input, weight, bias), input, normalized_shap │
│   2514 │   │   )                                                             │
│ ❱ 2515 │   return torch.layer_norm(input, normalized_shape, weight, bias, ep │
│   2516                                                                       │
│   2517                                                                       │
│   2518 def group_norm(                                                       │
╰──────────────────────────────────────────────────────────────────────────────╯
OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 79.15 
GiB total capacity; 5.17 GiB already allocated; 6.44 MiB free; 5.26 GiB reserved
in total by PyTorch) If reserved memory is >> allocated memory try setting 
max_split_size_mb to avoid fragmentation.  See documentation for Memory 
Management and PYTORCH_CUDA_ALLOC_CONF
2023-08-04 16:28:22 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:28:22 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  snil-sup  data is 11597
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11597
Warmup-steps: 10
Performance before training
2023-08-04 16:28:24 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset:
2023-08-04 16:28:27 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-04 16:28:27 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-04 16:28:27 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-04 16:28:27 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-04 16:28:29 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 4 steps:
2023-08-04 16:28:31 - Cosine-Similarity :	Pearson: 0.3969	Spearman: 0.4220
2023-08-04 16:28:31 - Manhattan-Distance:	Pearson: 0.4206	Spearman: 0.4237
2023-08-04 16:28:31 - Euclidean-Distance:	Pearson: 0.4185	Spearman: 0.4222
2023-08-04 16:28:31 - Dot-Product-Similarity:	Pearson: 0.3921	Spearman: 0.4081
2023-08-04 16:28:31 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:28:41 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 8 steps:
2023-08-04 16:28:43 - Cosine-Similarity :	Pearson: 0.4816	Spearman: 0.4913
2023-08-04 16:28:43 - Manhattan-Distance:	Pearson: 0.4917	Spearman: 0.4924
2023-08-04 16:28:43 - Euclidean-Distance:	Pearson: 0.4897	Spearman: 0.4907
2023-08-04 16:28:43 - Dot-Product-Similarity:	Pearson: 0.4837	Spearman: 0.4891
2023-08-04 16:28:43 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:28:51 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 12 steps:
2023-08-04 16:28:53 - Cosine-Similarity :	Pearson: 0.5735	Spearman: 0.5808
2023-08-04 16:28:53 - Manhattan-Distance:	Pearson: 0.5752	Spearman: 0.5807
2023-08-04 16:28:53 - Euclidean-Distance:	Pearson: 0.5734	Spearman: 0.5785
2023-08-04 16:28:53 - Dot-Product-Similarity:	Pearson: 0.5802	Spearman: 0.5876
2023-08-04 16:28:53 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:01 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 16 steps:
2023-08-04 16:29:03 - Cosine-Similarity :	Pearson: 0.6498	Spearman: 0.6633
2023-08-04 16:29:03 - Manhattan-Distance:	Pearson: 0.6523	Spearman: 0.6621
2023-08-04 16:29:03 - Euclidean-Distance:	Pearson: 0.6512	Spearman: 0.6608
2023-08-04 16:29:03 - Dot-Product-Similarity:	Pearson: 0.6484	Spearman: 0.6584
2023-08-04 16:29:03 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:10 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 20 steps:
2023-08-04 16:29:13 - Cosine-Similarity :	Pearson: 0.6755	Spearman: 0.6881
2023-08-04 16:29:13 - Manhattan-Distance:	Pearson: 0.6796	Spearman: 0.6884
2023-08-04 16:29:13 - Euclidean-Distance:	Pearson: 0.6792	Spearman: 0.6877
2023-08-04 16:29:13 - Dot-Product-Similarity:	Pearson: 0.6658	Spearman: 0.6720
2023-08-04 16:29:13 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:20 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 24 steps:
2023-08-04 16:29:22 - Cosine-Similarity :	Pearson: 0.6898	Spearman: 0.7014
2023-08-04 16:29:22 - Manhattan-Distance:	Pearson: 0.6941	Spearman: 0.7027
2023-08-04 16:29:22 - Euclidean-Distance:	Pearson: 0.6942	Spearman: 0.7022
2023-08-04 16:29:22 - Dot-Product-Similarity:	Pearson: 0.6750	Spearman: 0.6795
2023-08-04 16:29:22 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:30 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 28 steps:
2023-08-04 16:29:32 - Cosine-Similarity :	Pearson: 0.6993	Spearman: 0.7105
2023-08-04 16:29:32 - Manhattan-Distance:	Pearson: 0.7031	Spearman: 0.7118
2023-08-04 16:29:32 - Euclidean-Distance:	Pearson: 0.7036	Spearman: 0.7117
2023-08-04 16:29:32 - Dot-Product-Similarity:	Pearson: 0.6823	Spearman: 0.6876
2023-08-04 16:29:32 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:40 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 32 steps:
2023-08-04 16:29:42 - Cosine-Similarity :	Pearson: 0.7053	Spearman: 0.7162
2023-08-04 16:29:42 - Manhattan-Distance:	Pearson: 0.7087	Spearman: 0.7176
2023-08-04 16:29:42 - Euclidean-Distance:	Pearson: 0.7093	Spearman: 0.7178
2023-08-04 16:29:42 - Dot-Product-Similarity:	Pearson: 0.6890	Spearman: 0.6948
2023-08-04 16:29:42 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:29:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 36 steps:
2023-08-04 16:29:52 - Cosine-Similarity :	Pearson: 0.7084	Spearman: 0.7193
2023-08-04 16:29:52 - Manhattan-Distance:	Pearson: 0.7118	Spearman: 0.7207
2023-08-04 16:29:52 - Euclidean-Distance:	Pearson: 0.7123	Spearman: 0.7207
2023-08-04 16:29:52 - Dot-Product-Similarity:	Pearson: 0.6932	Spearman: 0.6994
2023-08-04 16:29:52 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:30:00 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 40 steps:
2023-08-04 16:30:02 - Cosine-Similarity :	Pearson: 0.7091	Spearman: 0.7201
2023-08-04 16:30:02 - Manhattan-Distance:	Pearson: 0.7126	Spearman: 0.7215
2023-08-04 16:30:02 - Euclidean-Distance:	Pearson: 0.7130	Spearman: 0.7218
2023-08-04 16:30:02 - Dot-Product-Similarity:	Pearson: 0.6944	Spearman: 0.7008
2023-08-04 16:30:02 - Save model to ./outputs_qa/esimcse-qa-sup-snli-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-12
2023-08-04 16:30:10 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 0 after 44 steps:
2023-08-04 16:30:12 - Cosine-Similarity :	Pearson: 0.7085	Spearman: 0.7193
2023-08-04 16:30:12 - Manhattan-Distance:	Pearson: 0.7121	Spearman: 0.7211
2023-08-04 16:30:12 - Euclidean-Distance:	Pearson: 0.7125	Spearman: 0.7212
2023-08-04 16:30:12 - Dot-Product-Similarity:	Pearson: 0.6939	Spearman: 0.7006
2023-08-04 16:30:13 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset after epoch 0:
2023-08-04 16:30:14 - Cosine-Similarity :	Pearson: 0.7080	Spearman: 0.7190
2023-08-04 16:30:14 - Manhattan-Distance:	Pearson: 0.7118	Spearman: 0.7207
2023-08-04 16:30:14 - Euclidean-Distance:	Pearson: 0.7121	Spearman: 0.7208
2023-08-04 16:30:14 - Dot-Product-Similarity:	Pearson: 0.6935	Spearman: 0.7005
2023-08-04 16:30:17 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 4 steps:
2023-08-04 16:30:20 - Cosine-Similarity :	Pearson: 0.7075	Spearman: 0.7188
2023-08-04 16:30:20 - Manhattan-Distance:	Pearson: 0.7115	Spearman: 0.7204
2023-08-04 16:30:20 - Euclidean-Distance:	Pearson: 0.7118	Spearman: 0.7203
2023-08-04 16:30:20 - Dot-Product-Similarity:	Pearson: 0.6937	Spearman: 0.7009
2023-08-04 16:30:22 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 8 steps:
2023-08-04 16:30:24 - Cosine-Similarity :	Pearson: 0.7068	Spearman: 0.7184
2023-08-04 16:30:24 - Manhattan-Distance:	Pearson: 0.7111	Spearman: 0.7201
2023-08-04 16:30:24 - Euclidean-Distance:	Pearson: 0.7113	Spearman: 0.7200
2023-08-04 16:30:24 - Dot-Product-Similarity:	Pearson: 0.6937	Spearman: 0.7014
2023-08-04 16:30:27 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 12 steps:
2023-08-04 16:30:29 - Cosine-Similarity :	Pearson: 0.7052	Spearman: 0.7173
2023-08-04 16:30:29 - Manhattan-Distance:	Pearson: 0.7100	Spearman: 0.7188
2023-08-04 16:30:29 - Euclidean-Distance:	Pearson: 0.7102	Spearman: 0.7188
2023-08-04 16:30:29 - Dot-Product-Similarity:	Pearson: 0.6930	Spearman: 0.7012
2023-08-04 16:30:33 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 16 steps:
2023-08-04 16:30:35 - Cosine-Similarity :	Pearson: 0.7023	Spearman: 0.7152
2023-08-04 16:30:35 - Manhattan-Distance:	Pearson: 0.7076	Spearman: 0.7164
2023-08-04 16:30:35 - Euclidean-Distance:	Pearson: 0.7077	Spearman: 0.7164
2023-08-04 16:30:35 - Dot-Product-Similarity:	Pearson: 0.6908	Spearman: 0.6997
2023-08-04 16:30:38 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 20 steps:
2023-08-04 16:30:40 - Cosine-Similarity :	Pearson: 0.6991	Spearman: 0.7128
2023-08-04 16:30:40 - Manhattan-Distance:	Pearson: 0.7050	Spearman: 0.7138
2023-08-04 16:30:40 - Euclidean-Distance:	Pearson: 0.7050	Spearman: 0.7136
2023-08-04 16:30:40 - Dot-Product-Similarity:	Pearson: 0.6882	Spearman: 0.6976
2023-08-04 16:30:44 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 24 steps:
2023-08-04 16:30:46 - Cosine-Similarity :	Pearson: 0.6973	Spearman: 0.7115
2023-08-04 16:30:46 - Manhattan-Distance:	Pearson: 0.7036	Spearman: 0.7123
2023-08-04 16:30:46 - Euclidean-Distance:	Pearson: 0.7035	Spearman: 0.7120
2023-08-04 16:30:46 - Dot-Product-Similarity:	Pearson: 0.6869	Spearman: 0.6969
2023-08-04 16:30:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 28 steps:
2023-08-04 16:30:52 - Cosine-Similarity :	Pearson: 0.6961	Spearman: 0.7106
2023-08-04 16:30:52 - Manhattan-Distance:	Pearson: 0.7026	Spearman: 0.7114
2023-08-04 16:30:52 - Euclidean-Distance:	Pearson: 0.7025	Spearman: 0.7111
2023-08-04 16:30:52 - Dot-Product-Similarity:	Pearson: 0.6860	Spearman: 0.6962
2023-08-04 16:30:56 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 32 steps:
2023-08-04 16:30:58 - Cosine-Similarity :	Pearson: 0.6952	Spearman: 0.7098
2023-08-04 16:30:58 - Manhattan-Distance:	Pearson: 0.7019	Spearman: 0.7106
2023-08-04 16:30:58 - Euclidean-Distance:	Pearson: 0.7017	Spearman: 0.7103
2023-08-04 16:30:58 - Dot-Product-Similarity:	Pearson: 0.6853	Spearman: 0.6957
2023-08-04 16:31:02 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 36 steps:
2023-08-04 16:31:05 - Cosine-Similarity :	Pearson: 0.6947	Spearman: 0.7092
2023-08-04 16:31:05 - Manhattan-Distance:	Pearson: 0.7014	Spearman: 0.7101
2023-08-04 16:31:05 - Euclidean-Distance:	Pearson: 0.7012	Spearman: 0.7098
2023-08-04 16:31:05 - Dot-Product-Similarity:	Pearson: 0.6849	Spearman: 0.6954
2023-08-04 16:31:08 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 40 steps:
2023-08-04 16:31:10 - Cosine-Similarity :	Pearson: 0.6941	Spearman: 0.7087
2023-08-04 16:31:10 - Manhattan-Distance:	Pearson: 0.7008	Spearman: 0.7095
2023-08-04 16:31:10 - Euclidean-Distance:	Pearson: 0.7006	Spearman: 0.7091
2023-08-04 16:31:10 - Dot-Product-Similarity:	Pearson: 0.6845	Spearman: 0.6950
2023-08-04 16:31:14 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset in epoch 1 after 44 steps:
2023-08-04 16:31:16 - Cosine-Similarity :	Pearson: 0.6937	Spearman: 0.7084
2023-08-04 16:31:16 - Manhattan-Distance:	Pearson: 0.7004	Spearman: 0.7091
2023-08-04 16:31:16 - Euclidean-Distance:	Pearson: 0.7002	Spearman: 0.7087
2023-08-04 16:31:16 - Dot-Product-Similarity:	Pearson: 0.6843	Spearman: 0.6949
2023-08-04 16:31:18 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-dev dataset after epoch 1:
2023-08-04 16:31:20 - Cosine-Similarity :	Pearson: 0.6937	Spearman: 0.7083
2023-08-04 16:31:20 - Manhattan-Distance:	Pearson: 0.7004	Spearman: 0.7091
2023-08-04 16:31:20 - Euclidean-Distance:	Pearson: 0.7002	Spearman: 0.7087
2023-08-04 16:31:20 - Dot-Product-Similarity:	Pearson: 0.6843	Spearman: 0.6949
2023-08-04 16:31:20 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-snli-test dataset:
2023-08-04 16:31:22 - Cosine-Similarity :	Pearson: 0.6417	Spearman: 0.6399
2023-08-04 16:31:22 - Manhattan-Distance:	Pearson: 0.6483	Spearman: 0.6420
2023-08-04 16:31:22 - Euclidean-Distance:	Pearson: 0.6476	Spearman: 0.6414
2023-08-04 16:31:22 - Dot-Product-Similarity:	Pearson: 0.6275	Spearman: 0.6220
2023-08-04 16:28:33 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:28:33 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of  sts-sup  data is 11565
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11565
Warmup-steps: 10
Performance before training
2023-08-04 16:28:36 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset:
2023-08-04 16:28:39 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-04 16:28:39 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-04 16:28:39 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-04 16:28:39 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
2023-08-04 16:28:42 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 4 steps:
2023-08-04 16:28:44 - Cosine-Similarity :	Pearson: 0.3970	Spearman: 0.4223
2023-08-04 16:28:44 - Manhattan-Distance:	Pearson: 0.4208	Spearman: 0.4240
2023-08-04 16:28:44 - Euclidean-Distance:	Pearson: 0.4187	Spearman: 0.4226
2023-08-04 16:28:44 - Dot-Product-Similarity:	Pearson: 0.3919	Spearman: 0.4079
2023-08-04 16:28:44 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:28:51 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 8 steps:
2023-08-04 16:28:54 - Cosine-Similarity :	Pearson: 0.4543	Spearman: 0.4686
2023-08-04 16:28:54 - Manhattan-Distance:	Pearson: 0.4683	Spearman: 0.4697
2023-08-04 16:28:54 - Euclidean-Distance:	Pearson: 0.4663	Spearman: 0.4681
2023-08-04 16:28:54 - Dot-Product-Similarity:	Pearson: 0.4537	Spearman: 0.4618
2023-08-04 16:28:54 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:01 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 12 steps:
2023-08-04 16:29:03 - Cosine-Similarity :	Pearson: 0.5712	Spearman: 0.5790
2023-08-04 16:29:03 - Manhattan-Distance:	Pearson: 0.5734	Spearman: 0.5787
2023-08-04 16:29:03 - Euclidean-Distance:	Pearson: 0.5718	Spearman: 0.5766
2023-08-04 16:29:03 - Dot-Product-Similarity:	Pearson: 0.5783	Spearman: 0.5859
2023-08-04 16:29:03 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:10 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 16 steps:
2023-08-04 16:29:13 - Cosine-Similarity :	Pearson: 0.6484	Spearman: 0.6625
2023-08-04 16:29:13 - Manhattan-Distance:	Pearson: 0.6517	Spearman: 0.6613
2023-08-04 16:29:13 - Euclidean-Distance:	Pearson: 0.6505	Spearman: 0.6597
2023-08-04 16:29:13 - Dot-Product-Similarity:	Pearson: 0.6468	Spearman: 0.6565
2023-08-04 16:29:13 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:20 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 20 steps:
2023-08-04 16:29:22 - Cosine-Similarity :	Pearson: 0.6764	Spearman: 0.6892
2023-08-04 16:29:22 - Manhattan-Distance:	Pearson: 0.6810	Spearman: 0.6896
2023-08-04 16:29:22 - Euclidean-Distance:	Pearson: 0.6806	Spearman: 0.6890
2023-08-04 16:29:22 - Dot-Product-Similarity:	Pearson: 0.6656	Spearman: 0.6714
2023-08-04 16:29:22 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:30 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 24 steps:
2023-08-04 16:29:33 - Cosine-Similarity :	Pearson: 0.6911	Spearman: 0.7029
2023-08-04 16:29:33 - Manhattan-Distance:	Pearson: 0.6954	Spearman: 0.7036
2023-08-04 16:29:33 - Euclidean-Distance:	Pearson: 0.6957	Spearman: 0.7033
2023-08-04 16:29:33 - Dot-Product-Similarity:	Pearson: 0.6756	Spearman: 0.6800
2023-08-04 16:29:33 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:40 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 28 steps:
2023-08-04 16:29:42 - Cosine-Similarity :	Pearson: 0.7021	Spearman: 0.7133
2023-08-04 16:29:42 - Manhattan-Distance:	Pearson: 0.7057	Spearman: 0.7142
2023-08-04 16:29:42 - Euclidean-Distance:	Pearson: 0.7061	Spearman: 0.7144
2023-08-04 16:29:42 - Dot-Product-Similarity:	Pearson: 0.6859	Spearman: 0.6907
2023-08-04 16:29:42 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:29:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 32 steps:
2023-08-04 16:29:52 - Cosine-Similarity :	Pearson: 0.7087	Spearman: 0.7194
2023-08-04 16:29:52 - Manhattan-Distance:	Pearson: 0.7118	Spearman: 0.7205
2023-08-04 16:29:52 - Euclidean-Distance:	Pearson: 0.7124	Spearman: 0.7209
2023-08-04 16:29:52 - Dot-Product-Similarity:	Pearson: 0.6939	Spearman: 0.6990
2023-08-04 16:29:52 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:30:00 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 36 steps:
2023-08-04 16:30:02 - Cosine-Similarity :	Pearson: 0.7119	Spearman: 0.7225
2023-08-04 16:30:02 - Manhattan-Distance:	Pearson: 0.7149	Spearman: 0.7236
2023-08-04 16:30:02 - Euclidean-Distance:	Pearson: 0.7154	Spearman: 0.7238
2023-08-04 16:30:02 - Dot-Product-Similarity:	Pearson: 0.6978	Spearman: 0.7034
2023-08-04 16:30:02 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:30:09 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 40 steps:
2023-08-04 16:30:12 - Cosine-Similarity :	Pearson: 0.7129	Spearman: 0.7232
2023-08-04 16:30:12 - Manhattan-Distance:	Pearson: 0.7158	Spearman: 0.7246
2023-08-04 16:30:12 - Euclidean-Distance:	Pearson: 0.7162	Spearman: 0.7247
2023-08-04 16:30:12 - Dot-Product-Similarity:	Pearson: 0.6985	Spearman: 0.7044
2023-08-04 16:30:12 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:30:19 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 0 after 44 steps:
2023-08-04 16:30:22 - Cosine-Similarity :	Pearson: 0.7129	Spearman: 0.7232
2023-08-04 16:30:22 - Manhattan-Distance:	Pearson: 0.7159	Spearman: 0.7249
2023-08-04 16:30:22 - Euclidean-Distance:	Pearson: 0.7161	Spearman: 0.7249
2023-08-04 16:30:22 - Dot-Product-Similarity:	Pearson: 0.6980	Spearman: 0.7038
2023-08-04 16:30:22 - Save model to ./outputs_qa/esimcse-qa-sup-sts-macbert-2-MultipleNegativesRankingLoss_embeddings-2023-08-04_16-28-24
2023-08-04 16:30:26 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset after epoch 0:
2023-08-04 16:30:29 - Cosine-Similarity :	Pearson: 0.7122	Spearman: 0.7227
2023-08-04 16:30:29 - Manhattan-Distance:	Pearson: 0.7154	Spearman: 0.7245
2023-08-04 16:30:29 - Euclidean-Distance:	Pearson: 0.7156	Spearman: 0.7243
2023-08-04 16:30:29 - Dot-Product-Similarity:	Pearson: 0.6970	Spearman: 0.7029
2023-08-04 16:30:32 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 4 steps:
2023-08-04 16:30:34 - Cosine-Similarity :	Pearson: 0.7104	Spearman: 0.7211
2023-08-04 16:30:34 - Manhattan-Distance:	Pearson: 0.7142	Spearman: 0.7233
2023-08-04 16:30:34 - Euclidean-Distance:	Pearson: 0.7144	Spearman: 0.7230
2023-08-04 16:30:34 - Dot-Product-Similarity:	Pearson: 0.6951	Spearman: 0.7014
2023-08-04 16:30:38 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 8 steps:
2023-08-04 16:30:40 - Cosine-Similarity :	Pearson: 0.7092	Spearman: 0.7205
2023-08-04 16:30:40 - Manhattan-Distance:	Pearson: 0.7135	Spearman: 0.7225
2023-08-04 16:30:40 - Euclidean-Distance:	Pearson: 0.7137	Spearman: 0.7225
2023-08-04 16:30:40 - Dot-Product-Similarity:	Pearson: 0.6946	Spearman: 0.7014
2023-08-04 16:30:44 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 12 steps:
2023-08-04 16:30:46 - Cosine-Similarity :	Pearson: 0.7075	Spearman: 0.7192
2023-08-04 16:30:46 - Manhattan-Distance:	Pearson: 0.7124	Spearman: 0.7212
2023-08-04 16:30:46 - Euclidean-Distance:	Pearson: 0.7125	Spearman: 0.7212
2023-08-04 16:30:46 - Dot-Product-Similarity:	Pearson: 0.6938	Spearman: 0.7013
2023-08-04 16:30:50 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 16 steps:
2023-08-04 16:30:52 - Cosine-Similarity :	Pearson: 0.7067	Spearman: 0.7189
2023-08-04 16:30:52 - Manhattan-Distance:	Pearson: 0.7120	Spearman: 0.7208
2023-08-04 16:30:52 - Euclidean-Distance:	Pearson: 0.7121	Spearman: 0.7209
2023-08-04 16:30:52 - Dot-Product-Similarity:	Pearson: 0.6939	Spearman: 0.7020
2023-08-04 16:30:56 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 20 steps:
2023-08-04 16:30:58 - Cosine-Similarity :	Pearson: 0.7062	Spearman: 0.7188
2023-08-04 16:30:58 - Manhattan-Distance:	Pearson: 0.7119	Spearman: 0.7206
2023-08-04 16:30:58 - Euclidean-Distance:	Pearson: 0.7119	Spearman: 0.7207
2023-08-04 16:30:58 - Dot-Product-Similarity:	Pearson: 0.6937	Spearman: 0.7020
2023-08-04 16:31:02 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 24 steps:
2023-08-04 16:31:04 - Cosine-Similarity :	Pearson: 0.7058	Spearman: 0.7187
2023-08-04 16:31:04 - Manhattan-Distance:	Pearson: 0.7117	Spearman: 0.7205
2023-08-04 16:31:04 - Euclidean-Distance:	Pearson: 0.7117	Spearman: 0.7205
2023-08-04 16:31:04 - Dot-Product-Similarity:	Pearson: 0.6936	Spearman: 0.7019
2023-08-04 16:31:08 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 28 steps:
2023-08-04 16:31:10 - Cosine-Similarity :	Pearson: 0.7056	Spearman: 0.7185
2023-08-04 16:31:10 - Manhattan-Distance:	Pearson: 0.7114	Spearman: 0.7202
2023-08-04 16:31:10 - Euclidean-Distance:	Pearson: 0.7114	Spearman: 0.7201
2023-08-04 16:31:10 - Dot-Product-Similarity:	Pearson: 0.6939	Spearman: 0.7023
2023-08-04 16:31:14 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 32 steps:
2023-08-04 16:31:16 - Cosine-Similarity :	Pearson: 0.7054	Spearman: 0.7183
2023-08-04 16:31:16 - Manhattan-Distance:	Pearson: 0.7111	Spearman: 0.7198
2023-08-04 16:31:16 - Euclidean-Distance:	Pearson: 0.7111	Spearman: 0.7198
2023-08-04 16:31:16 - Dot-Product-Similarity:	Pearson: 0.6940	Spearman: 0.7027
2023-08-04 16:31:20 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 36 steps:
2023-08-04 16:31:22 - Cosine-Similarity :	Pearson: 0.7048	Spearman: 0.7178
2023-08-04 16:31:22 - Manhattan-Distance:	Pearson: 0.7105	Spearman: 0.7192
2023-08-04 16:31:22 - Euclidean-Distance:	Pearson: 0.7104	Spearman: 0.7192
2023-08-04 16:31:22 - Dot-Product-Similarity:	Pearson: 0.6936	Spearman: 0.7024
2023-08-04 16:31:24 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 40 steps:
2023-08-04 16:31:26 - Cosine-Similarity :	Pearson: 0.7042	Spearman: 0.7173
2023-08-04 16:31:26 - Manhattan-Distance:	Pearson: 0.7099	Spearman: 0.7187
2023-08-04 16:31:26 - Euclidean-Distance:	Pearson: 0.7099	Spearman: 0.7186
2023-08-04 16:31:26 - Dot-Product-Similarity:	Pearson: 0.6931	Spearman: 0.7020
2023-08-04 16:31:28 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset in epoch 1 after 44 steps:
2023-08-04 16:31:30 - Cosine-Similarity :	Pearson: 0.7039	Spearman: 0.7170
2023-08-04 16:31:30 - Manhattan-Distance:	Pearson: 0.7096	Spearman: 0.7183
2023-08-04 16:31:30 - Euclidean-Distance:	Pearson: 0.7095	Spearman: 0.7183
2023-08-04 16:31:30 - Dot-Product-Similarity:	Pearson: 0.6928	Spearman: 0.7018
2023-08-04 16:31:30 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-dev dataset after epoch 1:
2023-08-04 16:31:32 - Cosine-Similarity :	Pearson: 0.7038	Spearman: 0.7170
2023-08-04 16:31:32 - Manhattan-Distance:	Pearson: 0.7095	Spearman: 0.7182
2023-08-04 16:31:32 - Euclidean-Distance:	Pearson: 0.7095	Spearman: 0.7182
2023-08-04 16:31:32 - Dot-Product-Similarity:	Pearson: 0.6928	Spearman: 0.7018
2023-08-04 16:31:32 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-sup-sts-test dataset:
2023-08-04 16:31:33 - Cosine-Similarity :	Pearson: 0.6503	Spearman: 0.6471
2023-08-04 16:31:33 - Manhattan-Distance:	Pearson: 0.6579	Spearman: 0.6507
2023-08-04 16:31:33 - Euclidean-Distance:	Pearson: 0.6570	Spearman: 0.6495
2023-08-04 16:31:33 - Dot-Product-Similarity:	Pearson: 0.6310	Spearman: 0.6239
[2023-08-04 16:33:01,422] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at ./models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2023-08-04 16:33:08 - Load pretrained SentenceTransformer: ./models/chinese-macbert-base
2023-08-04 16:33:08 - No sentence-transformers model found with name ./models/chinese-macbert-base. Creating a new one with MEAN pooling.
The len of sts-unsup data is 11692
The len of  sts-sup  data is 1458
The len of  sts-sup  data is 1361
Training sentences: 11692
Warmup-steps: 10
Performance before training
2023-08-04 16:33:11 - EmbeddingSimilarityEvaluator: Evaluating the model on qa-unsup-sts-dev dataset:
2023-08-04 16:33:13 - Cosine-Similarity :	Pearson: 0.3830	Spearman: 0.4117
2023-08-04 16:33:13 - Manhattan-Distance:	Pearson: 0.4093	Spearman: 0.4134
2023-08-04 16:33:13 - Euclidean-Distance:	Pearson: 0.4072	Spearman: 0.4119
2023-08-04 16:33:13 - Dot-Product-Similarity:	Pearson: 0.3770	Spearman: 0.3958
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /data/yf_center/Embeddings_demo/main_train.py:10 in <module>                 │
│                                                                              │
│    7 │   │   │   │   level=logging.INFO,                                     │
│    8 │   │   │   │   handlers=[LoggingHandler()])                            │
│    9 │                                                                       │
│ ❱ 10 │   train()                                                             │
│   11 │   # with open("./datasets_QA/QA-16k-sup-STS-train.txt", "r", encoding │
│   12 │   #     for i in f:                                                   │
│   13 │   #         i = i.replace("\n", "")                                   │
│                                                                              │
│ /data/yf_center/Embeddings_demo/models.py:101 in train                       │
│                                                                              │
│    98 │   │   training_params["moco_encoder"] = moco_encoder                 │
│    99 │                                                                      │
│   100 │                                                                      │
│ ❱ 101 │   model.fit(**training_params)                                       │
│   102 │   test_evaluator(model)                                              │
│   103 │   return model                                                       │
│   104                                                                        │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:293 in fit  │
│                                                                              │
│   290 │   │   │   │   │   features, labels = data                            │
│   291 │   │   │   │   │                                                      │
│   292 │   │   │   │   │   # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> │
│ ❱ 293 │   │   │   │   │   features[1] = self.word_repetition(sentence_featur │
│   294 │   │   │   │   │   batch_size = labels.size(0)                        │
│   295 │   │   │   │   │                                                      │
│   296 │   │   │   │   │   negative_samples = None                            │
│                                                                              │
│ /data/yf_center/Embeddings_demo/sentence_transformers/ESimCSE.py:64 in       │
│ word_repetition                                                              │
│                                                                              │
│    61 │   │   │   cur_input_id = input_ids[bsz_id]                           │
│    62 │   │   │   dup_len = random.randint(a=0, b=max(                       │
│    63 │   │   │   │   2, int(self.dup_rate * actual_len)))                   │
│ ❱  64 │   │   │   dup_word_index = random.sample(                            │
│    65 │   │   │   │   list(range(1, actual_len)), k=dup_len)                 │
│    66 │   │   │                                                              │
│    67 │   │   │   r_input_id = []                                            │
│                                                                              │
│ /data/software/anaconda/lib/python3.9/random.py:449 in sample                │
│                                                                              │
│   446 │   │   │   return [population[bisect(cum_counts, s)] for s in selecti │
│   447 │   │   randbelow = self._randbelow                                    │
│   448 │   │   if not 0 <= k <= n:                                            │
│ ❱ 449 │   │   │   raise ValueError("Sample larger than population or is nega │
│   450 │   │   result = [None] * k                                            │
│   451 │   │   setsize = 21        # size of a small set minus size of an emp │
│   452 │   │   if k > 5:                                                      │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Sample larger than population or is negative
